

{
	"header__instructions": "All translations prefixed with 'header_' should be as short as possible to fit the layout. Try to keep them at a single word while still being useful as links to the pages.",
	"header_action__instructions": "German: Handeln",
	"header_action": "Handeln",
	"header_donate": "Spenden",
	"header_events__instructions": "In some language 'calendar' might be the better wording for meeting the goal of a short translation.",
	"header_events": "Termine",
	"header_faq": "FAQ",
	"header_join__instructions": "In some languages 'join in' might be more appropriate if the translation doesn't consist of two words.",
	"header_join": "Mitmachen",
	"header_learn": "Lernen",
	"header_proposal": "Vorschlag",
	"home_action_c2a": "Tätig werden",
	"home_action_content": "Zu wenige Menschen sind sich der potenziellen Risiken von KI bewusst. Informieren Sie andere und helfen Sie, diesen Wettlauf nach unten zu stoppen.",
	"home_action_title": "<u>SIE</u> KÖNNEN HELFEN",
	"home_hero": "LASSEN SIE NICHT ZU, DASS KI-UNTERNEHMEN UNSERE ZUKUNFT AUF'S SPIEL SETZEN",
	"home_proposal_c2a": "Den Vorschlag lesen",
	"home_proposal_content__instructions": "'Stop' isn't addressed at the reader.",
	"home_proposal_content": "Wir müssen die Entwicklung von KI-Systemen, die leistungsfähiger sind als GPT-4, stoppen, bis wir wissen, wie wir sie sicher machen können. Dies muss auf internationaler Ebene geschehen, und es muss bald geschehen.",
	"home_proposal_title": "Wir brauchen eine <u>Pause</u>",
	"home_quotes_all": "Alle Zitate anzeigen",
	"home_quotes_bengio_text": "Eine fehlgeleitete KI könnte für die gesamte Menschheit gefährlich sein. Ein Verbot von leistungsfähigen KI-Systemen, die Autonomie und Handlungsfähigkeit besitzen, wäre ein guter Anfang.",
	"home_quotes_bengio_title": "KI-Turing-Preisträger",
	"home_quotes_hawking_text": "Die Entwicklung einer vollständigen künstlichen Intelligenz könnte das Ende der menschlichen Rasse bedeuten.",
	"home_quotes_hawking_title": "Theoretischer Physiker und Kosmologe",
	"home_quotes_hinton_text": "Wenn Sie das existenzielle Risiko ernst nehmen, wie ich es jetzt tue, könnte es durchaus sinnvoll sein, die Entwicklung dieser Dinge einfach zu stoppen.",
	"home_quotes_hinton_title": "Nobelpreisträger und \"Gottvater der KI\"",
	"home_quotes_russell_text": "Wenn wir unseren aktuellen Ansatz verfolgen, werden wir schließlich die Kontrolle über die Maschinen verlieren",
	"home_quotes_russell_title": "Autor des KI-Lehrbuchs",
	"home_quotes_turing_text": "... wir sollten damit rechnen, dass die Maschinen die Kontrolle übernehmen.",
	"home_quotes_turing_title": "Erfinder des modernen Computers",
	"home_risks_c2a": "Mehr über die Risiken erfahren",
	"home_risks_content": "KI kann enorme Vorteile haben, aber sie könnte auch unsere Demokratie untergraben, unsere Wirtschaft destabilisieren und zur Schaffung leistungsfähiger Cyberwaffen verwendet werden.",
	"home_risks_title": "Wir riskieren, die <u>Kontrolle zu verlieren</u>",
	"home_stats_2025": "Chance, dass wir 2025 AGI erreichen",
	"home_stats_alignment": "von KI-Wissenschaftlern glauben, dass das Alignment-Problem real und wichtig ist",
	"home_stats_citizens": "von Bürgern wollen, dass unsere Regierungen KI verlangsamen",
	"home_urgency_c2a": "Wie viel Zeit bleibt uns noch?",
	"home_urgency_content": "Im Jahr 2020 dachten Experten, wir hätten mehr als 35 Jahre Zeit, bis AGI erreicht ist. Jüngste Durchbrüche zeigen, dass wir fast da sind. Superintelligenz könnte nur eine Innovation entfernt sein, also sollten wir vorsichtig sein.",
	"home_urgency_title": "WIR MÜSSEN <u>JETZT</u> HANDELN",
	"home_xrisk_c2a": "Wie und warum KI uns gefährden könnte",
	"home_xrisk_content": "Viele KI-Labors und Experten stimmen überein: KI könnte die Menschheit auslöschen.",
	"home_xrisk_title": "Wir riskieren den <u>Untergang der Menschheit</u>",
	"simpletoc_heading": "Inhaltsverzeichnis"
}