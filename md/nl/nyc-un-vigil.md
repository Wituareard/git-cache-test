

---
title: PauseAI kaarsenwake bij het VN-hoofdkwartier in NYC, 3 juni
---
- Kaarsenwake om bewustzijn te creëren over het existentiële risico van kunstmatige intelligentie.
- 3 juni, 19:30-21:00 uur. Zonsondergang om 20:15 uur.
- Hoofdkwartier van de Verenigde Naties in New York City.
- [Meld je aan](https://forms.gle/hsVetUDx3R1w6yj59)

## Persbericht {#press-release-4}

Op zaterdag 3 juni, bij zonsondergang, vindt een kaarsenwake plaats voor het hoofdkwartier van de Verenigde Naties.
De wake is een symbool van hoop, zodat mensen samen kunnen komen om actie te ondernemen tegen een groeiende existentiële dreiging.
Vrijwilligers van de nieuwe [PauseAI](http://pauseai.info)-beweging zullen daar bijeenkomen om regeringen op te roepen een internationale top te organiseren om de ontwikkeling van deze gevaarlijke technologie te stoppen.

De helft van de onderzoekers op het gebied van kunstmatige intelligentie [gelooft](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dat er een kans van 10% of meer is dat de uitvinding van superintelligente kunstmatige intelligentie het einde van de mensheid betekent. Zou je in een vliegtuig stappen als de helft van de vliegtuigingenieurs dacht dat er een kans van 10% was dat het zou neerstorten?

Prominente voorbeelden van mensen die waarschuwen voor de gevaren van kunstmatige intelligentie zijn prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) en prof. [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), beide winnaars van de Turing Award en pioniers van de meest succesvolle methoden op het gebied van kunstmatige intelligentie. Niet alleen wetenschappers, maar ook leiders van bedrijven die kunstmatige intelligentie ontwikkelen, zijn bezorgd over dit gevaar:

- Sam Altman (CEO van OpenAI, het bedrijf achter ChatGPT): ["De ontwikkeling van superintelligente machine-intelligentie is waarschijnlijk de grootste bedreiging voor het voortbestaan van de mensheid."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (mede-oprichter van OpenAI): ["Kunstmatige intelligentie heeft het potentieel om beschavingen te vernietigen."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (mede-oprichter van Microsoft, eigenaar van 50% van OpenAI): ["Kunstmatige intelligentie kan besluiten dat mensen een bedreiging vormen."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (leidende investeerder bij Anthropic, bouwers van Claude): ["Ik heb niemand in laboratoria voor kunstmatige intelligentie ontmoet die zegt dat het risico [van het trainen van een next-gen model] minder dan 1% is om de planeet op te blazen. Het is belangrijk dat mensen weten dat levens op het spel staan."](https://twitter.com/liron/status/1656929936639430657)

De vooruitgang in het landschap van kunstmatige intelligentie heeft de verwachtingen overtroffen. In 2020 werd geschat dat een systeem voor kunstmatige intelligentie pas in 2050 universitaire toelatingsexamens zou halen. Dit doel werd in maart 2023 bereikt door OpenAI's GPT-4. Deze kunstmatige intelligentie heeft een [verbale IQ van 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spreekt 23 talen, kan programmeren en [kan mensen misleiden](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Gelukkig heeft GPT-4 nog steeds beperkingen. Bijvoorbeeld, het kan niet effectief [hacken of computervirussen schrijven](https://pauseai.info/cybersecurity-risks), maar het is mogelijk dat deze vaardigheden slechts een paar innovaties verwijderd zijn. Gezien het huidige tempo van investeringen in kunstmatige intelligentie nadert dit punt [snel](https://pauseai.info/urgency).

Deze enorme en onverwachte sprongen in capaciteiten hebben veel experts ertoe gebracht om een pauze in de ontwikkeling van kunstmatige intelligentie te vragen via een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) gericht aan grote bedrijven die kunstmatige intelligentie ontwikkelen. De brief is meer dan 27.000 keer ondertekend, voornamelijk door onderzoekers op het gebied van kunstmatige intelligentie en prominente figuren in de tech-industrie. Een pauze is nodig om te werken aan wetgeving voor kunstmatige intelligentie, het probleem van de uitlijning van kunstmatige intelligentie op te lossen en ons als samenleving aan te passen aan deze nieuwe technologie. Een [recente enquête](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in de Verenigde Staten laat zien dat er significante steun is voor een pauze, met meer dan 60% van het publiek voor. Helaas lijkt het erop dat bedrijven niet bereid zijn om vrijwillig hun concurrentiepositie in gevaar te brengen door te stoppen. Deze bedrijven zijn verwikkeld in een race naar de bodem, waarbij veiligheid steeds meer een achterbank krijgt. Daarom moet de pauze worden opgelegd door regeringen. Het implementeren van een nationale pauze is ook een uitdaging, omdat landen redenen hebben om niet de eerste te zijn die pauzeert. Daarom is een internationale oplossing nodig: een top. PauseAI roept onze regeringen op om die top te organiseren.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info).