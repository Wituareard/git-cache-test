

---
title: Communicatiestrategie
description: Hoe wij communiceren over het pauzeren van AI-ontwikkeling.
---
## Hoe wij communiceren {#how-we-communicate}

- **Verwijs naar experts**. Wij waarschuwen mensen voor een scenario dat zo extreem en angstaanjagend is, dat een instinctieve reactie is om het af te doen als onzin. Toon de [expertpolls en enquêtes](/polls-and-surveys). De [drie meest geciteerde](https://twitter.com/PauseAI/status/1734641804245455017) AI-wetenschappers waarschuwen allemaal voor x-risico's. Het is een goede manier om ons standpunt te onderbouwen door naar hen te verwijzen.
- **Gebruik heldere taal**. Je kunt laten zien dat je de technologie begrijpt en je huiswerk hebt gedaan, maar overmatig jargon kan mensen doen afhaken. Wij willen zoveel mogelijk mensen bereiken, dus maak de taal niet te ingewikkeld. Veel van de mensen die wij willen bereiken zijn niet-moedertaalsprekers van het Engels, dus overweeg vertalingen te maken.
- **Laat onze emoties zien**. Het zien van emoties geeft anderen toestemming om emoties te voelen. Wij zijn bezorgd, wij zijn boos, wij zijn gretig om te handelen. Het laten zien van hoe je je voelt kan eng zijn, maar in ons geval moeten wij het doen. Onze boodschap kan alleen worden ontvangen als deze overeenkomt met hoe wij hem overbrengen.
- **Benadruk onzekerheid**. Zeg niet dat AI _zal_ de overhand nemen, of dat wij _zullen_ AGI bereiken in x jaar. Niemand kan de toekomst voorspellen. Er is een significante _kans_ dat AI binnenkort verkeerd zal gaan, en dat zou genoeg moeten zijn om te handelen. Laat onzekerheid geen reden zijn om niet te handelen. Verwijs naar het _voorzorgsprincipe_ en maak het punt dat wij aan de veilige kant moeten blijven.
- **Maak individuen zich verantwoordelijk voelen**. Niemand wil zich verantwoordelijk voelen voor het goed laten verlopen van dingen. Onze hersenen sturen ons weg van deze verantwoordelijkheid, omdat wij allemaal diep van binnen willen geloven dat iemand ons beschermt. Maar er zijn geen volwassenen in de kamer op dit moment. Jij moet degene zijn die dit doet. Kies ervoor om verantwoordelijkheid te nemen.
- **Inspireer hoop**. Wanneer wij horen over de gevaren van AI en de huidige race naar de bodem, zullen velen van ons een gevoel van wanhoop krijgen, en dat maakt ons passief. Fatalisme is comfortabel, omdat een gebrek aan hoop betekent dat wij niet naar een goed resultaat hoeven te streven. Dit is waarom wij moeten benadrukken dat onze zaak niet verloren is. AGI is [niet onvermijdelijk](/feasibility), technologie is in het verleden met succes internationaal verboden, en ons voorstel heeft brede steun van het publiek.

## Nee-nee's {#no-gos}

- **Geen AI-gegenereerde visuals**. Het gebruik van AI-modellen is prima voor onderzoek, ideevorming en het itereren van ideeën, maar publiceer geen AI-gegenereerde afbeeldingen en video's. Zelfs als wij niet anti-AI zijn, kunnen wij gemakkelijk als hypocrieten worden bestempeld als wij duidelijk AI-gegenereerde content gebruiken.
- **Geen partijpolitiek**. Wij pushen geen enkele politieke partij of ideologie. Wij hebben geen mening over zaken buiten AI.
- **Geen tactische zelfcensuur**. Sommige AI-governanceorganisaties kiezen ervoor om niet te zeggen hoe bezorgd zij zijn, of kiezen ervoor om niet te pushen voor de beleidsmaatregelen die zij nodig achten _omdat zij zich zorgen maken over het verlies van geloofwaardigheid_. Wij kunnen deze strategie niet kopiëren, omdat als wij dat allemaal doen, niemand overblijft om de waarheid te spreken.
- **Geen geruchten**. Wij promoten geen vage of ongeverifieerde informatie. Wij kunnen ons geen verlies van geloofwaardigheid veroorloven door valse informatie te verspreiden.

## Verhalen die wij pushen {#narratives-that-we-push}

- **AI is niet alleen een gereedschap**. AI-modellen zijn niet geprogrammeerd, zij zijn [digitale hersenen](/digital-brains). Wij begrijpen niet hoe zij werken, wij kunnen niet voorspellen wat zij kunnen doen, wij kunnen hun gedrag niet goed controleren.
- **AI hoeft niet bewust te zijn om gevaarlijk te zijn**. Het vermogen om de wereld te ervaren of emoties te voelen is geen vereiste voor AI om gevaarlijke acties te ondernemen. Het enige dat ertoe doet is [mogelijkheden](/dangerous-capabilities).
- **Wereldwijde race naar de bodem**. Dit is geen race om te winnen. Het gaat niet om de VS tegen China, het gaat om de mensheid tegen AI. Wij kunnen niet verwachten superintelligente AI als wapen te gebruiken - wij weten niet of het überhaupt kan worden gecontroleerd.
- **Bestaande AI-schade zal erger worden**. Deepfakes, baanverlies, surveillance, desinformatie, polarisatie... Bestaande AI veroorzaakt al schade en wij moeten dat erkennen. De schade zal alleen maar erger worden met krachtigere AI, en wij moeten AI pauzeren om dat te voorkomen.
- **Supermenselijke AI is niet onvermijdelijk**. Het vereist hordes ingenieurs met miljoenen dollars aan salaris. Het vereist zeer gespecialiseerde hardware, gecreëerd door een handvol monopolies. Het vereist dat wij allemaal niets doen.
- **Internationale regulering is mogelijk**. Wij hebben collectief de ozonlaag beschermd door CFK's en verblindende lasergeweren wereldwijd te verbieden. De gecentraliseerde AI-chipketen maakt het afdwingen van rekenkrachtgovernance zeer [haalbaar](/feasibility).

Veel van onze strategie is afgeleid van onze [waarden](https://pauseai.info/values).