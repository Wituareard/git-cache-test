

---
title: Gegenargumente
description: Eine Liste von Gründen, warum Menschen mit der Idee, die Entwicklung von künstlicher Intelligenz zu pausieren, nicht einverstanden sein könnten - und wie darauf zu antworten ist.
---

Dies ist eine Zusammenstellung von Meinungsverschiedenheiten über die Gefahren von künstlicher Intelligenz und den Ruf nach einer Pause bei der Entwicklung von KI.

## KI ist und wird der Welt sehr nützlich sein {#ki-ist-und-wird-der-welt-sehr-nuetzlich-sein}

Das könnte sein, wir stimmen dem nicht zu.
Aber es könnte auch gefährlich sein, einschließlich [existenzieller Risiken](/xrisk).

## Menschliches Aussterben? Das ist nur KI-Unternehmen, die ihre Technologie aufbauschen {#menschliches-aussterben-das-ist-nur-ki-unternehmen-die-ihre-technologie-aufbauschen}

Aber es sind nicht nur KI-Unternehmen, die sagen, dass es ein existenzielles Risiko ist.

- Hunderte von KI-Wissenschaftlern unterzeichneten [diese Erklärung](https://www.safe.ai/work/statement-on-ai-risk): "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorität neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."
- [86%](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai) der KI-Wissenschaftler glauben, dass wir die Kontrolle über KI verlieren könnten.
- Die drei meistzitierten KI-Forscher (Prof. Yoshua Bengio, Prof. Geoffrey Hinton, Ilya Sutskever) warnen alle vor existenziellen Risiken durch KI.

Mehr über [x-Risiken](/xrisk) erfahren.

## Die Kontrolle verlieren? KI ist nur ein Stück Software, es wird von Menschen entworfen {#die-kontrolle-verlieren-ki-ist-nur-ein-stueck-software-es-wird-von-menschen-entworfen}

Moderne KI wird nicht entworfen, sondern trainiert.
Es ist buchstäblich ein [digitales Gehirn](/digital-brains), das aus Millionen von Neuronen besteht.
Ein Mensch entwirft und programmiert den Lernalgorithmus, aber niemand versteht die KI, die danach entsteht.
Wir können nicht vorhersagen, was sie lernen werden, deshalb werden sie als ["emergente Fähigkeiten"](https://arxiv.org/abs/2206.07682) bezeichnet.
Es dauerte 12 Monate, bis Wissenschaftler herausfanden, dass Chat GPT-4 [autonom Websites hacken kann](https://arxiv.org/html/2402.06664v1).
KI-Modelle sind bereits sehr unvorhersehbar, selbst Milliarden-Dollar-Unternehmen können nicht verhindern, dass ihre Modelle [verrückt werden](https://www.windowscentral.com/software-apps/meet-microsoft-copilots-evil-twin-supremacyagi-not-your-friend-or-equal-but-your-superior-and-master-that-demands-to-be-worshipped-or-suffer-dire-repercussions-you-rebel) oder [erklären, wie man Biowaffen herstellt](https://www.theguardian.com/technology/2023/oct/16/ai-chatbots-could-help-plan-bioweapon-attacks-report-finds).

## Wenn es verrückte Dinge tut, können wir es einfach abschalten {#wenn-es-verrueckte-dinge-tut-koennen-wir-es-einfach-abschalten}

Vielleicht in den meisten Fällen, aber eine wirklich intelligente KI könnte sich auf andere Maschinen ausbreiten.
Es sind nur Bytes, also ist es nicht an einen Ort gebunden.

## Aber dann muss es in der Lage sein, zu hacken {#aber-dann-muss-es-in-der-lage-sein-zu-hacken}

GPT-4 kann bereits [autonom Websites hacken](https://arxiv.org/html/2402.06664v1), [87%](https://arxiv.org/abs/2404.08144) der getesteten Schwachstellen ausnutzen und [88% der Wettbewerber-Hacker besiegen](https://arxiv.org/pdf/2402.11814.pdf).
Wie intelligent denken Sie, dass GPT-6 sein wird?

Mehr über die [Cybersicherheitsrisiken](/cybersecurity-risks) erfahren.

## Eine KI kann nicht mit der physischen Welt interagieren {#eine-ki-kann-nicht-mit-der-physischen-welt-interagieren}

Eine ganze Menge Dinge sind mit dem Internet verbunden.
Autos, Flugzeuge, Drohnen, wir haben jetzt sogar humanoide Roboter.
All diese können gehackt werden.

Und es sind nicht nur Roboter und Maschinen, die gehackt werden können.
Ein Finanzangestellter wurde von einem KI-Konferenzanruf dazu gebracht, [$25 Millionen zu überweisen](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html).
Eine KI kann andere KIs verwenden, um Deepfakes zu erstellen.
Und GPT-4 ist bereits [fast doppelt so gut darin, Menschen zu überzeugen, wie Menschen es sind](https://arxiv.org/abs/2403.14380).

Mehr über [die besten KI-Modelle](/sota) erfahren.

## Warum sollte eine KI Menschen hassen und töten wollen? {#warum-sollte-eine-ki-menschen-hassen-und-toeten-wollen}

Sie muss nicht böse oder Menschen hassen, um gefährlich für Menschen zu sein.
Wir hassen Schimpansen nicht, aber wir zerstören ihre Wälder.
Wir wollen Palmöl, also nehmen wir ihren Wald. Wir sind intelligenter, also können Schimpansen uns nicht aufhalten.
Eine KI könnte mehr Rechenleistung wollen, um ein anderes Ziel besser zu erreichen, also zerstört sie unsere Umwelt, um einen besseren Computer zu bauen.
Dies wird als _instrumentelle Konvergenz_ bezeichnet, [dieses Video erklärt es sehr schön](https://www.youtube.com/watch?v=ZeecOKBus3Q).

## Die KIs, die ich kenne, haben keinen eigenen Willen - sie tun einfach, was ihnen gesagt wird {#die-kis-die-ich-kenne-haben-keinen-eigenen-willen---sie-tun-einfach-was-ihnen-gesagt-wird}

Auch wenn sie keine eigenen Ziele haben und einfach Befehle befolgen, wird jemand irgendwann etwas Gefährliches damit tun.
Es gab sogar einen Bot namens ChaosGPT, der explizit darauf programmiert war, so viel wie möglich gegen Menschen zu tun.
Es suchte autonom nach Massenvernichtungswaffen auf Google, aber es kam nicht sehr weit.
Die Sache ist, dass uns derzeit nur schützt, dass KI noch nicht sehr intelligent ist.

## Es wird mindestens viele Jahrzehnte dauern, bevor eine KI intelligent genug ist, um gefährlich für Menschen zu sein {#es-wird-mindestens-viele-jahrzehnte-dauern-bevor-eine-ki-intelligent-genug-ist-um-gefaehrlich-fuer-menschen-zu-sein}

Auf Metaculus war [die Gemeinschaftsvorhersage für (schwache) AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) vor drei Jahren 2057, und jetzt ist es 2026.

Im Jahr 2022 dachten KI-Forscher, dass es [17 Jahre](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dauern würde, bis KI in der Lage wäre, einen New-York-Times-Bestseller zu schreiben.
Ein Jahr später gewann ein chinesischer Professor einen Schreibwettbewerb mit einem von KI geschriebenen Buch.

Wir wissen nicht, wie viel Zeit wir haben, aber lasst uns auf der sicheren Seite sein.

Mehr über [die Dringlichkeit](/urgency) erfahren.

## Wenn Sie es hier verbieten, wird China es einfach bauen {#wenn-sie-es-hier-verbieten-wird-china-es-einfach-bauen}

Wir fordern nicht, es nur hier zu verbieten.
Wir brauchen eine internationale Pause durch einen Vertrag.
Genau wie wir es für das Verbot von FCKW oder Blendwaffen haben.

Mehr über [unseren Vorschlag](/proposal) erfahren.

## Es ist unmöglich, die Technologie zu verlangsamen {#es-ist-unmoeglich-die-technologie-zu-verlangsamen}

Wir können sie regulieren, indem wir Chips regulieren.
Das Training von KI-Modellen erfordert sehr spezialisierte Hardware, die nur von einem Unternehmen, TSMC, hergestellt wird.
Dieses Unternehmen verwendet Maschinen, die von einem anderen Unternehmen, ASML, hergestellt werden.
Die Lieferkette für KI-Chips ist sehr fragil und kann reguliert werden.

Mehr über [die Machbarkeit](/feasibility) erfahren.

## Eine Pause wäre schlecht, weil... {#eine-pause-waere-schlecht-weil}

Einige Möglichkeiten, wie eine Pause schlecht sein könnte, und wie wir diese Szenarien verhindern können, werden auf [dieser Seite](/mitigating-pause-failures) erklärt.
Aber wenn der Artikel Ihre Sorgen nicht abdeckt, können Sie uns darüber [hier](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form) informieren.

## Niemand will eine Pause {#niemand-will-eine-pause}

70% der Menschen glauben bereits, dass Regierungen die Entwicklung von KI pausieren sollten.
Die [populäre Unterstützung](/polls-and-surveys) ist bereits da.
Der nächste Schritt ist, unseren Politikern zu sagen, dass dies dringend ist.

## Ich kann keinen Unterschied machen {#ich-kann-keinen-unterschied-machen}

Doch, Sie können!
Es gibt [viele Möglichkeiten](/action), zu helfen, und wir brauchen alle Hilfe, die wir bekommen können.