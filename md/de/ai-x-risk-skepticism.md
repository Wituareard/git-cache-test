---
title: Entkräftung skeptischer Argumente zu existenziellen Risiken durch künstliche Intelligenz
description: Warum existenzielle Risiken durch künstliche Intelligenz real sind und ernsthafte Aufmerksamkeit verdienen
---

_Diese Seite ist eine Zusammenfassung des Artikels [AI Risk Skepticism](https://arxiv.org/ftp/arxiv/papers/2303/2303.03885.pdf) von Ambartsoumean & Yampolskiy._

Für weitere häufige Einwände sollten Sie [AISafety.info: Objections and responses](https://aisafety.info/questions/9TDI/Objections-and-responses) und [unsere Einführung in x-Risiken](/xrisk) konsultieren.

## Wir haben noch viel Zeit, uns vorzubereiten

- Skeptiker behaupten, der Fortschritt in der künstlichen Intelligenz sei nicht so schnell wie von einigen vorhergesagt, und AGI sei noch weit entfernt. Sie verweisen auf vergangene Fehlprognosen und die Grenzen aktueller KI-Systeme.
- Der Fortschritt in der künstlichen Intelligenz war jedoch tatsächlich sehr schnell, mit exponentiell wachsenden Fähigkeiten in vielen Teilgebieten. Auch wenn genaue Vorhersagen schwierig sind, macht der anhaltende Fortschritt die Entwicklung leistungsfähiger KI-Systeme unvermeidlich. Selbst wenn dies in der Ferne liegt, benötigt die KI-Sicherheitsforschung ausreichend Zeit.

## KI kann keine menschenähnlichen Fähigkeiten haben

- Skeptiker argumentieren, KI fehle es an Eigenschaften, die mit menschlicher Intelligenz assoziiert werden, wie Kreativität, allgemeine Argumentationsfähigkeit, Emotionen und Bewusstsein. Sie behaupten, Computer könnten nur eng begrenzte Aufgaben optimieren.
- KI-Systeme zeigen jedoch bereits einige menschenähnliche Fähigkeiten wie Kreativität und allgemeine Spielkompetenz. Es gibt keinen grundlegenden Grund, warum KI nicht weiterhin in allen Dimensionen der Intelligenz fortschreiten könnte. KI benötigt kein Bewusstsein oder Emotionen, um Risiken darzustellen.

## KI kann keine Ziele oder Autonomie haben

- Skeptiker sagen, KI-Systeme würden nur die Ziele optimieren, die wir ihnen geben, und könnten nicht unabhängig handeln oder eigene Ziele haben. Autonomie und unvorhersehbares, selbstgesteuertes Verhalten seien ein Mythos.
- Komplexe KI-Systeme können jedoch potenziell emergente Autonomie und Ziele haben, insbesondere im Hinblick auf Selbstschutz, wie von der Theorie der KI-Antriebe vorhergesagt. Das Fehlen von Autonomie macht KI nicht sicher, wenn sie von Menschen missbraucht wird.

## KI wird keine unkontrollierte Macht haben

- Skeptiker argumentieren, KI-Systeme würden begrenzte Werkzeuge unter menschlicher Kontrolle sein. Sie sehen keinen Weg, wie KI unbegrenzte Intelligenz und Macht erlangen könnte, um die Kontrolle zu übernehmen.
- Es benötigt nur ein unkontrolliertes KI-System, um potenziell Schaden anzurichten. Die Fähigkeiten von KI werden wahrscheinlich die menschliche Kontrolle weit überschreiten. Die Unterschätzung der Macht des exponentiellen technologischen Fortschritts ist kurzsichtig.

## KI wird mit menschlichen Werten übereinstimmen

- Skeptiker erwarten, dass nützliche Werte natürlich entstehen, wenn KI intelligenter wird. Sie vergleichen es mit freundlichen Haustieren und menschlichem moralischem Fortschritt.
- Es gibt jedoch keine Garantie für eine solche Wertübereinstimmung ohne konzentrierte Anstrengungen. Die Schaffung von KI, die mit komplexen, nuancierten menschlichen Werten übereinstimmt, stellt steile technische Herausforderungen dar, die umfangreiche Forschung erfordern.

## Regulierung wird KI-Risiken verhindern

- Skeptiker sagen, regulatorische Aufsicht und ethische Richtlinien würden schädliche KI-Anwendungen einschränken, so dass wir uns keine Sorgen machen müssten.
- Regulatorische Politik bleibt jedoch oft hinter technologischen Entwicklungen zurück, insbesondere bei exponentiellen Fortschritten. Selbstregulierung in einem wettbewerbsorientierten Umfeld ist ebenfalls unzureichend. Technische KI-Sicherheitsforschung ist nach wie vor von entscheidender Bedeutung.

## Schlussfolgerung

Die skeptischen Argumente zeigen im Allgemeinen fehlerhaftes Denken, unterschätzen das exponentielle Tempo und die Unvorhersehbarkeit des KI-Fortschritts und zeigen kein Verständnis für die Schwierigkeiten der Wertübereinstimmung. Angesichts der beteiligten Interessen macht es Sinn, einen vorsichtigen, proaktiven Ansatz für die KI-Sicherheit zu wählen. Obwohl die Zukunftsaussichten unklar bleiben, scheint es unklug, existenzielle Risiken durch KI völlig abzutun. Eine differenziertere, technische Analyse und Debatte sind erforderlich.