

---
title: PauseAI-Protest in Den Haag, Niederlande - 11. August
description: Wir organisieren einen Protest, um eine Pause bei der Entwicklung gef√§hrlicher k√ºnstlicher Intelligenz zu fordern.
---
<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wir haben in Den Haag, Niederlande, protestiert, um unsere Regierung aufzufordern, die Minderung von KI-Risiken zu priorisieren. Wir hatten einige Reden, sprachen mit Menschen auf der Stra√üe, verteilten Flyer und hatten eine gute Zeit!<br><br>√úberpr√ºfen Sie die Pressemitteilung (EN + NL) f√ºr weitere Informationen: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">12. August 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI-Protest
- Wo: Wijnhaven, Den Haag
- Wann: 11. August 2023, 16:00 - 17:00

## Warum wir protestieren {#why-we-protest}

Die k√ºnstliche Intelligenz entwickelt sich rasant und wird immer leistungsf√§higer - viel schneller als die meisten KI-Wissenschaftler vorhergesagt haben.
Milliarden werden in KI-F√§higkeiten investiert, und die Ergebnisse sind beeindruckend.
Neue Modelle √ºberbieten Menschen in vielen Bereichen.
Mit zunehmenden F√§higkeiten steigen auch die Risiken.
Wissenschaftler warnen sogar davor, dass KI m√∂glicherweise die Menschheit gef√§hrden k√∂nnte.

Unsere Politiker nehmen dieses Thema nicht ernst genug.
Wir brauchen unsere F√ºhrer, um diese Warnungen zu h√∂ren und Ma√ünahmen zu ergreifen, um diese Entwicklung zu stoppen.

Wir fordern die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI anzusetzen
- Die Vorbereitungen f√ºr den KI-Gipfel sp√§ter in diesem Jahr zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen

## Agenda {#agenda}

- 12:00 - 16:00 Vorbereitung von Schildern im Workshop (nur f√ºr die echten Enthusiasten, kontaktieren Sie uns, wenn Sie dabei sein m√∂chten!)
- 16:00 Reden + Protest + Flyerverteilung
- 17:00 Getr√§nke in einer nahegelegenen Kneipe

## Kontakt {#contact-4}

- Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io))

## Pressemitteilung (DE): PauseAI fordert niederl√§ndische Regierung auf, menschheitsbedrohende KI-Katastrophen zu verhindern {#press-release-en-pauseai-calls-on-dutch-government-to-prevent-human-threatening-ai-related-disasters}

Am Freitag, den 11. August, um 16:00 Uhr, wird eine Gruppe besorgter B√ºrger unter dem Namen [PauseAI](http://pauseai.info) vor dem Innenministerium zusammenkommen, um die Entwicklungen im Bereich der (generativen) KI anzusprechen. Sie fordern die Regierung auf, Ma√ünahmen zu ergreifen, um die Entwicklung leistungsf√§higer und m√∂glicherweise gef√§hrlicher k√ºnstlicher Intelligenz zu pausieren.

Bisher hat die niederl√§ndische Regierung keine Schritte unternommen, um die existenzielle Bedrohung durch KI zu adressieren. Es gab keine Reaktion auf Warnungen und Stellungnahmen von Organisationen wie den [UN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), dem Premierminister des [Vereinigten K√∂nigreichs](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (wo ein Gipfel zu diesem Thema f√ºr den Herbst geplant ist) und [KI-Experten](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), selbst nachdem eine [Motion](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) im Parlament zuvor in diesem Jahr zu solchen Ma√ünahmen aufgerufen hatte.

"Wissenschaftler schlagen Alarm: KI k√∂nnte das Ende der Menschheit bedeuten. Experten sch√§tzen die Wahrscheinlichkeit daf√ºr auf 30%. KI-Unternehmen rasen vorw√§rts und riskieren unser aller Leben, w√§hrend die Regulierung hoffnungslos hinterherhinkt." - Joep Meindertsma, CEO von Ontola und Gr√ºnder von PauseAI.

Die Sorgen √ºber die Risiken, die mit KI verbunden sind, wachsen weltweit rasant. Diese Woche ver√∂ffentlichte das Forschungsinstitut Axios die Ergebnisse einer Meinungsumfrage unter Einwohnern der Vereinigten Staaten, die ergab, dass 86% der Befragten besorgt √ºber katastrophale KI-Risiken sind.

"Die USA haben Senatsanh√∂rungen, bei denen KI-Experten dar√ºber sprechen, wie KI das Ende der Menschheit bedeuten k√∂nnte. Warum wird dieses Thema in der niederl√§ndischen Politik ignoriert? Insbesondere, da die Niederlande eine Schl√ºsselrolle in der Chip-Lieferkette spielen, dank ASML. Deshalb kann es auch eine Schl√ºsselrolle bei der KI-Regulierung spielen. Alle Leben stehen auf dem Spiel!" - Joep Meindertsma

PauseAI fordert die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI anzusetzen
- Die Vorbereitungen f√ºr den vorgeschlagenen KI-Gipfel im Vereinigten K√∂nigreich sp√§ter in diesem Jahr zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen, einschlie√ülich einer sogenannten KI-Pause.

F√ºr weitere Informationen besuchen Sie [PauseAI.info](http://pauseai.info). Kontakt: Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io)) & Ruben Dieleman ([E-Mail](mailto:ruben@existentialriskobservatory.org))