---
title: PauseAI-Protest in Den Haag, Niederlande - 11. August
description: Wir organisieren einen Protest, um eine Pause bei der Entwicklung gef√§hrlicher KI zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested in The Hague, Netherlands to ask our government to prioritise mitigation of AI risks. We had a few speeches, talked to people on the streets, handed out flyers and had a good time!<br><br>Check out the press release (EN + NL) for more information: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">August 12, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI-Protest
- Wo: Wijnhaven, Den Haag
- Wann: 11. August 2023, 16:00 - 17:00

## Warum wir protestieren

KI entwickelt sich rasant und wird immer leistungsf√§higer, weit schneller als fast jeder KI-Wissenschaftler vorhergesagt hat.
Milliarden werden in KI-F√§higkeiten investiert, und die Ergebnisse sind atemberaubend.
Neue Modelle √ºberbieten Menschen in vielen Bereichen.
Mit zunehmenden F√§higkeiten steigen auch die Risiken.
Wissenschaftler warnen sogar davor, dass KI m√∂glicherweise die Menschheit zerst√∂ren k√∂nnte.

Unsere Politiker nehmen dieses Thema nicht ann√§hernd so ernst, wie sie sollten.
Wir brauchen unsere F√ºhrer, um auf diese Warnungen zu h√∂ren.
Wir brauchen sie, um Ma√ünahmen zu ergreifen und eine Pause einzulegen, um dieses Selbstmordrennen zu stoppen.

Wir fordern die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Parlamentsdebatt √ºber die existenziellen Risiken von KI anzusetzen
- Die Vorbereitungen f√ºr den KI-Gipfel sp√§ter in diesem Jahr zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- Internationale Zusammenarbeit zu f√∂rdern, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen

## Agenda

- 12:00 - 16:00 Vorbereitung von Schildern im Workshop (nur f√ºr die echten Enthusiasten, kontaktieren Sie uns, wenn Sie dabei sein m√∂chten!)
- 16:00 Reden + Protest + Flyerverteilung
- 17:00 Getr√§nke in einer nahegelegenen Kneipe

## Kontakt

- Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io))

## Pressemitteilung (EN): PauseAI fordert die niederl√§ndische Regierung auf, menschheitsbedrohende KI-Katastrophen zu verhindern

Am Freitag, den 11. August, um 16:00 Uhr, wird eine Gruppe besorgter B√ºrger unter dem Namen [PauseAI](http://pauseai.info) vor dem Innenministerium zusammenkommen, um die Entwicklungen im Bereich der (generativen) KI anzusprechen. Sie fordern die Regierung auf, Ma√ünahmen zu ergreifen, um die Entwicklung leistungsf√§higer und m√∂glicherweise gef√§hrlicher k√ºnstlicher Intelligenz zu pausieren.

Bisher hat die niederl√§ndische Regierung keine Schritte unternommen, um die existenzielle Bedrohung durch KI zu bek√§mpfen. Es gab keine Reaktion auf Warnungen und Erkl√§rungen von Organisationen wie den [UN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), dem Premierminister des [Vereinigten K√∂nigreichs](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (wo ein Gipfel zu diesem Thema f√ºr den Herbst geplant ist) und [KI-Experten](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), selbst nachdem eine [Motion](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) im Parlament zu solchen Ma√ünahmen aufgerufen hatte.

"[Wissenschaftler](https://www.safe.ai/statement-on-ai-risk) schlagen Alarm: KI k√∂nnte das Ende der Menschheit bedeuten. Experten sch√§tzen die Wahrscheinlichkeit sogar auf [30%](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). KI-Unternehmen rasen vorw√§rts und riskieren unser aller Leben, w√§hrend die Regulierung hoffnungslos hinterherhinkt." - Joep Meindertsma, CEO von Ontola und Gr√ºnder von PauseAI.

Die Sorgen √ºber die Risiken, die mit KI verbunden sind, wachsen weltweit rasant. Diese Woche ver√∂ffentlichte das Forschungsinstitut Axios die Ergebnisse einer Meinungsumfrage unter Einwohnern der Vereinigten Staaten, die zeigte, dass 86% der Befragten besorgt √ºber katastrophale KI-Risiken sind.

"Die USA haben Senatsanh√∂rungen, bei denen