

---
title: PauseAI-Protest in Den Haag, Niederlande - 11. August
description: Wir organisieren einen Protest, um eine Pause bei der Entwicklung gef√§hrlicher k√ºnstlicher Intelligenz zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested in The Hague, Netherlands to ask our government to prioritise mitigation of AI risks. We had a few speeches, talked to people on the streets, handed out flyers and had a good time!<br><br>Check out the press release (EN + NL) for more information: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">August 12, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI-Protest
- Wo: Wijnhaven, Den Haag
- Wann: 11. August 2023, 16:00 - 17:00

## Warum wir protestieren {#why-we-protest}

K√ºnstliche Intelligenz entwickelt sich rasant und weit schneller als fast jeder KI-Wissenschaftler vorhergesagt hat.
Milliarden werden in KI-F√§higkeiten investiert, und die Ergebnisse sind atemberaubend.
Neue Modelle √ºberbieten Menschen in vielen Bereichen.
Mit zunehmenden F√§higkeiten steigen auch die Risiken.
Wissenschaftler warnen sogar davor, dass KI die Menschheit ausl√∂schen k√∂nnte.

Unsere Politiker nehmen dieses Thema nicht ann√§hernd so ernst, wie sie sollten.
Wir brauchen unsere F√ºhrer, um diese Warnungen zu h√∂ren.
Wir brauchen sie, um Ma√ünahmen zu ergreifen und eine Pause einzulegen, um dieses Selbstmordrennen zu stoppen.

Wir fordern die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI zu f√ºhren
- Die Vorbereitungen f√ºr den KI-Gipfel sp√§ter in diesem Jahr zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen

## Agenda {#agenda}

- 12:00 - 16:00 Vorbereitung von Schildern im Workshop (nur f√ºr die echten Enthusiasten, kontaktieren Sie uns, wenn Sie dabei sein m√∂chten!)
- 16:00 Reden + Protest + Flyerverteilung
- 17:00 Getr√§nke in einer nahegelegenen Kneipe

## Kontakt {#contact}

- Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io))

## Pressemitteilung (EN): PauseAI fordert niederl√§ndische Regierung auf, menschheitsbedrohende KI-Katastrophen zu verhindern {#press-release-en-pauseai-calls-on-dutch-government-to-prevent-human-threatening-ai-related-disasters}

Am Freitag, den 11. August, um 16:00 Uhr, wird eine Gruppe besorgter B√ºrger unter dem Namen [PauseAI](http://pauseai.info) vor dem Innenministerium zusammenkommen, um die Entwicklungen im Bereich der (generativen) KI anzusprechen. Sie fordern die Regierung auf, Ma√ünahmen zu ergreifen, um die Entwicklung von leistungsf√§higer und potenziell gef√§hrlicher k√ºnstlicher Intelligenz zu pausieren.

Bisher hat die niederl√§ndische Regierung keine Schritte unternommen, um die existenzielle Bedrohung durch KI zu bek√§mpfen. Es gab keine Reaktion auf Warnungen und Erkl√§rungen von Organisationen wie den [UN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), dem Premierminister des [Vereinigten K√∂nigreichs](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (wo ein Gipfel zu diesem Thema f√ºr den Herbst geplant ist) und [KI-Experten](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), selbst nachdem eine [Motion](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) im Parlament zuvor in diesem Jahr zu solchen Ma√ünahmen aufgerufen hatte.

"[Wissenschaftler](https://www.safe.ai/statement-on-ai-risk) schlagen Alarm: KI k√∂nnte das Ende der Menschheit bedeuten. Experten sch√§tzen die Wahrscheinlichkeit sogar auf [30%](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). KI-Unternehmen rasen vorw√§rts und riskieren unser aller Leben, w√§hrend die Regulierung hoffnungslos hinterherhinkt." - Joep Meindertsma, CEO von Ontola und Gr√ºnder von PauseAI.

Die Sorgen √ºber die Risiken von KI wachsen weltweit rasant. Diese Woche ver√∂ffentlichte das Forschungsinstitut Axios die Ergebnisse einer Meinungsumfrage unter Einwohnern der Vereinigten Staaten, die ergab, dass 86% der Befragten besorgt √ºber katastrophale KI-Risiken sind.

"Die USA haben Senatsanh√∂rungen, bei denen KI-Experten dar√ºber sprechen, wie KI das Ende der Menschheit bedeuten k√∂nnte. Warum wird dieses Thema in der niederl√§ndischen Politik ignoriert? Insbesondere, da die Niederlande eine Schl√ºsselrolle in der Chip-Lieferkette spielen, dank ASML. Deshalb kann es auch eine Schl√ºsselrolle bei der KI-Regulierung spielen. Alle Leben stehen auf dem Spiel!" - Joep Meindertsma

PauseAI fordert die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI zu f√ºhren
- Die Vorbereitungen f√ºr den vorgeschlagenen KI-Gipfel im Vereinigten K√∂nigreich sp√§ter in diesem Jahr zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen, einschlie√ülich einer sogenannten KI-Pause.

F√ºr weitere Informationen besuchen Sie [PauseAI.info](http://pauseai.info). Kontakt: Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io)) & Ruben Dieleman ([E-Mail](mailto:ruben@existentialriskobservatory.org))

## Pressemitteilung (NL): PauseAI roept overheid op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen {#press-release-nl-pauseai-roept-overheid-op-tot-het-voorkomen-van-mensbedreigende-ai-gerelateerde-rampen}

Op vrijdag 11 augustus om 16.00 komt een groep mensen samen die zich zorgen maken over de ontwikkelingen op het gebied van (generatieve) AI bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info). Zij roepen de regering op zich in te spannen voor een pauze van de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie.

Tot nu toe heeft de Nederlandse regering echter geen actie ondernomen tegen de existenti√´le bedreiging van AI . Er is nog niet [gereageerd](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648) op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075088560508284928), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie). Ook niet nadat eerder dit jaar een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer daartoe aanspoorde.

"[Wetenschappers](https://www.safe.ai/statement-on-ai-risk) trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). AI bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achter blijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit [bleek](https://www.axios.com/2023/08/09/ai-voters-trust-government-regulation) dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI safety-experts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io)) & Ruben Dieleman ([E-Mail](mailto:ruben@existentialriskobservatory.org))