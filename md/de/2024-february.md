

---
title: PauseAI / Keine AGI-Demonstration @ OpenAI San Francisco - 12. Februar 2024
description: Wir organisieren eine Demonstration, um eine Pause bei der Entwicklung gefährlicher KI zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- PauseAI-Demonstration
- Wo: San Francisco, OpenAI-Hauptquartier
- Wann: 12. Februar 2024, 16:30 - 18:00 Uhr
- [Facebook-Event](https://fb.me/e/78BzWmaaj)
- [Website](https://openaiprotest.com/)

Andere internationale Orte / Zeiten:
UK (genauer Ort noch nicht bekannt) / 16:00 Uhr GMT

## Warum wir gegen OpenAI demonstrieren {#why-we-are-protesting-openai}

OpenAI versucht, eine KI zu entwickeln, die intelligenter ist als Menschen.
Hunderte von Wissenschaftlern warnen davor, dass dies das Ende der Menschheit bedeuten könnte.
Deswegen haben über 33.000 Menschen den Pause-Brief unterzeichnet, in dem sie Unternehmen wie OpenAI auffordern, ihre Forschung zu stoppen.
Sogar Sam Altman, der CEO von OpenAI, hat gesagt, dass man die Notbremse ziehen sollte, wenn "KI-Modelle auf Weisen verbessert werden, die wir nicht vollständig verstehen".
In einem anderen Interview nannte Sam die Vorhersage von Fähigkeiten ein "unterhaltsames Ratespiel" für OpenAI-Mitarbeiter.
Mit anderen Worten: Selbst OpenAI versteht nicht, wie ihre Modelle verbessert werden.
Es ist Zeit, die Notbremse zu ziehen.

## Schließt euch uns an und sagt OpenAI: "Hört auf, mit dem Pentagon zusammenzuarbeiten!" {#join-us-and-tell-openai-stop-working-with-the-pentagon}

Am 10. Januar hat OpenAI ohne Ankündigung die Sprache in seiner Nutzungsrichtlinie gelöscht, die besagte, dass OpenAI nicht zulässt, dass seine Modelle für "Aktivitäten mit hohem Risiko" wie "Militär und Kriegsführung" verwendet werden. Dann berichtete TIME am 17. Januar, dass OpenAI das Pentagon als Kunden aufnehmen würde. Am 12. Februar werden wir OpenAI auffordern, seine Beziehung zum Pentagon zu beenden und keine militärischen Kunden aufzunehmen. Wenn ihre ethischen und Sicherheitsgrenzen aus Bequemlichkeit revidiert werden können, können sie nicht vertrauenswürdig sein.

KI wird rapide immer leistungsfähiger, viel schneller als fast jeder KI-Wissenschaftler vorhergesagt hat. Milliarden werden in KI-Fähigkeiten investiert, und die Ergebnisse sind atemberaubend. Neue Modelle überbieten Menschen in vielen Bereichen. Mit zunehmenden Fähigkeiten steigen auch die Risiken. Wissenschaftler warnen sogar davor, dass KI die Menschheit zerstören könnte.

Laut ihrer Satzung ist "OpenAIs Mission, sicherzustellen, dass künstliche allgemeine Intelligenz (AGI) - mit der wir hochautonome Systeme meinen, die Menschen bei allen wirtschaftlich wertvollen Arbeiten überbieten - allen Menschen zugutekommt". Aber viele Menschen schätzen ihre Arbeit und finden Sinn darin, und daher wollen sie nicht, dass ihre Jobs von einer AGI übernommen werden. Was der Protest-Mitorganisator Sam Kirchner von No AGI den "psychologischen Bedrohung" nennt, gilt auch, wenn AGI uns nicht tötet.

## Kontakt {#contact-6}

- Holly Elmore ([Twitter](https://twitter.com/ilex_ulmus))
- Sam Kirchner ([Twitter](https://twitter.com/No_AGI_))

## Medienberichterstattung {#media-coverage}

- [Bloomberg](https://www.bloomberg.com/news/newsletters/2024-02-13/ai-protest-at-openai-hq-in-san-francisco-focuses-on-military-work)
- [ReadWrite](https://readwrite.com/stop-working-with-pentagon-openai-staff-face-protests/)
- [VentureBeat](https://venturebeat.com/ai/protesters-gather-outside-openai-office-opposing-military-ai-and-agi/)

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">From the protest yesterday at OpenAI HQ, covered in Bloomberg: <a href="https://t.co/sgp1KFoFPs">https://t.co/sgp1KFoFPs</a> <a href="https://t.co/N6fHGIlOYm">pic.twitter.com/N6fHGIlOYm</a></p>&mdash; PauseAI US (@pauseaius) <a href="https://twitter.com/pauseaius/status/1757604719047114786?ref_src=twsrc%5Etfw">February 14, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>