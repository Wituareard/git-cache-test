

---
title: PauseAI-Protest bei Bletchley Park - 1. November
description: Wir organisieren einen Protest bei Bletchley Park w√§hrend des KI-Sicherheitsgipfels
---
<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook-Event](https://www.facebook.com/events/347499967619516/347499967619516)
- [Anmelden](https://www.mixily.com/event/4419031774197158693)

![KI-Sicherheitsgipfel-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Das Vereinigte K√∂nigreich ist auf dem richtigen Weg. Es anerkennt praktisch jedes Risiko, das von k√ºnstlicher Intelligenz (KI) ausgeht, investiert 100 Millionen Pfund in KI-Sicherheit, organisiert einen Gipfel und k√ºndigt ein KI-Sicherheitsinstitut an.

Doch das ist noch nicht genug. F√ºhrende KI-Experten wie Geoffrey Hinton und Yoshua Bengio haben deutlich gemacht: Wir wissen nicht, wie man eine √ºbermenschliche KI kontrolliert. Wenn wir dies falsch machen, ist das Aussterben der Menschheit eine sehr reale M√∂glichkeit. Deshalb fordern wir eine sofortige und unbefristete Pause bei der Forschung und Entwicklung von KI.

Am 1. und 2. November findet der erste KI-Sicherheitsgipfel im Vereinigten K√∂nigreich statt.
Dies ist eine einmalige Gelegenheit, die ersten Schritte in Richtung sinnvoller internationaler KI-Sicherheitsregulierung zu unternehmen.

Es scheint jedoch, dass die Verantwortlichen nicht das Gef√ºhl haben, [wie wenig Zeit uns noch bleibt](/urgency).
Der Organisator und Vertreter des Premierministers f√ºr den KI-Sicherheitsgipfel, Matt Clifford, hat [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" einf√ºhren wird.
Das letzte Woche ver√∂ffentlichte KI-Sicherheitspapier [deutet darauf hin](https://twitter.com/PauseAI/status/1717474950557090151), dass das Vereinigte K√∂nigreich zuversichtlich ist, dass wir noch viele Jahre Zeit haben, uns auf die Entwicklung einer allgemeinen KI vorzubereiten.
Doch das Vereinigte K√∂nigreich st√ºtzt sich auf Sch√§tzungen aus dem letzten Jahr, bevor ChatGPT ver√∂ffentlicht wurde.
Auf Metaculus ist die Vorhersage des Datums der ersten allgemeinen KI [von 2047 auf 2026 gesunken](https://metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) in den letzten 18 Monaten!

**Wir brauchen unsere F√ºhrer, die auf der Seite der Vorsicht erraten und eine Pause einleiten.**

## Was wir fordern {#what-we-ask}

- **Politiker**: Erlauben Sie Unternehmen nicht, eine Superintelligenz zu entwickeln. Regulierungen und Hardware-Beschr√§nkungen sollten vor dem Beginn der Forschung gelten, da es sehr schwierig ist, die Verbreitung einer neuen F√§higkeit zu kontrollieren, sobald sie erreicht wurde. Wir k√∂nnen es nicht zulassen, dass Unternehmen potenziell weltbedrohende KI-Modelle entwickeln. Die Erstellung von Gesetzen ist schwierig und dauert lange, aber wir haben m√∂glicherweise nicht so viel Zeit, also arbeiten Sie, als ob Ihr Leben davon abh√§ngt. Denn das tut es.
- **Unternehmen**: Viele von Ihnen haben Angst vor dem, was KI tun kann, aber Sie sind in einem Wettlauf gefangen. Also seien Sie laut und unterst√ºtzen Sie eine Pause im Prinzip. Wenn Sie Erkl√§rungen unterzeichnen, dass diese Technologie uns alle t√∂ten k√∂nnte, zeigen Sie der Welt, dass Sie lieber nicht daran arbeiten w√ºrden, wenn es eine gangbare Option w√§re.
- **Gipfel-Teilnehmer**: Priorisieren Sie Sicherheit vor wirtschaftlichem Wachstum. Wir wissen, dass KI unsere L√§nder reicher machen kann, aber das ist nicht der Grund, warum Sie hier sind. Seien Sie der Erwachsene im Raum.

F√ºr unseren gesamten Vorschlag siehe [hier](/proposal).

## Pressemitteilung {#press-release-3}

_ZUR VER√ñFFENTLICHUNG AM 1. NOVEMBER 2023_

### Protest w√§hrend des KI-Sicherheitsgipfels fordert ein Ende der gef√§hrlichen KI-Entwicklung {#protest-during-ai-safety-summit-calls-for-a-halt-to-dangerous-ai-development}

**1. November:** [**PauseAI**](https://pauseai.info/) **veranstaltet einen Protest in Bletchley Park w√§hrend des KI-Sicherheitsgipfels und fordert Politiker und Gipfel-Teilnehmer auf, die Entwicklung einer superintelligenten KI sofort zu verbieten.**

Im M√§rz dieses Jahres unterzeichneten viele bekannte Pers√∂nlichkeiten [einen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.), in dem sie einen sechsmonatigen Stopp der Entwicklung ihrer KI-Modelle forderten. Im Mai unterzeichneten Hunderte von KI-Wissenschaftlern [eine Erkl√§rung](https://www.safe.ai/statement-on-ai-risk), in der es hei√üt: "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorit√§t neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."

J√ºngste Umfragen in [den USA](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) und [dem Vereinigten K√∂nigreich](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693) haben gezeigt, dass eine gro√üe Mehrheit der Menschen will, dass die Regierung eingreift und die Entwicklung einer superintelligenten KI verhindert. Bisher [wurden keine Gesetzesentw√ºrfe](https://twitter.com/PauseAI/status/1706605169608159458) vorgeschlagen, die dies tun w√ºrden.

Am 1. und 2. November findet der erste KI-Sicherheitsgipfel in Bletchley Park, UK, statt.
Der Gipfel wird von f√ºhrenden KI-Wissenschaftlern, Politikern und Industrie-Executives besucht.
Dies ist eine einmalige Gelegenheit, die ersten Schritte in Richtung internationaler KI-Sicherheitsregulierung zu unternehmen.
Doch das Vereinigte K√∂nigreich plant nicht, diese Gelegenheit zu nutzen, um starke KI-Regulierungen einzuf√ºhren.
Der Organisator und Vertreter des Premierministers f√ºr den KI-Sicherheitsgipfel, Matt Clifford, hat [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" einf√ºhren wird.

"Wir freuen uns, dass das Vereinigte K√∂nigreich die KI-Sicherheit vorantreibt und internationale F√ºhrung zeigt", sagt Joep Meindertsma, Direktor von PauseAI. "Aber wir sehen nicht das Ma√ü an Dringlichkeit, das es verdient. Im Jahr 2020 sagten Prognostiker [voraus](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/), dass die Ankunft von KI auf menschlichem Niveau im Jahr 2055 erfolgen w√ºrde. Heute ist die [durchschnittliche Prognose](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. Wir k√∂nnen es uns nicht leisten, das Risiko zu untersch√§tzen. Wir brauchen unsere Politiker, die auf der Seite der Vorsicht erraten. Jedes einzelne Leben ist in Gefahr. Kein Unternehmen sollte eine Superintelligenz entwickeln d√ºrfen."

### Medien {#media-2}

[Der Protest wurde in NewScientist berichtet.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="de" dir="ltr">Wir haben w√§hrend des KI-Sicherheitsgipfels in Bletchley Park protestiert, um unsere F√ºhrer aufzufordern, die Entwicklung von superintelligenter KI zu stoppen. <br><br>üßµ <a href="https://t.co/WbH1GuKqAS">pic.twitter.com/WbH1GuKqAS</a></p>&mdash; PauseAI ‚è∏ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1719740149905400128?ref_src=twsrc%5Etfw">1. November 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>