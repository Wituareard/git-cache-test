

---
title: PauseAI-Protest bei Bletchley Park - 1. November
description: Wir organisieren einen Protest bei Bletchley Park während des AI Safety Summit
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook-Event](https://www.facebook.com/events/347499967619516/347499967619516)
- [Anmelden](https://www.mixily.com/event/4419031774197158693)

![AI-Safety-Summit-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Das Vereinigte Königreich ist auf dem richtigen Weg. Es anerkennt praktisch jedes Risiko, das von künstlicher Intelligenz (KI) ausgeht, investiert 100 Millionen Pfund in KI-Sicherheit, organisiert einen Gipfel und kündigt ein KI-Sicherheitsinstitut an.

Doch gut ist nicht gut genug. Top-KI-Experten wie Geoffrey Hinton und Yoshua Bengio haben sehr deutlich gemacht: Wir wissen nicht, wie man eine übermenschliche KI kontrolliert. Wenn wir das falsch machen, ist das Aussterben der Menschheit eine sehr reale Möglichkeit. Deshalb fordern wir einen sofortigen und unbefristeten Stopp der Forschung und Entwicklung von KI-Systemen, die stärker sind als GPT-4.

Am 1. und 2. November findet der erste KI-Sicherheitsgipfel im Vereinigten Königreich statt.
Dies ist eine goldene Gelegenheit, die ersten Schritte in Richtung einer vernünftigen internationalen KI-Sicherheitsregulierung zu unternehmen.

Es scheint jedoch, dass die Verantwortlichen nicht das Gefühl haben, [wie wenig Zeit uns noch bleibt](/urgency).
Der Organisator und Vertreter des Premierministers für den KI-Sicherheitsgipfel, Matt Clifford, hat [erklärt](https://twitter.com/PauseAI/status/1709845853668553065), dass "ein Stopp der KI-Entwicklung jetzt verfrüht wäre", und dass er [nicht erwartet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" bringt.
Das letzte Woche veröffentlichte KI-Sicherheitspapier [deutet darauf hin](https://twitter.com/PauseAI/status/1717474950557090151), dass das Vereinigte Königreich zuversichtlich ist, dass wir noch viele Jahre Zeit haben, uns auf die Entwicklung einer allgemeinen KI vorzubereiten.
Doch das Vereinigte Königreich stützt sich auf Schätzungen vom letzten Jahr, bevor ChatGPT veröffentlicht wurde.
Auf Metaculus ist die Vorhersage des Datums der ersten allgemeinen KI [von 2047 auf 2026 gesunken](https://metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) in den letzten 18 Monaten!

**Wir brauchen unsere Führer, die auf der Seite der Vorsicht erraten und einen Stopp SOFORT umsetzen.**

## Was wir fordern

- **Politiker**: Erlauben Sie Unternehmen nicht, eine Superintelligenz zu entwickeln. Regulierungen und Hardware-Beschränkungen sollten vor dem Beginn der Forschung gelten, da es sehr schwierig ist, die Verbreitung einer neuen Fähigkeit zu kontrollieren, sobald sie erreicht wurde. Wir können es nicht zulassen, dass Unternehmen potenziell weltbedrohende KI-Modelle entwickeln. Die Erstellung von Gesetzen ist schwierig und dauert lange, aber wir haben möglicherweise nicht so viel Zeit, also arbeiten Sie, als ob Ihr Leben davon abhängt. Denn das tut es.
- **Unternehmen**: Viele von Ihnen haben Angst vor dem, was KI tun kann, aber Sie sind in einem Wettlauf gefangen. Also seien Sie laut und unterstützen Sie einen Stopp im Prinzip. Wenn Sie Erklärungen unterzeichnen, dass diese Technologie uns alle töten könnte, zeigen Sie der Welt, dass Sie lieber nicht daran arbeiten würden, wenn es eine gangbare Option wäre.
- **Gipfel-Teilnehmer**: Priorisieren Sie Sicherheit vor wirtschaftlichem Wachstum. Wir wissen, dass KI unsere Länder reicher machen kann, aber das ist nicht der Grund, warum Sie hier sind. Seien Sie der Erwachsene im Raum.

Für unseren gesamten Vorschlag siehe [hier](/proposal).

## Pressemitteilung

_ZUR VERÖFFENTLICHUNG AM 1. NOVEMBER 2023_

### Protest während des KI-Sicherheitsgipfels fordert Stopp der gefährlichen KI-Entwicklung

**1. November:** [**PauseAI**](https://pauseai.info/) **veranstaltet einen Protest in Bletchley Park während des KI-Sicherheitsgipfels und fordert Politiker und Gipfel-Teilnehmer auf, die Entwicklung von Superintelligenz sofort zu stoppen.**

Im März dieses Jahres unterzeichneten viele bekannte Persönlichkeiten [einen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.), in dem sie einen sechsmonatigen Stopp der Entwicklung von KI-Modellen forderten. Im Mai unterzeichneten Hunderte von KI-Wissenschaftlern [eine Erklärung](https://www.safe.ai/statement-on-ai-risk), in der es heißt: "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorität neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."

Aktuelle Umfragen in [den USA](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) und [dem Vereinigten Königreich](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693) haben gezeigt, dass eine große Mehrheit der Menschen will, dass die Regierung eingreift und die Entwicklung von Superintelligenz verhindert. Bisher gibt es jedoch [keine Gesetzesentwürfe](https://twitter.com/PauseAI/status/1706605169608159458), die dies tun würden.

Am 1. und 2. November findet der erste KI-Sicherheitsgipfel in Bletchley Park, UK, statt.
Der Gipfel wird von führenden KI-Wissenschaftlern, Politikern und Industrie-Executives besucht.
Dies ist eine einzigartige Gelegenheit, die ersten Schritte in Richtung einer internationalen KI-Sicherheitsregulierung zu unternehmen.
Der Organisator und Vertreter des Premierministers für den KI-Sicherheitsgipfel, Matt Clifford, hat jedoch [erklärt](https://twitter.com/PauseAI/status/1709845853668553065), dass "ein Stopp der KI-Entwicklung jetzt verfrüht wäre", und dass er [nicht erwartet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" bringt.

"Wir freuen uns, dass das Vereinigte Königreich die KI-Sicherheit vorantreibt und internationale Führung zeigt", sagt Joep Meindertsma, Direktor von PauseAI. "Aber wir sehen nicht das Maß an Dringlichkeit, das es verdient. Im Jahr 2020 sagten Prognostiker [voraus](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/), dass die Ankunft von menschenähnlicher KI im Jahr 2055 erfolgen würde. Heute ist die [durchschnittliche Prognose](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. Wir können es nicht riskieren, dass wir die Geschwindigkeit des Fortschritts unterschätzen. Wir brauchen unsere Politiker, die auf der Seite der Vorsicht erraten. Jedes einzelne Leben ist in Gefahr. Kein Unternehmen sollte in der Lage sein, eine Superintelligenz zu entwickeln."

### Medien

[Der Protest wurde in NewScientist besprochen.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wir haben während des KI-Sicherheitsgipfels in Bletchley Park protestiert, um unsere Führer aufzufordern, die Entwicklung von Superintelligenz zu stoppen. <br><br> <a href="https://t.co/WbH1GuKqAS">pic.twitter.com/WbH1GuKqAS</a></p>&mdash; PauseAI (@PauseAI) <a href="https://twitter.com/PauseAI/status/1719740149905400128?ref_src=twsrc%5Etfw">1. November 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>