---
title: PauseAI-Protest bei Bletchley Park - 1. November
description: Wir organisieren einen Protest bei Bletchley Park w√§hrend des AI Safety Summit
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook-Event](https://www.facebook.com/events/347499967619516/347499967619516)
- [Anmelden](https://www.mixily.com/event/4419031774197158693)

![AI-Safety-Summit-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Das Vereinigte K√∂nigreich ist auf dem richtigen Weg. Es anerkennt praktisch jedes Risiko, das von k√ºnstlicher Intelligenz (KI) ausgeht, investiert 100 Millionen Pfund in die Sicherheit von KI und organisiert einen Gipfel, auf dem ein Institut f√ºr KI-Sicherheit angek√ºndigt wird.

Doch gut ist nicht gut genug. Spitzen-Experten wie Geoffrey Hinton und Yoshua Bengio haben sehr deutlich gemacht: Wir wissen nicht, wie man eine √ºbermenschliche KI kontrolliert. Wenn wir das falsch machen, ist das Aussterben der Menschheit eine sehr reale M√∂glichkeit. Deshalb fordern wir eine sofortige und unbefristete Pause bei der Forschung und Entwicklung von KI.

Am 1. und 2. November findet im Vereinigten K√∂nigreich der erste AI Safety Summit statt.
Dies ist eine goldene Gelegenheit, die ersten Schritte in Richtung einer vern√ºnftigen internationalen Regulierung der KI-Sicherheit zu unternehmen.

Es scheint jedoch, dass die Verantwortlichen nicht das Gef√ºhl haben, [wie wenig Zeit uns noch bleibt](/urgency).
Der Organisator und Vertreter des Premierministers f√ºr den AI Safety Summit, Matt Clifford, hat [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" einf√ºhren wird.
Das letzte Woche ver√∂ffentlichte Papier zur KI-Sicherheit [deutet darauf hin](https://twitter.com/PauseAI/status/1717474950557090151), dass das Vereinigte K√∂nigreich zuversichtlich ist, dass wir noch viele Jahre Zeit haben, uns auf die Entwicklung einer allgemeinen k√ºnstlichen Intelligenz (AGI) vorzubereiten.
Doch das Vereinigte K√∂nigreich st√ºtzt sich auf Sch√§tzungen aus dem letzten Jahr, bevor ChatGPT ver√∂ffentlicht wurde.
Auf Metaculus ist die Vorhersage des Datums der ersten AGI [von 2047 auf 2026 gesunken](https://metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) in den letzten 18 Monaten!

**Wir brauchen unsere F√ºhrer, die auf der Seite der Vorsicht sind und eine Pause EINLEITEN.**

## Was wir fordern

- **Politiker**: Erlauben Sie Unternehmen nicht, eine Superintelligenz zu entwickeln. Regulierungen und Hardware-Einschr√§nkungen sollten vor dem Training gelten, da es sehr schwierig ist, die Verbreitung einer neuen F√§higkeit zu kontrollieren, sobald sie erreicht wurde. Wir k√∂nnen es nicht zulassen, dass Unternehmen potenziell weltbedrohende KI-Modelle trainieren. Die Erstellung von Gesetzen ist schwierig und dauert lange, aber wir haben m√∂glicherweise nicht so viel Zeit, also arbeiten Sie, als ob Ihr Leben davon abh√§ngt. Denn das tut es.
- **Unternehmen**: Viele von Ihnen haben Angst vor dem, was KI tun kann, aber Sie sind in einem Wettlauf gefangen. Also seien Sie laut und unterst√ºtzen Sie eine Pause im Prinzip. Wenn Sie Erkl√§rungen unterzeichnen, dass diese Technologie uns alle t√∂ten k√∂nnte, zeigen Sie der Welt, dass Sie lieber nicht daran arbeiten w√ºrden, wenn es eine gangbare Option w√§re.
- **Gipfel-Teilnehmer**: Priorisieren Sie Sicherheit gegen√ºber wirtschaftlichem Wachstum. Wir wissen, dass KI unsere L√§nder reicher machen kann, aber das ist nicht der Grund, warum Sie hier sind. Seien Sie die Erwachsenen im Raum.

F√ºr unseren gesamten Vorschlag siehe [hier](/proposal).

## Pressemitteilung

_ZUR VER√ñFFENTLICHUNG AM 1. NOVEMBER 2023_

### Protest w√§hrend des AI Safety Summit fordert ein Ende der gef√§hrlichen KI-Entwicklung

**1. November:** [**PauseAI**](https://pauseai.info/) **veranstaltet einen Protest in Bletchley Park w√§hrend des AI Safety Summit und fordert Politiker und Teilnehmer des Gipfels auf, die Entwicklung einer superintelligenten KI sofort zu verbieten.**

Im M√§rz dieses Jahres unterzeichneten viele bekannte Pers√∂nlichkeiten [einen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.), in dem sie eine sechsmonatige Pause bei der Entwicklung ihrer KI-Modelle forderten. Im Mai unterzeichneten Hunderte von KI-Wissenschaftlern [eine Erkl√§rung](https://www.safe.ai/statement-on-ai-risk), in der es hei√üt: "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorit√§t neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."

Aktuelle Umfragen in [den USA](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) und [dem Vereinigten K√∂nigreich](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693) haben gezeigt, dass eine gro√üe Mehrheit der Menschen will, dass die Regierung eingreift und die Entwicklung einer superintelligenten KI verhindert. Bisher gibt es jedoch [keine Gesetzesentw√ºrfe](https://twitter.com/PauseAI/status/1706605169608159458), die dies tun w√ºrden.

Am 1. und 2. November findet in Bletchley Park, UK, der erste AI Safety Summit statt.
Der Gipfel wird von f√ºhrenden KI-Wissenschaftlern, Politikern und Industrie-Executives besucht.
Dies ist eine einzigartige Gelegenheit, die ersten Schritte in Richtung einer internationalen Regulierung der KI-Sicherheit zu unternehmen.
Der Organisator und Vertreter des Premierministers f√ºr den AI Safety Summit, Matt Clifford, hat jedoch [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" einf√ºhren wird.

"Wir freuen uns, dass das Vereinigte K√∂nigreich die F√ºhrung bei der KI-Sicherheit √ºbernommen hat und internationale F√ºhrung zeigt", sagt Joep Meindertsma, Direktor von PauseAI. "Aber wir sehen nicht das Ma√ü an Dringlichkeit, das es verdient. Im Jahr 2020 sagten Prognostiker [voraus](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/), dass die Ankunft von KI auf menschlichem Niveau im Jahr 2055 erfolgen w√ºrde. Heute ist die [durchschnittliche Prognose](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. Wir k√∂nnen es nicht riskieren, dass wir die Geschwindigkeit des Fortschritts untersch√§tzen. Wir brauchen unsere Politiker, die auf der Seite der Vorsicht sind. Jedes einzelne Leben ist in Gefahr. Kein Unternehmen sollte in der Lage sein, eine Superintelligenz zu entwickeln."

### Medien

[Der Protest wurde in NewScientist besprochen.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wir haben w√§hrend des AI Safety Summit in Bletchley Park protestiert, um unsere F√ºhrer aufzufordern, die Entwicklung von superintelligenter KI zu stoppen. <br><br>üßµ <a href="https://t.co/WbH1