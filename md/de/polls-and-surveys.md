

---
title: Umfragen & Studien
description: Wie sehr sorgen sich Laien und Experten um die Risiken und die Regulierung von KI?
---

## Katastrophale Risiken durch KI

- **[KI-Forscher, AIImpacts 2022](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/)**: schätzen die Wahrscheinlichkeit "sehr schlechter Ergebnisse (wie das Aussterben der Menschheit)" auf 14%, mit einem Median von 5%. 82% halten das Kontrollproblem für wichtig.
- **[KI-Forscher, AIImpacts 2023](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai)**: Die durchschnittliche Wahrscheinlichkeit eines katastrophalen Ausgangs (p(doom)) liegt zwischen 14 und 19,4%, je nach Formulierung der Frage. 86% halten das Kontrollproblem für wichtig.
- **[KI-Ingenieure / Startup-Gründer, State of AI Engineering](https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631)**: Über 60% haben eine [p(doom)](/pdoom) > 25%. Nur 12% haben eine p(doom) = 0.
- **[KI-Sicherheitsforscher, AlignmentForum](https://web.archive.org/web/20221013014859/https://www.alignmentforum.org/posts/QvwSr5LsxyDeaPK5s/existential-risk-from-ai-survey-results)**: Die Befragten schätzten die Wahrscheinlichkeit eines existenziellen Risikos aufgrund mangelnder technischer Forschung auf 20% und aufgrund eines Versagens von KI-Systemen, die Absichten ihrer Entwickler zu erfüllen, auf 30%, mit großen Schwankungen (z.B. gibt es Datenpunkte bei ~1% und ~99%).
- **[Bürger des Vereinigten Königreichs, PublicFirst](https://publicfirst.co.uk/ai/)**: glauben, dass es eine 9%ige Wahrscheinlichkeit gibt, dass die Menschheit aufgrund von KI ausstirbt. Etwa 50% sagen, sie seien sehr oder einigermaßen besorgt darüber.
- **[Deutsche Bürger, Kira](https://www.zeit.de/digital/2023-04/ki-risiken-angst-umfrage-forschung-kira)**: Nur 14% glauben, dass KI einen positiven Einfluss auf die Welt haben wird, 40% sind unentschieden, 40% negativ.
- **[US-Bürger, RethinkPriorities](https://rethinkpriorities.org/publications/us-public-perception-of-cais-statement-and-the-risk-of-extinction)**: stimmen der Aussage zu (59%) und unterstützen sie (58%), dass KI ein existenzielles Risiko darstellt. Die Ablehnung (26%) und Opposition (22%) waren relativ niedrig, und ein erheblicher Anteil der Befragten blieb neutral (12% bzw. 18% für die Zustimmung und Unterstützung).
- **[Australische Bürger, Ready Research](https://theconversation.com/80-of-australians-think-ai-risk-is-a-global-priority-the-government-needs-to-step-up-225175)**: 80% glauben, dass das KI-Risiko eine globale Priorität ist, 64% wollen, dass die Regierung sich auf katastrophale Ergebnisse konzentriert (im Vergleich zu nur 25% auf Arbeitsplatzverlust oder 5% auf Voreingenommenheit).

## Regulierung und Governance

- [**US-Bürger, RethinkPriorities**](https://forum.effectivealtruism.org/posts/ConFiY9cRmg37fs2p/us-public-opinion-of-ai-policy-and-risk): 50% unterstützen eine Pause, 25% lehnen eine Pause ab.
- [**US-Bürger, YouGov**](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation): 72% wollen, dass KI langsamer entwickelt wird, 8% wollen eine Beschleunigung. 83% der Wähler glauben, dass KI versehentlich ein katastrophales Ereignis verursachen könnte.
- [**US-Bürger, YouGov**](https://theaipi.org/poll-shows-voters-oppose-open-sourcing-ai-models-support-regulatory-representation-on-boards-and-say-ai-risks-outweigh-benefits-2/): 73% glauben, dass KI-Unternehmen für Schäden haftbar gemacht werden sollten, die durch die von ihnen entwickelte Technologie verursacht werden, 67% denken, dass die Leistungsfähigkeit von KI-Modellen eingeschränkt werden sollte, und 65% glauben, dass es wichtiger ist, KI aus den Händen von böswilligen Akteuren fernzuhalten, als ihre Vorteile allen zugänglich zu machen.
- [**US-Bürger, AIPI**](https://www.politico.com/newsletters/digital-future-daily/2023/11/29/exclusive-what-people-actually-think-about-ai-00129147): 49:20 unterstützen "einen internationalen Vertrag, um jede 'intelligenter-als-menschliche' künstliche Intelligenz (KI) zu verbieten?", 70:14 unterstützen "Die Verhinderung, dass KI schnell übermenschliche Fähigkeiten erreicht".
- [**US-Professoren für Informatik, Axios Generation Lab**](https://www.axios.com/2023/09/05/ai-regulations-expert-survey): Etwa 1 von 5 sagte, dass KI "definitiv" unter menschlicher Kontrolle bleiben wird. Der Rest war zwischen denen, die sagten, KI werde "wahrscheinlich" oder "definitiv" außer Kontrolle geraten, und denen, die sagten, "wahrscheinlich nicht", aufgeteilt.
  Nur 1 von 6 sagte, KI sollte nicht oder könne nicht reguliert werden. Nur eine Handvoll vertraut dem privaten Sektor, sich selbst zu regulieren.
- [**US-Bürger, Sentience Institute**](https://www.sentienceinstitute.org/aims-survey-supplement-2023): Es gab breite Unterstützung für Schritte, die unternommen werden könnten, um die Entwicklung zu verlangsamen. Die Menschen unterstützten öffentliche Kampagnen, um die KI-Entwicklung zu verlangsamen (71,3%), staatliche Regulierung, die die Entwicklung verlangsamt (71,0%), und eine sechsmonatige Pause bei bestimmten Arten von KI-Entwicklungen (69,1%). Die Unterstützung für ein Verbot von künstlicher allgemeiner Intelligenz (AGI), die intelligenter ist als Menschen, lag bei 62,9%.
- [**Bürger des Vereinigten Königreichs, YouGov**](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693): 74% glauben, dass die Regierung die schnelle Entwicklung von übermenschlicher KI verhindern sollte. Über 60% unterstützen einen Vertrag mit einem globalen Verbot von Superintelligenz.
- [**Bürger des Vereinigten Königreichs, AISCC**](https://aiscc.org/2023/11/01/yougov-poll-83-of-brits-demand-companies-prove-ai-systems-are-safe-before-release/): 83% der Menschen sagten, dass die Regierung von KI-Unternehmen verlangen sollte, dass sie beweisen, dass ihre KI-Modelle sicher sind, bevor sie sie freigeben.
- [**NL, US, UK Bürger, Existential Risk Observatory**](https://www.existentialriskobservatory.org/papers_and_reports/Trends%20in%20Public%20Attitude%20Towards%20Existential%20Risk%20And%20Artificial%20Intelligence.pdf): Das öffentliche Bewusstsein für existenzielle Risiken wuchs in den USA von 7% auf 15% und in den Niederlanden und dem Vereinigten Königreich auf 19%. Die Unterstützung für eine staatlich angeordnete KI-Pause ist in den USA von 56% auf 66% gestiegen.