

---
title: Kommunikationsstrategie
description: Wie wir über die Pause der KI-Entwicklung kommunizieren.
---

## Wie wir kommunizieren {#how-we-communicate}

- **Verweise auf Experten**. Wir warnen vor einem Szenario, das so extrem und beängstigend ist, dass eine intuitive Reaktion darin besteht, es als verrücktes Gerede abzutun. Zeigen Sie die [Expertenbefragungen und -umfragen](/polls-and-surveys). Die [drei meistzitierten](https://twitter.com/PauseAI/status/1734641804245455017) KI-Wissenschaftler warnen alle vor dem x-Risiko. Sich auf sie zu beziehen, ist ein guter Weg, um unseren Standpunkt zu verdeutlichen.
- **Verwenden Sie einfache Sprache**. Sie können zeigen, dass Sie die Technologie verstehen und Ihre Hausaufgaben gemacht haben, aber übermäßiger Jargon kann dazu führen, dass die Leute das Interesse verlieren. Wir möchten so viele Menschen wie möglich erreichen, also machen Sie die Sprache nicht zu kompliziert. Viele der Menschen, die wir erreichen möchten, sind nicht Muttersprachler, also sollten Sie Übersetzungen in Betracht ziehen.
- **Zeigen Sie Emotionen**. Wenn man Emotionen zeigt, gibt man anderen die Erlaubnis, Emotionen zu fühlen. Wir sind besorgt, wir sind wütend, wir sind bereit zu handeln. Es kann beängstigend sein, seine Emotionen zu zeigen, aber in unserem Fall müssen wir es tun. Unsere Botschaft kann nur empfangen werden, wenn sie mit der Art und Weise übereinstimmt, wie wir sie senden.
- **Betonen Sie die Unsicherheit**. Sagen Sie nicht, dass KI die Kontrolle übernehmen wird oder dass wir in x Jahren AGI erreichen werden. Niemand kann die Zukunft vorhersagen. Es besteht eine signifikante Chance, dass KI bald schiefgeht, und das sollte genug sein, um zu handeln. Lassen Sie die Unsicherheit nicht zum Grund werden, nicht zu handeln. Beziehen Sie sich auf das Vorsorgeprinzip und machen Sie den Punkt, dass wir auf der Seite der Vorsicht sein sollten.
- **Machen Sie Einzelpersonen verantwortlich**. Niemand möchte sich verantwortlich fühlen, um sicherzustellen, dass alles gut geht. Unsere Gehirne steuern uns weg von dieser Verantwortung, weil wir alle den tiefen Wunsch haben zu glauben, dass jemand die Kontrolle hat und uns schützt. Aber es gibt keine Erwachsenen im Raum. Sie müssen derjenige sein, der dies tut. Wählen Sie, Verantwortung zu übernehmen.
- **Inspizieren Sie Hoffnung**. Wenn man von den Gefahren der KI und dem aktuellen Wettlauf nach unten hört, fühlen viele von uns Angst, und das lässt uns nicht handeln. Fatalismus ist bequem, weil ein Mangel an Hoffnung bedeutet, dass wir nicht für ein gutes Ergebnis arbeiten müssen. Deshalb müssen wir betonen, dass unser Fall nicht verloren ist. AGI ist [nicht unvermeidlich](/feasibility), Technologie wurde bereits erfolgreich international verboten, und unser Vorschlag hat breite öffentliche Unterstützung.

## Was wir nicht tun {#no-gos}

- **Kein KI-generierter Inhalt**. Die Verwendung von KI-Modellen ist in Ordnung für Recherche, Ideenfindung und Iteration von Ideen, aber veröffentlichen Sie keinen KI-generierten Inhalt als unseren eigenen - insbesondere keine KI-generierten Bilder oder Videos. Selbst wenn wir nicht gegen KI sind, können wir leicht als Heuchler bezeichnet werden, wenn wir offensichtlich KI-generierten Inhalt verwenden.
- **Keine parteipolitischen Inhalte**. Wir unterstützen keine politische Partei oder Ideologie. Wir haben keine Meinungen zu Dingen außerhalb von KI.
- **Keine taktische Selbstzensur**. Einige KI-Governance-Organisationen wählen, nicht zu sagen, wie besorgt sie sind, oder wählen, nicht für die Politiken zu pushen, die sie für notwendig halten, weil sie sich Sorgen um den Verlust ihrer Glaubwürdigkeit machen. Wir können diese Strategie nicht kopieren, weil, wenn wir alle dies tun, niemand übrig bleibt, um die Wahrheit zu sagen.
- **Keine Gerüchte**. Wir fördern keine vagen oder unverifizierten Informationen. Wir können es uns nicht leisten, unsere Glaubwürdigkeit zu verlieren, indem wir falsche Informationen verbreiten.

## Narrative, die wir pushen {#narratives-that-we-push}

- **KI ist nicht nur ein Werkzeug**. KI-Modelle sind nicht programmiert, sie sind [digitale Gehirne](/digital-brains). Wir verstehen nicht, wie sie funktionieren, wir können nicht vorhersagen, was sie tun können, wir können ihr Verhalten nicht richtig kontrollieren.
- **KI muss nicht bewusst sein, um gefährlich zu sein**. Die Fähigkeit, die Welt zu erleben oder Emotionen zu fühlen, ist keine Voraussetzung dafür, dass KI gefährliche Aktionen ausführt. Das Einzige, was zählt, sind [Fähigkeiten](/dangerous-capabilities).
- **Globaler Wettlauf nach unten**. Dies ist kein Wettlauf, den man gewinnen kann. Es geht nicht um die USA gegen China, sondern um die Menschheit gegen KI. Wir können nicht erwarten, superintelligente KI als Waffe einzusetzen - wir wissen nicht, ob sie überhaupt kontrolliert werden kann.
- **Bestehende KI-Schäden werden schlimmer**. Deepfakes, Arbeitsplatzverlust, Überwachung, Fehlinformationen, Polarisierung... Bestehende KI verursacht bereits Schäden, und wir müssen dies anerkennen. Die Schäden werden nur schlimmer mit leistungsfähigerer KI, und wir müssen KI pausieren, um dies zu verhindern.
- **Superintelligente KI ist nicht unvermeidlich**. Sie erfordert Horden von Ingenieuren mit Millionen-Dollar-Gehältern. Sie erfordert hochspezialisierte Hardware, die von einer Handvoll Monopole erstellt wird. Sie erfordert, dass wir alle nichts tun.
- **Internationale Regulierung ist möglich**. Wir haben den Ozonschutz gemeinsam geschützt, indem wir FCKW und Blendwaffen global verboten haben. Die zentralisierte KI-Chip-Lieferkette macht die Durchsetzung von Rechenleistungs-Governance sehr [machbar](/feasibility).

Ein Großteil unserer Strategie leitet sich von unseren [Werten](https://pauseai.info/values) ab.