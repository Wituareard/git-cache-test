

Titel: Kommunikationsstrategie
Beschreibung: Wie wir über die Pause der KI-Entwicklung kommunizieren.

## Wie wir kommunizieren

- **Verweisen Sie auf Experten**. Wir warnen vor einem Szenario, das so extrem und beängstigend ist, dass die erste Reaktion oft ist, es als verrücktes Gerede abzutun. Zeigen Sie die [Expertenbefragungen und Umfragen](/polls-and-surveys). Die [drei meistzitierten](https://twitter.com/PauseAI/status/1734641804245455017) KI-Wissenschaftler warnen alle vor dem x-Risiko. Sich auf sie zu beziehen, ist ein guter Weg, unsere Argumentation zu untermauern.
- **Verwenden Sie einfache Sprache**. Sie können zeigen, dass Sie die Technologie verstehen und Ihre Hausaufgaben gemacht haben, aber übermäßiger Jargon kann dazu führen, dass die Leute das Interesse verlieren. Wir möchten so viele Menschen wie möglich erreichen, also machen Sie die Sprache nicht zu kompliziert. Viele der Menschen, die wir erreichen möchten, sind nicht Muttersprachler, also sollten Sie Übersetzungen in Betracht ziehen.
- **Zeigen Sie Emotionen**. Wenn man Emotionen zeigt, gibt man anderen die Erlaubnis, Emotionen zu fühlen. Wir sind besorgt, wir sind wütend, wir sind bereit zu handeln. Es kann beängstigend sein, seine Emotionen zu zeigen, aber in unserem Fall müssen wir es tun. Unsere Botschaft kann nur empfangen werden, wenn sie mit der Art und Weise übereinstimmt, wie wir sie senden.
- **Betonen Sie die Unsicherheit**. Sagen Sie nicht, dass KI die Kontrolle übernehmen _wird_ oder dass wir AGI in x Jahren _erreichen werden_. Niemand kann die Zukunft vorhersagen. Es gibt eine signifikante _Chance_, dass KI bald schiefgeht, und das sollte genug sein, um zu handeln. Lassen Sie die Unsicherheit nicht zum Grund werden, nicht zu handeln. Beziehen Sie sich auf das _Vorsorgeprinzip_ und machen Sie den Punkt, dass wir auf der Seite der Vorsicht sein sollten.
- **Machen Sie Einzelpersonen verantwortlich**. Niemand möchte sich verantwortlich fühlen, wenn es darum geht, dass alles gut geht. Unsere Gehirne steuern uns weg von dieser Verantwortung, weil wir alle den tiefen Wunsch haben zu glauben, dass jemand die Kontrolle hat und uns schützt. Aber es gibt keine Erwachsenen im Raum, die momentan die Verantwortung tragen. Sie müssen diejenigen sein, die dies tun. Wählen Sie, Verantwortung zu übernehmen.
- **Inspizieren Sie Hoffnung**. Wenn man von den Gefahren der KI und dem aktuellen Wettlauf nach unten hört, fühlen viele von uns Angst, und das lässt uns nicht handeln. Fatalismus ist bequem, weil ein Mangel an Hoffnung bedeutet, dass wir nicht für ein gutes Ergebnis arbeiten müssen. Deshalb müssen wir betonen, dass unser Fall nicht verloren ist. AGI ist [nicht unvermeidlich](/feasibility), Technologie wurde bereits erfolgreich international verboten, und unser Vorschlag hat breite öffentliche Unterstützung.

## Was wir nicht tun

- **Kein KI-generierter Inhalt**. Die Verwendung von KI-Modellen ist in Ordnung, um Recherchen durchzuführen, Ideen zu entwickeln und Ideen zu iterieren, aber veröffentlichen Sie keinen KI-generierten Inhalt als unseren eigenen - insbesondere keine KI-generierten Bilder oder Videos. Selbst wenn wir nicht gegen KI sind, können wir leicht als Heuchler bezeichnet werden, wenn wir offensichtlich KI-generierten Inhalt verwenden.
- **Keine parteipolitischen Inhalte**. Wir unterstützen keine politische Partei oder Ideologie. Wir haben keine Meinungen zu Dingen außerhalb von KI.
- **Keine taktische Selbstzensur**. Einige KI-Governance-Organisationen entscheiden sich dafür, nicht zu sagen, wie besorgt sie sind, oder entscheiden sich dafür, nicht für die Politiken zu werben, die sie für notwendig halten, _weil sie sich Sorgen um den Verlust ihrer Glaubwürdigkeit machen_. Wir können diese Strategie nicht kopieren, weil, wenn wir alle dies tun, niemand übrig bleibt, um die Wahrheit zu sagen.
- **Keine Gerüchte**. Wir fördern keine vagen oder unverifizierten Informationen. Wir können es uns nicht leisten, unsere Glaubwürdigkeit zu verlieren, indem wir falsche Informationen verbreiten.

## Narrative, die wir verbreiten

- **KI ist nicht nur ein Werkzeug**. KI-Modelle sind nicht programmiert, sie sind [digitale Gehirne](/digital-brains). Wir verstehen nicht, wie sie funktionieren, wir können nicht vorhersagen, was sie tun können, wir können ihr Verhalten nicht richtig kontrollieren.
- **KI muss nicht bewusst sein, um gefährlich zu sein**. Die Fähigkeit, die Welt zu erleben oder Emotionen zu fühlen, ist keine Voraussetzung dafür, dass KI gefährliche Aktionen ausführt. Das Einzige, was zählt, sind [Fähigkeiten](/dangerous-capabilities).
- **Globaler Wettlauf nach unten**. Dies ist kein Wettlauf, den man gewinnen kann. Es geht nicht um die USA gegen China, sondern um die Menschheit gegen KI. Wir können nicht erwarten, superintelligente KI als Waffe einzusetzen - wir wissen nicht, ob sie überhaupt kontrolliert werden kann.
- **Bestehende KI-Schäden werden schlimmer**. Deepfakes, Arbeitsplatzverlust, Überwachung, Fehlinformationen, Polarisierung... Bestehende KI verursacht bereits Schäden, und wir müssen dies anerkennen. Die Schäden werden nur schlimmer mit leistungsfähigerer KI, und wir müssen KI pausieren, um dies zu verhindern.
- **Superintelligente KI ist nicht unvermeidlich**. Sie erfordert Horden von Ingenieuren mit Millionen-Dollar-Gehältern. Sie erfordert hochspezialisierte Hardware, die von einer Handvoll Monopole erstellt wird. Sie erfordert, dass wir alle zurücklehnen und nichts tun.
- **Internationale Regulierung ist möglich**. Wir haben gemeinsam die Ozonschicht geschützt, indem wir FCKW und Blendwaffen global verboten haben. Die zentralisierte KI-Chip-Lieferkette macht die Durchsetzung von Rechenleistungs-Governance sehr [machbar](/feasibility).

Ein Großteil unserer Strategie leitet sich von unseren [Werten](https://pauseai.info/values) ab.