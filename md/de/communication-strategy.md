---
title: Kommunikationsstrategie
description: Wie wir über die Pause der KI-Entwicklung kommunizieren.
---

## Wie wir kommunizieren

- **Verweisen Sie auf Experten**. Wir warnen die Menschen vor einem Szenario, das so extrem und beängstigend ist, dass die erste Reaktion oft ist, es als verrücktes Gerede abzutun. Zeigen Sie die [Expertenbefragungen und -umfragen](/polls-and-surveys). Die [drei meistzitierten](https://twitter.com/PauseAI/status/1734641804245455017) KI-Wissenschaftler warnen alle vor dem x-Risiko. Sich auf sie zu beziehen, ist ein guter Weg, unsere Argumentation zu untermauern.
- **Verwenden Sie einfache Sprache**. Sie können zeigen, dass Sie die Technologie verstehen und Ihre Hausaufgaben gemacht haben, aber übermäßiger Jargon kann dazu führen, dass die Menschen das Interesse verlieren. Wir möchten so viele Menschen wie möglich erreichen, also machen Sie die Sprache nicht zu kompliziert. Viele der Menschen, die wir erreichen möchten, sind nicht Muttersprachler, also sollten Sie Übersetzungen in Betracht ziehen.
- **Zeigen Sie Ihre Emotionen**. Wenn man Emotionen zeigt, gibt man anderen die Erlaubnis, Emotionen zu fühlen. Wir sind besorgt, wir sind wütend, wir sind bereit zu handeln. Es kann beängstigend sein, seine Gefühle zu zeigen, aber in unserem Fall müssen wir es tun. Unsere Botschaft kann nur empfangen werden, wenn sie mit der Art und Weise übereinstimmt, wie wir sie senden.
- **Betonen Sie die Unsicherheit**. Sagen Sie nicht, dass KI die Kontrolle übernehmen wird oder dass wir in x Jahren AGI erreichen werden. Niemand kann die Zukunft vorhersagen. Es gibt eine signifikante Chance, dass KI bald schiefgehen wird, und das sollte genug sein, um zu handeln. Lassen Sie die Unsicherheit nicht zum Grund werden, nicht zu handeln. Beziehen Sie sich auf das Vorsorgeprinzip und machen Sie den Punkt, dass wir auf der Seite der Vorsicht sein sollten.
- **Machen Sie die Menschen für ihre Verantwortung bewusst**. Niemand möchte sich verantwortlich fühlen, wenn es darum geht, dass alles gut geht. Unsere Gehirne lenken uns davon ab, weil wir alle den tiefen Wunsch haben zu glauben, dass jemand die Kontrolle hat und uns schützt. Aber es gibt keine Erwachsenen im Raum, die momentan die Verantwortung tragen. Sie müssen derjenige sein, der dies tut. Wählen Sie, Verantwortung zu übernehmen.
- **Wecken Sie Hoffnung**. Wenn man von den Gefahren der KI und dem aktuellen Wettlauf nach unten hört, fühlen viele von uns Angst, und das lässt uns nicht handeln. Fatalismus ist bequem, weil ein Mangel an Hoffnung bedeutet, dass wir nicht für ein gutes Ergebnis arbeiten müssen. Deshalb müssen wir betonen, dass unser Fall nicht verloren ist. AGI ist [nicht unvermeidlich](/feasibility), Technologie wurde bereits erfolgreich international verboten, und unser Vorschlag hat breite öffentliche Unterstützung.

## Was wir nicht tun

- **Kein KI-generierter Inhalt**. Die Verwendung von KI-Modellen ist in Ordnung, um Recherchen durchzuführen, Ideen zu entwickeln und Ideen zu iterieren, aber veröffentlichen Sie keinen KI-generierten Inhalt als unseren eigenen - insbesondere keine KI-generierten Bilder oder Videos. Selbst wenn wir nicht gegen KI sind, können wir leicht als Heuchler bezeichnet werden, wenn wir offensichtlich KI-generierten Inhalt verwenden.
- **Keine parteipolitischen Inhalte**. Wir unterstützen keine politische Partei oder Ideologie. Wir haben keine Meinungen zu Dingen außerhalb der KI.
- **Keine taktische Selbstzensur**. Einige KI-Governance-Organisationen entscheiden sich dafür, nicht zu sagen, wie besorgt sie sind, oder entscheiden sich dafür, nicht für die Politiken zu werben, die sie für notwendig halten, weil sie sich Sorgen um den Verlust ihrer Glaubwürdigkeit machen. Wir können diese Strategie nicht kopieren, weil, wenn wir alle dies tun, niemand übrig bleibt, um die Wahrheit zu sagen.
- **Keine Gerüchte**. Wir fördern keine vagen oder unbestätigten Informationen. Wir können es uns nicht leisten, unsere Glaubwürdigkeit zu verlieren, indem wir falsche Informationen verbreiten.

## Narrative, die wir fördern

- **KI ist nicht nur ein Werkzeug**. KI-Modelle sind nicht programmiert, sie sind [digitale Gehirne](/digital-brains). Wir verstehen nicht, wie sie funktionieren, wir können nicht vorhersagen, was sie tun können, wir können ihr Verhalten nicht richtig kontrollieren.
- **KI muss nicht bewusst sein, um gefährlich zu sein**. Die Fähigkeit, die Welt zu erleben oder Emotionen zu fühlen, ist keine Voraussetzung dafür, dass KI gefährliche Aktionen ausführt. Das Einzige, was zählt, sind die [Fähigkeiten](/dangerous-capabilities).
- **Globaler Wettlauf nach unten**. Dies ist kein Wettlauf, den man gewinnen kann. Es geht nicht um die USA gegen China, sondern um die Menschheit gegen die KI. Wir können nicht erwarten, superintelligente KI als Waffe einzusetzen - wir wissen nicht, ob sie überhaupt kontrolliert werden kann.
- **Bestehende KI-Schäden werden schlimmer**. Deepfakes, Arbeitsplatzverlust, Überwachung, Fehlinformationen, Polarisierung... Bestehende KI verursacht bereits Schäden, und wir müssen dies anerkennen. Die Schäden werden nur schlimmer, wenn die KI leistungsfähiger wird, und wir müssen die KI anhalten, um dies zu verhindern.
- **Superintelligente KI ist nicht unvermeidlich**. Sie erfordert Horden von Ingenieuren mit Millionen-Dollar-Gehältern. Sie erfordert hochspezialisierte Hardware, die von einer Handvoll Monopole hergestellt wird. Sie erfordert, dass wir alle nichts tun.
- **Internationale Regulierung ist möglich**. Wir haben gemeinsam die Ozonschicht geschützt, indem wir FCKW und Blend-Laser-Waffen weltweit verboten haben. Die zentralisierte KI-Chip-Lieferkette macht die Durchsetzung von Rechenleistungs-Governance sehr [machbar](/feasibility).

Ein Großteil unserer Strategie leitet sich von unseren [Werten](https://pauseai.info/values) ab.