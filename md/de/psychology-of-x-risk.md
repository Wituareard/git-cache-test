---
title: Die schwierige Psychologie des existenziellen Risikos
description: Über das Ende der Welt nachzudenken ist schwer.

Die meisten Menschen reagieren anfangs auf das Thema des existenziellen Risikos durch künstliche Intelligenz (KI) mit einer Mischung aus Spott, Ablehnung und Unglauben. Die Angst setzt oft erst nach langer Zeit des Nachdenkens ein.

Die Psychologie des existenziellen Risikos ist ein Thema, das im Vergleich zu den technischen Aspekten der KI-Sicherheit nur selten diskutiert wird. Es könnte jedoch genauso wichtig sein. Wenn wir nämlich nicht in der Lage sind, die Menschen dazu zu bringen, das Thema ernst zu nehmen und entsprechend zu handeln, können wir nichts dagegen tun.

Es ist schwer, das Thema **anzusprechen**, schwer zu **glauben**, schwer zu **verstehen** und schwer, **darauf zu reagieren**. Ein besseres Verständnis dafür, warum diese Dinge so schwierig sind, kann uns helfen, überzeugender, effektiver und empathischer zu sein.

## Schwierig anzusprechen

Das existenzielle Risiko ist ein schwieriges Thema, über das man sprechen kann, insbesondere wenn man Politiker ist. Die Menschen könnten denken, dass man verrückt ist, und man könnte sich nicht wohl dabei fühlen, über dieses technisch komplexe Thema zu sprechen.

### Angst vor Spott

Die erste Reaktion auf das existenzielle Risiko ist oft, es einfach abzutun. Wir haben auch gesehen, dass dies im Weißen Haus passiert ist, als das existenzielle Risiko zum ersten Mal angesprochen wurde. Dies macht es wiederum schwieriger, das Thema erneut anzusprechen, da andere befürchten, verspottet zu werden, wenn sie es ansprechen.

Profis können befürchten, dass ihre Reputation geschädigt wird, wenn sie ihre Bedenken teilen.

> "Es war fast gefährlich aus karrieretechnischer Sicht, zuzugeben, dass man besorgt war", sagte Jeff Clune.

Das Eintreten für vernünftige politische Maßnahmen (wie eine Pause) kann als "extremistisch" oder "alarmistisch" angesehen werden, was die Glaubwürdigkeit oder den Ruf senken kann.

### Angst, als Rassist/Kult-Anhänger/Verschwörungstheoretiker bezeichnet zu werden

In den letzten Monaten sind verschiedene Verschwörungstheorien aufgetaucht. Einige Personen haben behauptet, dass alle KI-Sicherheitsforscher Rassisten seien und dass KI-Sicherheit ein Kult sei. Einige haben behauptet, dass KI-"Doomer" Teil einer Verschwörung von Big Tech seien, um KI zu "hype". Diese lächerlichen Anschuldigungen können besorgte Menschen dazu bringen, ihre Bedenken nicht zu teilen.

Bevor man jedoch wütend auf die Menschen wird, die diese Anschuldigungen erheben, sollte man bedenken, dass sie das Ergebnis von Angst und Ablehnung sein können (siehe unten). Die Anerkennung der Gefahren von KI ist beängstigend, und es ist leichter, den Boten abzulehnen, als die Botschaft zu internalisieren.

### Ein komplexes Thema, über das man streiten kann

Die Menschen sprechen gerne über Dinge, die sie kennen. Die technische Schwierigkeit der KI-Sicherheit macht es zu einem einschüchternden Thema für die meisten Menschen. Es dauert Zeit und Mühe, die Argumente zu verstehen. Als Politiker möchte man nicht dabei erwischt werden, etwas Falsches zu sagen, also könnte man das Thema ganz vermeiden.

## Schwierig zu glauben

Selbst wenn es eine Diskussion über das existenzielle Risiko gibt, ist es schwierig, die Menschen davon zu überzeugen, dass es ein reales Problem ist. Es gibt verschiedene Gründe, warum die meisten Menschen die Idee sofort ablehnen.

### Normalitätsbias

Wir alle kennen die Bilder von Katastrophen in Filmen, oder? Menschen, die schreien und in Panik geraten. Es stellt sich heraus, dass das Gegenteil oft wahr ist: etwa 80% der Menschen zeigen Symptome von Normalitätsbias während Katastrophen: Sie suchen nicht nach Schutz während eines Tornados, ignorieren Regierungs warnungen und schütteln weiterhin Hände in den frühen COVID-Tagen. Der Normalitätsbias beschreibt unsere Tendenz, die Möglichkeit einer Katastrophe zu unterschätzen und zu glauben, dass das Leben weitergehen wird wie gewohnt, selbst angesichts erheblicher Bedrohungen oder Krisen.

> Die Menschen zögern, nach Meinungen zu fragen, weil sie hören wollen, dass alles in Ordnung ist. Sie werden weiter fragen und zögern, bis sie die Antwort erhalten, die sie hören wollen.

> Während des 11. Septembers zum Beispiel betrug die durchschnittliche Wartezeit unter den Überlebenden, um die Türme zu evakuieren, 6 Minuten, wobei einige bis zu einer halben Stunde warteten, um zu gehen. Etwa 1000 Menschen nahmen sich sogar die Zeit, ihre Computer herunterzufahren und andere Büroarbeiten zu erledigen, eine Strategie, um während einer unbekannten Situation weiterhin normale Aktivitäten auszuführen.

Ein weiteres Beispiel dafür ist die Challenger-Raumfähren-Katastrophe im Jahr 1986. Roger Boisjoly war ein Ingenieur, der vorhersagte, dass sie explodieren würde, aber keiner seiner Vorgesetzten wollte glauben, dass es möglich war:

> Wir wussten alle, dass wenn die Dichtungen versagten, die Raumfähre explodieren würde. Ich kämpfte wie verrückt, um den Start zu stoppen. Ich bin so zerrissen, dass ich kaum darüber sprechen kann, selbst jetzt. Wir sprachen mit den richtigen Leuten, wir sprachen mit den Leuten, die die Macht hatten, den Start zu stoppen.

Eine Erklärung dafür, warum unser Gehirn sich weigert zu glauben, dass Gefahr droht, ist die kognitive Dissonanz.

### Kognitive Dissonanz

Wenn man mit neuen Informationen konfrontiert wird, versucht das Gehirn, sie mit dem zu vereinbaren, was es bereits weiß. Ideen, die bereits mit bestehenden Überzeugungen übereinstimmen, werden leicht in unser Weltbild integriert. Ideen, die zu unterschiedlich von dem sind, was wir bereits glauben, verursachen kognitive Dissonanz - wir fühlen uns unwohl und versuchen, die Ideen abzulehnen oder alternative Erklärungen für das zu finden, was wir hören.

Viele Überzeugungen, die die meisten Menschen haben, werden durch die Idee des existenziellen Risikos in Frage gestellt:

- Die Technologie ist da, um uns zu dienen und kann leicht kontrolliert werden
- Es gibt intelligente Menschen, die dafür sorgen, dass alles in Ordnung ist
- Ich werde wahrscheinlich alt werden, und meine Kinder auch

Viele dieser Gedanken werden durch die Idee in Frage gestellt, dass KI ein existenzielles Risiko darstellt. Unser Gehirn sucht nach alternativen Erklärungen dafür, warum Wissenschaftler vor diesem Risiko warnen:

- Sie werden von Big Tech bezahlt
- Sie sind Teil einer Verschwörung oder eines Kults
- Sie wollen nur Aufmerksamkeit oder Macht

Die Internalisierung, dass Wissenschaftler uns warnen, weil sie glauben, dass wir in Gefahr sind, steht im Widerspruch zu unseren bestehenden Überzeugungen und verursacht zu viel kognitive Dissonanz.

### Das Ende der Welt ist noch nie passiert

Sehen ist glauben (siehe Verfügbarkeitsheuristik). Das ist ein Problem für das Aussterberisiko, weil wir es nie sehen werden, bevor es zu spät ist.

Andererseits haben wir tonnenweise Beweise für das Gegenteil. Das Ende der Zeiten wurde von vielen Menschen vorhergesagt, und jeder einzelne von ihnen hat sich geirrt.

Wenn also die Menschen von existenziellem Risiko hören, denken sie, dass es nur eine weitere dieser Weltuntergangs-Kult-Vorhersagen ist. Versuchen Sie, diese Sichtweise zu verstehen und seien Sie nicht zu hart zu den Menschen, die so denken. Sie haben wahrscheinlich nicht die gleichen Informationen wie Sie.

### Wir möchten glauben, dass wir besonders sind

Sowohl auf kollektiver als auch auf individueller Ebene möchten wir glauben, dass wir besonders sind.

Auf kollektiver Ebene möchten wir die Menschen als etwas sehr anderes als Tiere sehen - Darwins Idee, dass wir von Affen abstammen, war für die meisten fast undenkbar. Die meisten Religionen haben Geschichten über den Himmel oder die Wiedergeburt, in denen die Menschen (oder zumindest die Gläubigen) auf irgendeine Weise ewig leben werden. Die Idee, dass die Menschheit eines Tages nicht mehr existieren könnte, ist sehr verstörend und schwer zu internalisieren. Wir möchten glauben, dass wir eine Art "Plot-Panzer" haben - dass wir die Hauptfiguren in einer Geschichte sind und dass die Geschichte ein glückliches Ende haben wird. Die Menschen können es rational betrachten, aber sie werden es nicht fühlen.

Ein Video von Robert Miles mit dem Titel "Es gibt keine Regel, die besagt, dass wir es schaffen werden" erklärt dies sehr gut.

Auf individueller Ebene sind wir stolz auf unsere einzigartigen intellektuellen Fähigkeiten. Viele wollten nie glauben, dass eine KI eines Tages in der Lage sein könnte, Kunst zu schaffen, Bücher zu schreiben oder uns sogar beim Schach zu schlagen. Der Gedanke, dass unsere eigene Intelligenz nur ein Produkt der Evolution ist und dass sie von einer Maschine repliziert werden kann, ist etwas, das viele Menschen schwer akzeptieren können. Dies macht es schwierig zu akzeptieren, dass eine KI intelligenter sein könnte als wir.

### Fiktion hat uns darauf konditioniert, ein glückliches Ende zu erwarten

Die meisten Dinge, die wir über existenzielles Risiko wissen, stammen aus der Fiktion. Dies hilft wahrscheinlich nicht, weil fiktive Geschichten nicht geschrieben werden, um realistisch zu sein: Sie werden geschrieben, um unterhaltsam zu sein.

In der Fiktion gibt es oft einen Helden, Konflikte, Hoffnung und schließlich ein glückliches Ende. Wir sind darauf konditioniert, einen Kampf zu erwarten, den wir gewinnen können. In Science-Fiction werden KIs oft sehr anthropomorph dargestellt - als böse, als menschlich, als ihre Ziele ändernd. All dies stimmt nicht mit dem überein, worüber KI-Sicherheitsexperten besorgt sind.

Und in den meisten Geschichten gewinnt der Held. Die KI macht einen dummen Fehler, und der Held findet einen Weg, die Sache, die viel intelligenter sein soll, zu überlisten. Der Held ist durch eine Art "Plot-Panzer" geschützt. In realistischeren KI-Untergangsszenarien gibt es keinen Helden, keinen Plot-Panzer, keinen Kampf, kein menschliches Überlisten einer Superintelligenz und kein glückliches Ende.

### Fortschritt war immer (meist) gut

Viele der Technologien, die in unsere Gesellschaft eingeführt wurden, waren größtenteils vorteilhaft für die Menschheit. Wir haben Krankheiten geheilt, unsere Lebenserwartung erhöht und unser Leben komfortabler gemacht. Und jedes Mal, wenn wir dies getan haben, gab es Menschen, die sich diesen Innovationen widersetzten und vor den Gefahren warnten. Die Ludditen zerstörten die Maschinen, die ihre Arbeitsplätze nahmen, und die Menschen hatten Angst vor den ersten Zügen und Autos. Diese Menschen haben sich immer geirrt.

### Wir möchten nicht an unseren Tod denken

Der menschliche Geist mag keine schlechten Nachrichten, und er hat verschiedene Bewältigungsmechanismen, um damit umzugehen. Die wichtigsten, wenn es um existenzielles Risiko geht, sind Verleugnung und Kompartimentalisierung. Wenn es um unseren eigenen Tod geht, sind wir sehr anfällig für Verleugnung. Bücher wurden über die Verleugnung des Todes geschrieben.

Diese Bewältigungsmechanismen schützen uns vor dem Schmerz, akzeptieren zu müssen, dass die Welt nicht so ist, wie wir dachten. Sie können uns jedoch auch daran hindern, auf eine Bedrohung angemessen zu reagieren.

Wenn Sie bemerken, dass jemand diese Bewältigungsmechanismen verwendet, versuchen Sie, empathisch zu sein. Sie tun es nicht absichtlich, und sie sind nicht dumm. Es ist eine natürliche Reaktion auf schlechte Nachrichten, und wir alle tun es in gewissem Maße.

### Es ist schwer, zuzugeben, dass die eigene Arbeit gefährlich ist

Für diejenigen, die an KI-Fähigkeiten gearbeitet haben, ist es noch schwieriger, die Gefahren zu akzeptieren.

Nehmen Sie zum Beispiel Yoshua Bengio. Yoshua Bengio hat ein brillantes Gehirn und ist einer der Pioniere auf dem Gebiet der KI. KI-Sicherheitsexperten warnen seit Jahren vor den potenziellen Gefahren der KI, aber es dauerte lange, bis er ihre Warnungen ernst nahm. In einem Interview gab er die folgende Erklärung:

> "Warum habe ich nicht früher darüber nachgedacht? Warum hat Geoffrey Hinton nicht früher darüber nachgedacht? [...] Ich glaube, es gibt einen psychologischen Effekt, der immer noch bei vielen Menschen wirkt. [...] Es ist sehr schwer, aus egoistischer Sicht und um sich gut zu fühlen, zu akzeptieren, dass das, woran man seit Jahrzehnten arbeitet, tatsächlich sehr gefährlich für die Menschheit sein könnte. [...] Ich denke, ich wollte nicht zu viel darüber nachdenken, und das ist wahrscheinlich auch bei anderen der Fall."

Es sollte niemanden überraschen, dass einige der heftigsten KI-Risiko-Leugner KI-Forscher selbst sind.

### Es ist leicht, es als Verschwörung oder Kult abzutun

Im letzten Jahr wurde der größte Teil der Bevölkerung mit dem Konzept des existenziellen Risikos durch KI bekannt gemacht. Wenn die Menschen davon hören, suchen sie nach einer Erklärung. Die richtige Erklärung ist, dass KI tatsächlich gefährlich ist, aber dies zu glauben ist schwierig und beängstigend: Es wird zu viel kognitive Dissonanz führen. Die Menschen werden also fast direkt nach einer anderen Erklärung suchen.

Es gibt zwei alternative Erklärungen, die viel leichter zu glauben sind:

1. **Es ist alles eine große Verschwörung**. KI-Unternehmen hypen KI, um mehr Geld zu bekommen, und KI-Sicherheitsleute sind Teil dieser Hype-Maschine. Diese Erzählung stimmt mit verschiedenen Beobachtungen übere