

---
title: Die schwierige Psychologie des existenziellen Risikos
description: Über das Ende der Welt nachzudenken ist schwer.
---

Die meisten Menschen reagieren anfangs auf das Thema des existenziellen Risikos durch künstliche Intelligenz (KI) mit einer Mischung aus Spott, Ablehnung und Unglauben. Die Angst setzt oft erst nach längerem Nachdenken ein.

Die Psychologie des existenziellen Risikos ist ein Thema, das im Vergleich zu den technischen Aspekten der KI-Sicherheit selten diskutiert wird. Es könnte jedoch genauso wichtig sein. Wenn wir die Menschen nicht dazu bringen können, das Thema ernst zu nehmen und entsprechend zu handeln, können wir nichts dagegen tun.

Es ist schwer, das Thema **anzusprechen**, schwer zu **glauben**, schwer zu **verstehen** und schwer, **darauf zu reagieren**. Ein besseres Verständnis dafür, warum diese Dinge so schwierig sind, kann uns helfen, überzeugender, effektiver und empathischer zu sein.

## Schwierig anzusprechen {#difficult-to-bring-up}

Das existenzielle Risiko ist ein schwieriges Thema, insbesondere für Politiker. Die Menschen könnten denken, dass man verrückt ist, und man könnte sich nicht wohl dabei fühlen, über dieses technisch komplexe Thema zu sprechen.

### Angst vor Spott und sozialer Ausgrenzung {#fear-of-being-ridiculed}

Die erste Reaktion auf das existenzielle Risiko ist oft, es einfach abzutun. Wir haben auch gesehen, dass dies im Weißen Haus passiert ist, als das existenzielle Risiko zum ersten Mal angesprochen wurde. Dies macht es wiederum schwieriger, das Thema erneut anzusprechen, da andere befürchten, verspottet oder sozial ausgegrenzt zu werden.

Profis können befürchten, dass ihre Reputation geschädigt wird, wenn sie ihre Bedenken teilen.

> "Es war fast gefährlich aus karrieretechnischer Sicht, zuzugeben, dass man besorgt war", sagte Jeff Clune.

Das Eintreten für vernünftige politische Maßnahmen (wie eine Pause) kann als "extremistisch" oder "alarmistisch" angesehen werden, was die Glaubwürdigkeit oder den Ruf senken kann.

### Angst, als Rassist/Kult-Anhänger/Verschwörungstheoretiker bezeichnet zu werden {#fear-of-being-called-racistcultistconspiracy-theorist}

In den letzten Monaten sind verschiedene Verschwörungstheorien aufgetaucht. Einige Personen haben behauptet, dass alle KI-Sicherheitsforscher Rassisten seien und dass KI-Sicherheit ein Kult sei. Einige haben behauptet, dass KI-"Doomer" Teil einer Verschwörung von Big Tech seien, um KI zu "hype". Diese lächerlichen Anschuldigungen können besorgte Menschen davon abhalten, ihre Bedenken zu teilen.

Bevor man jedoch wütend auf die Menschen wird, die diese Anschuldigungen erheben, sollte man bedenken, dass sie das Ergebnis von Angst und Ablehnung sein können (siehe unten). Die Anerkennung der Gefahren von KI ist beängstigend, und es kann einfacher sein, den Boten abzulehnen, als die Botschaft zu internalisieren.

### Ein komplexes Thema, über das zu diskutieren ist {#a-complex-topic-to-argue-about}

Die Menschen sprechen gerne über Dinge, die sie kennen. Die technische Schwierigkeit der KI-Sicherheit macht es zu einem einschüchternden Thema für die meisten Menschen. Es dauert Zeit und Mühe, die Argumente zu verstehen. Als Politiker möchte man nicht dabei erwischt werden, etwas Falsches zu sagen, also könnte man das Thema ganz vermeiden.

## Schwierig zu glauben {#difficult-to-believe}

Selbst wenn es eine Diskussion über das existenzielle Risiko gibt, ist es schwierig, die Menschen davon zu überzeugen, dass es ein reales Problem ist. Es gibt verschiedene Gründe, warum die meisten Menschen die Idee sofort ablehnen.

### Normalitätsbias {#normalcy-bias}

Wir alle kennen die Bilder von Katastrophen in Filmen, oder? Menschen, die schreien und in Panik geraten. Es stellt sich heraus, dass das Gegenteil oft wahr ist: etwa 80% der Menschen zeigen Symptome von Normalitätsbias während Katastrophen: Sie suchen nicht nach Schutz während eines Tornados, ignorieren Regierungs warnungen und schütteln weiterhin Hände in den frühen COVID-Tagen.

> Die Menschen fragen nach Meinungen, weil sie hören wollen, dass alles in Ordnung ist. Sie werden weiter fragen und zögern, bis sie die Antwort erhalten, die sie hören wollen.

Ein weiteres Beispiel dafür ist die Challenger-Raumfähre-Katastrophe im Jahr 1986. Roger Boisjoly war ein Ingenieur, der vorhersagte, dass sie explodieren würde, aber keiner seiner Vorgesetzten wollte glauben, dass es möglich war.

Eine Erklärung dafür, warum unser Gehirn sich weigert zu glauben, dass Gefahr droht, ist die kognitive Dissonanz.

### Kognitive Dissonanz {#cognitive-dissonance}

Wenn man mit neuen Informationen konfrontiert wird, versucht das Gehirn, sie mit dem zu vereinbaren, was es bereits weiß. Ideen, die bereits mit bestehenden Überzeugungen übereinstimmen, werden leicht in unser Weltbild integriert. Ideen, die zu unterschiedlich von dem sind, was wir bereits glauben, verursachen kognitive Dissonanz - wir fühlen uns unwohl und versuchen, die Ideen abzulehnen oder alternative Erklärungen für das zu finden, was wir hören.

Viele Überzeugungen, die die meisten Menschen haben, werden durch die Idee des existenziellen Risikos in Frage gestellt:

- Technologie ist da, um uns zu dienen und kann leicht kontrolliert werden
- Es gibt intelligente Menschen, die dafür sorgen, dass alles in Ordnung ist
- Ich werde wahrscheinlich alt werden, und meine Kinder auch

Viele dieser Gedanken werden durch die Idee in Frage gestellt, dass KI ein existenzielles Risiko darstellt. Unser Gehirn sucht nach alternativen Erklärungen dafür, warum Wissenschaftler warnen:

- Sie werden von Big Tech bezahlt
- Sie sind Teil einer Verschwörung oder eines Kults
- Sie wollen nur Aufmerksamkeit oder Macht

Die Internalisierung, dass Wissenschaftler warnen, weil sie glauben, dass wir in Gefahr sind, steht im Widerspruch zu unseren bestehenden Überzeugungen und verursacht zu viel kognitive Dissonanz.

### Das Ende der Welt ist noch nie passiert {#the-end-of-the-world-has-never-happened}

Sehen ist glauben. Das ist ein Problem für das Aussterberisiko, weil wir es nie sehen werden, bevor es zu spät ist.

Andererseits haben wir tonnenweise Beweise für das Gegenteil. Das Ende der Zeiten wurde von vielen Menschen vorhergesagt, und jeder einzelne von ihnen hat sich geirrt.

Wenn die Menschen also von existenziellem Risiko hören, denken sie, es sei nur eine weitere dieser Weltuntergangs-Kult-Vorhersagen.

### Wir möchten glauben, dass wir besonders sind {#we-like-to-think-that-we-are-special}

Sowohl auf kollektiver als auch auf individueller Ebene möchten wir glauben, dass wir besonders sind.

Auf kollektiver Ebene möchten wir glauben, dass die Menschheit etwas sehr anderes ist als Tiere - Darwins Idee, dass wir von Affen abstammen, war für die meisten fast undenkbar.

Die meisten Religionen haben Geschichten über den Himmel oder die Wiedergeburt, in denen die Menschen (oder zumindest die Gläubigen) auf irgendeine Weise ewig leben werden. Die Idee, dass die Menschheit eines Tages nicht mehr existieren könnte, ist sehr verstörend und schwer zu internalisieren.

Wir möchten glauben, dass wir eine Art "Plot-Panzer" haben - dass wir die Hauptfiguren in einer Geschichte sind und dass die Geschichte ein glückliches Ende haben wird.

### Fiktion hat uns darauf konditioniert, ein glückliches Ende zu erwarten {#fiction-has-conditioned-us-to-expect-a-happy-ending}

Die meisten Dinge, die wir über existenzielles Risiko wissen, stammen aus der Fiktion. Dies hilft wahrscheinlich nicht, weil fiktive Geschichten nicht realistisch geschrieben sind - sie sind unterhaltsam geschrieben.

In der Fiktion gibt es oft einen Helden, Konflikt, Hoffnung und schließlich ein glückliches Ende. Wir sind darauf konditioniert, einen Kampf zu erwarten, den wir gewinnen können.

In der Realität gibt es jedoch keinen Helden, kein glückliches Ende, keinen Kampf und keine Menschen, die eine Superintelligenz überlisten.

### Fortschritt war immer (meist) gut {#progress-has-always-been-mostly-good}

Viele der Technologien, die in unsere Gesellschaft eingeführt wurden, waren größtenteils vorteilhaft für die Menschheit. Wir haben Krankheiten geheilt, unsere Lebenserwartung erhöht und unser Leben komfortabler gemacht.

Und jedes Mal, wenn wir dies getan haben, gab es Menschen, die sich diesen Innovationen widersetzten und vor den Gefahren warnten. Die Ludditen zerstörten die Maschinen, die ihre Arbeitsplätze nahmen, und die Menschen fürchteten sich vor den ersten Zügen und Autos.

Diese Menschen haben sich immer geirrt.

### Wir möchten nicht an unseren Tod denken {#we-dont-like-to-think-about-our-death}

Der menschliche Geist mag keine schlechten Nachrichten und hat verschiedene Bewältigungsmechanismen, um damit umzugehen. Die wichtigsten sind Verleugnung und Kompartimentalisierung.

Wenn es um unseren eigenen Tod geht, sind wir sehr anfällig für Verleugnung. Bücher wurden über die Verleugnung des Todes geschrieben.

Diese Bewältigungsmechanismen schützen uns vor dem Schmerz, akzeptieren zu müssen, dass die Welt nicht so ist, wie wir dachten. Sie können uns jedoch auch daran hindern, auf eine Bedrohung angemessen zu reagieren.

Wenn Sie bemerken, dass jemand diese Bewältigungsmechanismen verwendet, versuchen Sie, empathisch zu sein. Sie tun es nicht absichtlich, und sie sind nicht dumm. Es ist eine natürliche Reaktion auf schlechte Nachrichten, und wir alle tun es in gewissem Maße.

## Schwierig zu verstehen {#admitting-your-work-is-dangerous-is-hard}

Die Argumente für das existenzielle Risiko durch KI sind oft sehr technisch, und wir neigen dazu, KI-Systeme zu anthropomorphisieren.

### KI-Alignment ist überraschend schwierig {#easy-to-dismiss-as-conspiracy-or-cult}

Die Menschen könnten intuitiv denken, dass sie das KI-Alignment-Problem lösen könnten. Warum nicht einfach einen Stopp-Knopf hinzufügen? Warum nicht die KI wie ein Kind aufziehen? Warum nicht Asimovs drei Gesetze?

Im Gegensatz zu den meisten technischen Problemen haben die Menschen eine Meinung darüber, wie man das KI-Alignment-Problem lösen kann, und unterschätzen die Schwierigkeit des Problems.

Das Verständnis der tatsächlichen Schwierigkeit erfordert viel Zeit und Mühe.

### Wir anthropomorphisieren {#difficult-to-understand}

Wir sehen Gesichter in Wolken und menschliche Qualitäten in KI-Systemen. Millionen von Jahren der Evolution haben uns zu hochsozialen Wesen gemacht, aber diese Instinkte sind nicht immer hilfreich.

Wir neigen dazu, KIs als menschliche Ziele und Motivationen zu sehen, Emotionen zu empfinden und ein moralisches Empfinden zu haben. Wir erwarten von einer sehr intelligenten KI, dass sie auch sehr weise und freundlich ist.

Dies ist einer der Gründe, warum die Menschen intuitiv denken, dass KI-Alignment einfach ist, und warum die Orthogonalitäts-These so kontraintuitiv sein kann.

### KI-Sicherheit verwendet komplexe Sprache {#ai-alignment-is-surprisingly-hard}

Das KI-Sicherheitsfeld besteht größtenteils aus einer kleinen Gruppe von (intelligenten) Menschen, die ihre eigene Fachsprache entwickelt haben. Das Lesen von LessWrong-Beiträgen kann sich wie das Lesen einer fremden Sprache anfühlen.

Viele Beiträge gehen davon aus, dass der Leser bereits mit mathematischen Konzepten, verschiedenen technischen Konzepten und der Fachsprache des Fachgebiets vertraut ist.

## Schwierig, darauf zu reagieren {#we-anthropomorphize}

Selbst wenn die Menschen die Argumente verstehen, ist es schwierig, darauf zu reagieren. Der Einfluss ist zu groß, wir haben Bewältigungsmechanismen, die die Risiken herunterspielen, und wenn wir die Schwere der Situation spüren, können wir uns machtlos fühlen.

### Mangel an angeborener Angstreaktion {#ai-safety-uses-complex-language}

Unsere Gehirne haben sich entwickelt, um Dinge zu fürchten, die gefährlich sind. Wir fürchten uns instinktiv vor Höhen, großen Tieren mit scharfen Zähnen, plötzlichen lauten Geräuschen und Dingen, die sich in einer S-Form bewegen.

Eine superintelligente KI trifft jedoch nicht auf unsere primären Ängste. Darüber hinaus haben wir eine starke Angst vor sozialer Ablehnung oder dem Verlust des sozialen Status, was bedeutet, dass die Menschen Angst haben, über KI-Risiken zu sprechen.

### Umfangsinsensitivität {#difficult-to-act-on}

> "Ein einzelner Tod ist eine Tragödie; eine Million Tote ist eine Statistik." - Joseph Stalin

Umfangsinsensitivität ist die menschliche Tendenz, die Auswirkungen großer Zahlen zu unterschätzen. Wir kümmern uns nicht 10-mal so viel um 1000 Tote wie um 100 Tote.

Existenzielles Risiko bedeutet den Tod aller 8 Milliarden Menschen auf der Erde (ohne ihre Nachkommen).

Selbst wenn es nur eine 1-prozentige Chance gibt, dass dies passiert, ist es immer noch ein sehr großes Problem.

Wenn jemand denkt, dass das Ende der Welt nicht so schlimm ist (Sie wären überrascht, wie oft dies passiert), können Sie versuchen, die Dinge persönlicher zu machen. Die Menschheit ist nicht nur ein abstraktes Konzept, sondern Ihre Freunde, Ihre Familie und Sie selbst.

Alle Menschen, die Ihnen wichtig sind, werden sterben.

### Unser Verhalten wird durch unsere Umgebung und primitive Geister geprägt {#lack-of-innate-fear-response}

Unsere Handlungen werden durch das bestimmt, was als normal, gut und vernünftig angesehen wird. Egal, wie sehr wir in einer Situation handeln möchten, die ein Handeln erfordert, wenn diese Handlungen ungewöhnlich sind, fürchten wir uns oft bewusst oder unbewusst davor, von der Gesellschaft ausgeschlossen zu werden. Und was normal ist, wird uns durch unsere engen sozialen Kreise und Online-Feeds eingeimpft.

Die Menschen, die einfach Dinge tun und über Dinge sprechen, die nichts mit dem zu tun haben, was uns wirklich wichtig ist, werden das, was in unseren Köpfen ist, überschreiben und uns motivieren, täglich andere Dinge zu tun.

Existenzielle Risiken verdienen viel mehr unserer Zeit, Energie und Aufmerksamkeit. Unsere Reaktionen darauf sollten eher wie lebensbedrohliche Situationen sein, die uns mit Adrenalin füllen. Aber wegen der abstrakten Natur der Probleme und unserer unangepassten Geister gehen die meisten Menschen, die davon erfahren, einfach weiter mit ihrem Tag, als hätten sie nichts gelernt.

### Bewältigungsmechanismen (Verhinderung von Handlungen) {#scope-insensitivity}

Die gleichen Bewältigungsmechanismen, die die Menschen daran hindern, an existenzielles Risiko zu glauben, hindern sie auch daran, darauf zu reagieren. Wenn Sie in Verleugnung oder Kompartimentalisierung sind, werden Sie nicht das Bedürfnis verspüren, etwas dagegen zu tun.

### Stress und Angst {#our-behavior-is-shaped-by-our-environment-and-primitive-minds}

Während ich dies schreibe, fühle ich mich gestresst und ängstlich. Es ist nicht nur, weil ich das Ende der Welt fürchte, sondern auch, weil ich das Gefühl habe, dass ich etwas dagegen tun muss. Es gibt viel Druck, zu handeln, und es kann überwältigend sein. Dieser Stress kann ein guter Motivator sein, aber er kann auch lähmend sein.

### Hoffnungslosigkeit und Machtlosigkeit {#coping-mechanisms-preventing-action}

Wenn die Menschen das Thema ernst nehmen und die volle Schwere der Situation begreifen, können sie sich hoffnungslos und machtlos fühlen. Es kann sich wie eine Krebsdiagnose anfühlen: Sie werden früher sterben, als Sie wollten, und es gibt nichts, was Sie dagegen tun können.

Das Problem ist zu groß, um es anzugehen, und Sie sind zu klein. Die meisten Menschen sind keine KI-Sicherheitsexperten oder erfahrene Lobbyisten, also wie können sie etwas dagegen tun?

## Aber Sie können helfen! {#stress-and-anxiety}

Es gibt viele Dinge, die Sie tun können. Ein Brief schreiben, an einer Demonstration teilnehmen, Geld spenden oder einer Gemeinschaft beitreten ist nicht so schwer! Und diese Aktionen haben einen realen Einfluss.

Selbst wenn wir dem Ende der Welt gegenüberstehen, kann es immer noch Hoffnung und sehr lohnende Arbeit geben.

[Treten Sie PauseAI bei](/join) und werden Sie Teil unserer Bewegung.