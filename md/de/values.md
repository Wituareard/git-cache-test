---
title: Werte von PauseAI
description: Wie plant PauseAI, seine Mission zu erreichen?
---

## Was wollen wir?

Den globalen Stopp der Entwicklung von Spitzen-AI-Systemen, bis wir wissen, wie wir sie sicher und unter demokratischer Kontrolle entwickeln können. Siehe unseren [Vorschlag](/proposal).

## Was sind unsere Werte?

- **Menschlichkeit an erster Stelle**. Wir glauben, dass AI so entwickelt werden sollte, dass sie der Menschheit nützt, oder gar nicht.
- **Gemeinschaft**. Ein Gefühl der Gemeinschaft entsteht nicht nur durch ein gemeinsames Ziel (z.B. den Stopp von AI) oder Werte, sondern auch durch soziale Aktivitäten. Deshalb ist es wichtig, Menschen zusammenzubringen, Veranstaltungen zu organisieren, soziale Treffen zu veranstalten und reale Freundschaften zu schließen. Es geht nicht nur um konstruktives Handeln, sondern auch darum, Freunde zu finden und sich in einer Gruppe zuhause zu fühlen.
- **Jeder kann beitragen**. Viele Organisationen für AI-Sicherheit und AI-Governance verlassen sich ausschließlich auf ihre Gruppe von bezahlten Mitarbeitern. Dies hat seine Vorteile, aber es hinterlässt eine Lücke an Freiwilligen. Hier unterscheidet sich PauseAI. Durch die Förderung von Freiwilligen und die Ermutigung zum Handeln können wir Dinge erreichen, auch ohne viel Förderung.
- **Transparenz als Standard**. Wir handeln und diskutieren öffentlich und offen, es sei denn, es gibt einen guten Grund, dies nicht zu tun. Meetings sind offen für alle, die Website ist Open-Source, und der Discord-Server ist beitrittsbereit. Durch unsere Zugänglichkeit senken wir die Barrieren, um sich willkommen zu fühlen und zu helfen.
- **Ehrlichkeit**. Wir haben keine merkwürdigen Anreize (z.B. einen Anteil an einem AI-Unternehmen), also sind wir frei, unsere Meinung auszudrücken. Wir beschönigen unsere Botschaft nicht, um sie schmackhafter zu machen.
- **Vielfalt in Risiken, Einheit in Wünschen**. Ob Sie sich Sorgen um existenzielle Risiken, Cybersicherheitsgefahren oder die Auswirkungen von AI auf unsere Demokratie machen: Wir sind vereint in unserem Wunsch, die AI-Entwicklung zu stoppen.
- **Keine parteipolitischen Spiele**. Menschen sind gruppenorientiert, was uns dazu bringt, Meinungen in Gruppen (links/rechts) zu bündeln. AI-Sicherheit ist noch nicht so parteipolitisch (noch nicht), und wir wollen es so halten. Wir lassen unsere anderen politischen Ansichten nicht von unserem gemeinsamen Ziel ablenken.

## Welche Art von Kultur möchten wir fördern?

- **Handlungsorientiert**. Wir möchten eine Gruppe sein, die Dinge erreicht. Das Perfekte ist der Feind des Guten. Wir können uns nicht dem Komfort hingegeben, nur über Dinge zu sprechen. Wir müssen handeln.
- **Freundlich**. Wir möchten eine Gruppe sein, der Menschen gerne angehören. Wir möchten neue Mitglieder willkommen heißen.
- **Offen**. Wir möchten offen für neue Ideen, neue Menschen und neue Wege des Handelns sein. Wir möchten offen für Kritik sein. Unser Ziel ist es, AI-Risiken zu verhindern. Wir sollten offen für die Möglichkeit sein, dass wir falsch liegen, wie wir das erreichen.
- **Vernünftig**. Da unsere Bedenken oft als verrückt abgetan werden, müssen wir besonders vorsichtig sein, nicht verrückt auszusehen. Betonen Sie, dass viele Menschen in unserer Gruppe technische Hintergründe haben. Zeigen Sie, dass wir wissen, worüber wir sprechen.

_Related: unser [Verhaltenskodex für Demonstranten](/protesters-code-of-conduct)_