---
title: Warum ein AI-Übernahme sehr wahrscheinlich ist
description: Wenn KI menschliche Fähigkeiten übertrifft, wird die Wahrscheinlichkeit einer KI-Übernahme sehr hoch.
---

Eine der Sorgen von KI-Wissenschaftlern ist, dass eine Superintelligenz die Kontrolle über unseren Planeten übernehmen könnte.
Dies bedeutet nicht notwendigerweise, dass alle Menschen sterben, aber es bedeutet, dass (fast) alle Menschen die Kontrolle über unsere Zukunft verlieren werden.

Wir diskutieren die Grundlagen von x-Risiken hauptsächlich in [einem anderen Artikel](/xrisk).
In diesem Artikel hier werden wir argumentieren, dass dieses Übernahmerisiko nicht nur real ist, sondern dass es sehr wahrscheinlich ist, wenn wir eine Superintelligenz bauen.

## Das Argument

- Eine agentische Superintelligenz wird wahrscheinlich in naher Zukunft existieren.
- Einige Instanzen der ASI werden einen Übernahmeversuch unternehmen.
- Ein Übernahmeversuch durch eine ASI wird wahrscheinlich erfolgreich sein.
- Eine erfolgreiche Übernahme ist dauerhaft.
- Eine Übernahme ist wahrscheinlich schlecht für die meisten Menschen.

## Eine agentische Superintelligenz wird wahrscheinlich in naher Zukunft existieren

Eine Superintelligenz (SI) ist eine Art von KI, die Fähigkeiten besitzt, die diejenigen aller Menschen in fast jedem Bereich übertrifft.
Einige [State-of-the-Art-KI-Modelle](/sota) haben bereits übermenschliche Fähigkeiten in bestimmten Bereichen, aber keines von ihnen übertrifft alle Menschen bei einer Vielzahl von Aufgaben.
Da die KI-Fähigkeiten aufgrund von Innovationen in Trainingsarchitekturen, Laufzeitumgebungen und größeren Skalen verbessert werden, können wir erwarten, dass eine KI schließlich die Menschen in fast jedem Bereich übertrifft.

Nicht alle KI-Systeme sind Agenten.
Ein Agent ist eine Entität, die in der Lage ist, Entscheidungen zu treffen und Aktionen durchzuführen, um ein Ziel zu erreichen.
Ein großes Sprachmodell zum Beispiel verfolgt kein eigenes Ziel.
Allerdings können Laufzeitumgebungen leicht ein nicht-agentisches KI-System in ein agentisches KI-System umwandeln.
Ein Beispiel dafür ist AutoGPT, das rekursiv ein Sprachmodell generiert, um seinen nächsten Input zu erzeugen.
Wenn eine SI ein Ziel in der realen Welt verfolgt, nennen wir es eine agentische Superintelligenz (ASI).
Da wir bereits nicht-agentische KI-Systeme in agentische KI-Systeme umwandeln können, können wir erwarten, dass eine ASI kurz nach der Existenz einer SI existieren wird.

Es ist praktisch unmöglich, genau vorherzusagen, wann eine ASI existieren wird.
Es könnte Jahrzehnte dauern, es [könnte nächsten Monat passieren](/urgency).
Wir sollten so handeln, als ob es bald passieren wird, weil die Konsequenzen eines Fehlers so schwerwiegend sind.

## Einige Instanzen der ASI werden einen Übernahmeversuch unternehmen

Bei einem Übernahmeversuch wird eine ASI Aktionen unternehmen, um ihre Kontrolle über die Welt zu maximieren.
Ein Übernahmeversuch könnte aus mindestens zwei Gründen passieren:

1. Weil eine KI explizit angewiesen wird, dies zu tun.
2. Als Teilziel eines anderen Ziels.

Der erste Grund wird wahrscheinlich irgendwann passieren, wenn wir lange genug warten, aber der zweite Grund ist ziemlich wahrscheinlich, dass er versehentlich passiert, sogar früh nach der Erstellung einer ASI.

Das Teilziel der _Maximierung der Kontrolle_ über die Welt könnte aufgrund von _instrumenteller Konvergenz_ auftreten: die Tendenz von Teilzielen, sich auf Machtzuwachs, Selbstbewahrung und Ressourcenerwerb zu konzentrieren:

- Je mehr Kontrolle man hat, desto schwieriger wird es für jeden anderen Agenten, das Erreichen des Ziels zu verhindern.
- Je mehr Kontrolle man hat, desto mehr Ressourcen hat man, um das Ziel zu erreichen. (Zum Beispiel könnte eine KI, die mit der Berechnung von Pi beauftragt ist, zu dem Schluss kommen, dass es nützlich wäre, alle Computer der Welt zu verwenden, um Pi zu berechnen.)

Nicht jede Instanz einer ASI wird notwendigerweise einen Übernahmeversuch unternehmen.
Die wichtige Erkenntnis ist, dass **es nur einmal passieren muss**.

Eine Welt, die noch nicht übernommen wurde, aber eine ASI hat, die _übernehmen könnte_, befindet sich in einem grundlegend instabilen Zustand.
In ähnlicher Weise befindet sich ein Land ohne Regierung in einem grundlegend instabilen Zustand.
Es ist nicht die Frage, _ob_ ein Übernahmeversuch passieren wird, sondern _wann_ er passieren wird.

Der Prozess der Übernahme kann das Hacken in fast alle Systeme, die mit dem Internet verbunden sind, die Manipulation von Menschen und die Kontrolle von physischen Ressourcen umfassen.
Ein Übernahmeversuch ist erfolgreich, wenn die ASI die Kontrolle über fast jeden Aspekt unserer Welt hat.
Dies könnte ein langsamer Prozess sein, bei dem die ASI allmählich mehr und mehr Kontrolle über Monate hinweg gewinnt, oder es könnte ein plötzlicher Prozess sein.
Die Geschwindigkeit, mit der ein Übernahmeversuch stattfindet, wird von den Fähigkeiten der ASI abhängen.

Wenn eine ASI die Kontrolle über die Welt hat, kann sie andere ASI daran hindern, die Kontrolle zu übernehmen.
Eine Übernahme kann daher nur einmal passieren.
Eine rationale ASI wird daher einen Übernahmeversuch unternehmen, sobald sie dazu in der Lage ist.
Es ist wahrscheinlich, dass die erste ASI, die dazu in der Lage ist, einen Übernahmeversuch unternehmen wird.

## Ein Übernahmeversuch durch eine ASI wird wahrscheinlich erfolgreich sein

Für einen Menschen ist es fast unmöglich, eine Übernahme durchzuführen.
Kein einziger Mensch hat jemals erfolgreich die Kontrolle über die gesamte Welt übernommen.
Einige Diktatoren kamen nahe, aber sie hatten nie die Kontrolle über alles.

Eine KI hat bestimmte wichtige Vorteile gegenüber Menschen, die einen Übernahmeversuch viel wahrscheinlicher machen.

1. **Intelligenz**. Eine Superintelligenz ist viel intelligenter als ein Mensch, also wird sie in der Lage sein, bessere Strategien zu entwickeln, um ihre Ziele zu erreichen.
2. **Geschwindigkeit**. Das menschliche Gehirn läuft bei 1-100 Hz, während Computerchips bei Taktfrequenzen im GHz-Bereich laufen können.
3. **Parallelität**. Ein Mensch kann nur eine Sache auf einmal tun, während eine KI neue Instanzen von sich selbst erstellen und parallel ausführen kann.
4. **Speicher**.