

---
title: Handeln Sie
description: Möglichkeiten, das Risiko von künstlicher Intelligenz zu reduzieren.
---
KI wird nicht sicherer, wenn wir nicht entschlossen handeln, um Sicherheit zu fördern.
Wählen Sie eine Aktivität unten, je nach Ihren Interessen oder Fähigkeiten.

## Für alle {#for-everyone}

### Fordern Sie Regierungsmaßnahmen {#demand-government-action}

- **Schreiben Sie Ihren Abgeordneten**: Wir haben festgestellt, dass E-Mails überraschend effektiv sind und relativ wenig Aufwand erfordern. Wenn Sie sich nicht sicher sind, was Sie schreiben sollen, [beginnen Sie mit unserem E-Mail-Generator](/email-builder). Wenn Sie ein Treffen erhalten, sollten Sie unsere [Lobby-Tipps](/lobby-tips) lesen.
- **Rufen Sie Ihre Abgeordneten an**: Versuchen Sie, die Büros der Gesetzgeber anzurufen, während Sie einen Satz von Gesprächspunkten im Blick haben, um auf dem Thema zu bleiben.
- **Protestieren Sie**: Nehmen Sie an [einer der Proteste](https://pauseai.info/protests) teil oder [organisieren Sie selbst einen](https://pauseai.info/organizing-a-protest).
- **Unterzeichnen Sie Petitionen**: [Internationaler KI-Vertrag](https://aitreaty.org), [Verbot von Superintelligenz](https://chng.it/Djjfj2Gmpk), [Forderung nach verantwortungsvoller KI](https://www.change.org/p/artificial-intelligence-time-is-running-out-for-responsible-ai-development-91f0a02c-130a-46e1-9e55-70d6b274f4df) oder eine der **nationalen Petitionen**: [UK](https://petition.parliament.uk/petitions/639956), [AUS](https://www.aph.gov.au/e-petitions/petition/EN5163), [NL](https://aipetitie.nl).

### Informieren Sie Menschen in Ihrer Umgebung {#inform-people-around-you}

- **Teilen Sie Informationen über KI-Risiken** auf Ihren sozialen Medien. Eines [dieser Videos](https://www.youtube.com/watch?v=xBqU1QxCao8&list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt) oder diese Website kann ein guter Anfang sein. Und vergessen Sie nicht, uns in Ihren Beiträgen zu markieren.
- **Sprechen Sie mit Menschen in Ihrem Leben** über KI-Sicherheit. Beantworten Sie ihre Fragen und ermutigen Sie sie, auch zu handeln. Verwenden Sie unsere [Gegenargumente](/counterarguments), um überzeugender zu sein.
- **[Infostände](/tabling) und [Flyer-Verteilung](/flyering)** sind großartige Möglichkeiten, viele Menschen in kurzer Zeit zu erreichen.
- **Besuchen Sie lokale Veranstaltungen**: Viele Städte haben (kostenlose oder kostengünstige) Veranstaltungen über KI und Technologiepolitik. Die Teilnahme an diesen Veranstaltungen ist eine großartige Möglichkeit, Kontakte zu knüpfen und Ihre Bedenken zu teilen. Wenn Sie KI-Sicherheits-Marketingmaterial benötigen, kontaktieren Sie uns auf [Discord](https://discord.gg/2XXWXvErfA), damit wir Ihnen einige senden können.

### Unterstützen Sie PauseAI {#support-pauseai}

- **Treten Sie einer [lokalen PauseAI-Community](/communities) bei** oder gründen Sie eine.
- **Treten Sie dem [Discord](https://discord.gg/2XXWXvErfA) bei**, wo die meisten Zusammenarbeitsaktivitäten stattfinden.
- **Protestieren Sie oder nehmen Sie an [Veranstaltungen](/events) teil**. Wenn kein Protest in Ihrer Nähe stattfindet, sollten Sie [einen starten](/organizing-a-protest).
- **Überprüfen Sie unsere [Stellenangebote](/vacancies)**, um zu sehen, ob Ihre Fähigkeiten unseren organisatorischen Bedürfnissen entsprechen. Wir suchen oft nach Menschen mit Erfahrung in sozialen Medien, Kommunikation, Organisation, Öffentlichkeitsarbeit und Software. Einige Positionen sind bezahlt.
- **[Melden Sie sich als Freiwilliger an](https://airtable.com/appWPTGqZmUcs3NWu/pag7ztLh27Omj5s2n/form)**, damit wir Projekte in Ihren Interessengebieten finden können.
- [**Spenden Sie**](/donate) an PauseAI oder kaufen Sie Merchandise in unserem [Shop](https://pauseai-shop.fourthwall.com/).
- **Folgen Sie unseren [sozialen Medien-Kanälen](https://linktr.ee/pauseai)** und bleiben Sie auf dem Laufenden. Ihr lokales PauseAI-Kapitel kann auch eigene soziale Medien-Seiten haben.

## Für bestimmte Personen {#for-specific-people}

### Wenn Sie im Bereich KI arbeiten {#if-you-work-in-ai}

- **Arbeiten Sie nicht an KI-Systemen, die Risiken bergen**: Arbeiten Sie nicht für Unternehmen oder Forschungseinrichtungen, die KI-Systeme entwickeln, die Risiken für die Menschheit bergen. Und verbreiten Sie keine Ideen darüber, wie wir KI-Systeme schneller oder intelligenter machen können.
- **Sprechen Sie mit Ihrem Management und Ihren Kollegen** über die Risiken. Bringen Sie sie dazu, eine institutionelle Position zu beziehen, um Risiken zu mindern und nicht den Profit zu priorisieren. Ermutigen Sie die Implementierung von Standard-Risikominderungsverfahren und anonymen Meldungen.
- **Halten Sie ein Seminar** über KI-Sicherheit an Ihrem Arbeitsplatz. Überprüfen Sie diese [Folien](https://drive.google.com/drive/u/1/folders/1p9VtopzMV6Xpk4p6EGYUTna4fLE6G8hd) und [Vorträge und Videos](https://www.youtube.com/playlist?list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt) für Inspiration.
- **Unterzeichnen Sie** die [Erklärung zu KI-Risiken](https://www.safe.ai/statement-on-ai-risk).

### Wenn Sie Politiker oder Regierungsmitarbeiter sind {#if-you-are-a-politician-or-work-in-government}

- **Bereiten Sie sich auf den nächsten [KI-Sicherheitsgipfel](/summit) vor**. Bilden Sie Koalitionen mit anderen Ländern, um Sicherheitsinformationen auszutauschen und schnell zu handeln, wenn Schäden auftreten. Arbeiten Sie auf einen globalen Vertrag hin.
- **Laden Sie (oder laden Sie vor) KI-Laborleiter** zu parlamentarischen/parlamentarischen Anhörungen ein, um ihre Vorhersagen und Zeitpläne für KI-Katastrophen zu geben.
- **Einrichten Sie einen Ausschuss**, um die [Risiken von KI](/risks) zu untersuchen. Veröffentlichen Sie die Ergebnisse, wenn möglich.
- **Machen Sie KI-Sicherheit zu einer Priorität** in der Plattform Ihrer Partei, der Politik Ihrer Regierung oder stellen Sie sicher, dass es auf der Agenda steht.
- **Arbeiten Sie mit oppositionellen Politikern** zusammen, um zu demonstrieren, dass KI-Sicherheit uns alle betrifft, unabhängig von politischen Überzeugungen.

### Wenn Sie Erfahrung im (internationalen) Recht haben {#if-you-have-experience-with-international-law}

- **Helfen Sie bei der Erstellung von Richtlinien**. [Beispiele für Entwürfe](https://www.campaignforaisafety.org/celebrating-the-winners-law-student-moratorium-treaty-competition/). ([einige](https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf) [Rahmenbedingungen](https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/))
- **Machen Sie Einreichungen** zu Regierungsanfragen für Kommentare zu KI-Richtlinien ([Beispiel](https://ntia.gov/issues/artificial-intelligence/request-for-comments)).

### Wenn Sie als Journalist oder soziale Medien-Persönlichkeit arbeiten {#if-you-work-as-a-journalist-or-have-a-social-media-following}

- **Erstellen Sie Inhalte** über KI-Gefahren oder PauseAI. Für weitere Informationen kontaktieren Sie uns über einen unserer [Kommunikationskanäle](/faq#do-you-have-social-media).