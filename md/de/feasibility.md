

Möglichkeit einer Pause
=====================

Eine Pause bei der Entwicklung von künstlicher Intelligenz (KI) ist nicht unmöglich. Die Festlegung einer roten Linie, die bestimmt, welche Art von Technologien und Aktionen entwickelt und durchgeführt werden dürfen, ist etwas, was wir ständig tun.

Politische Machbarkeit einer Pause
--------------------------------

Einige haben die Pause als "radikal" oder "extrem" bezeichnet, aber das ist nicht die Meinung der Öffentlichkeit. Verschiedene [Umfragen und Studien](/polls-and-surveys) haben gezeigt, dass:

* Die Menschen sehr besorgt über KI sind (hauptsächlich wegen der Sicherheit)
* Die überwiegende Mehrheit (fast 70%) [eine Pause bei der KI-Entwicklung unterstützt](https://www.sentienceinstitute.org/aims-survey-supplement-2023)
* Die überwiegende Mehrheit (>60%) [einen internationalen Vertrag zum Verbot von AGI unterstützt](https://www.sentienceinstitute.org/aims-survey-supplement-2023)

Technische Durchsetzbarkeit einer Pause
--------------------------------------

Der einfachste Weg, um Vorreiter-Modelle zu regulieren, besteht darin, [die Rechenleistung zu steuern](https://www.governance.ai/post/computing-power-and-the-governance-of-ai). Wir können [GPUs verfolgen](https://arxiv.org/abs/2303.11341), wie wir Elemente verfolgen, die bei der Entwicklung von Nuklearwaffen verwendet werden. Glücklicherweise hat die Lieferkette für Rechenleistung verschiedene Engpässe. Die Hardware, die für die Ausbildung der größten Modelle benötigt wird (spezialisierte GPUs), wird von [nur 1 oder 3 Unternehmen](https://assets-global.website-files.com/614b70a71b9f71c9c240c7a7/65cb86a0341180453f268f38_SpwF1cBT0AS-m_n20TBXzCF6YprIVM4YRb9PMYWURseU1KtVkSAZJ735esGxNenwVO4Q4wlSUP-_MV3E-SEKp4SIgo1-oNe14CeDHtrb3PLXpJMym5qpWEDbXcf3maEi4yQYfQ-3NP7XgUmkO_4Zekw.jpeg) produziert.

Macht über Unternehmen
----------------------

Wenn Sie hauptsächlich Unternehmen oder Organisationen fürchten, können wir sie über 1) Gesetze, Vorschriften und Verträge oder 2) öffentliche Meinung, die sie dazu zwingt, sich selbst zu regulieren, kontrollieren.

Natürlich ist die erste Methode die bessere, aber der Ruf, der Kunden, Investoren, Mitarbeitermoral und Rekrutierung beeinflusst, ist ein Grund, warum wir Proteste vor einigen KI-Labors organisieren. Es ist auch wichtig zu beachten, dass Vorschriften Unternehmen langfristig nützen können, da sie aufgrund von Regulierungskapital nicht die Verbraucher verlieren, wenn die Gefahren real werden, und Konkurrenten benachteiligen.

Macht über Regierungen
----------------------

Wenn Sie befürchten, dass Regierungen Ihre Sicherheit nicht ernst nehmen, ist das ein komplizierteres Problem. Aber im Allgemeinen kümmern sich Politiker darum, politische Unterstützung nicht zu verlieren. Und wichtiger noch, sie können auch besorgt über die Risiken sein, ohne die enorme Voreingenommenheit und rechtlichen Verpflichtungen, die einige Einzelpersonen aus Unternehmen haben, um Gewinne zu maximieren.

Wenn Sie denken, dass wir die Regulierung einer einzelnen Regierung erreichen könnten, aber nicht einen multilateralen Vertrag, müssen Sie erkennen, dass, wenn Regierungen erkennen, dass einige unkontrollierbare Technologien eine Gefahr für ihre Bevölkerung darstellen und aus anderen Nationen stammen können, die neuen Technologien zu einem nationalen Sicherheitsproblem werden und die Regierungen daran interessiert sind, andere Länder daran zu hindern, sie zu entwickeln.

Ähnliche historische Fälle
---------------------------

Obwohl jeder Beweis für Inkompetenz oder Bosheit unserer Regierungen, Unternehmen und Systeme uns in eine Niederlage locken kann, wo Koordination zu schwierig ist, die Interessen der Menschen nicht gut vertreten sind und/oder vertreten sind, aber dumm sind, erkennen wir manchmal nicht die Siege, die wir als Zivilisation throughout Geschichte errungen haben.

Für empirische Beweise dafür, dass ein Vertrag wie dieser möglich ist, sollten wir uns auf vergangene globale Vereinbarungen konzentrieren. Ob formell oder informell, sie waren in der Geschichte ziemlich häufig, hauptsächlich um Streitigkeiten zu lösen und Menschenrechte zu fördern. Viele vergangene Siege, wie die Abschaffung der Sklaverei, hatten auch starke, kurzfristige wirtschaftliche Anreize gegen sie. Aber das hat sie nicht aufgehalten.

Wenn wir nach ähnlichen modernen Beispielen für globale Vereinbarungen gegen neue Technologien suchen, können wir viele finden. Einige der wichtigsten waren:

* Das [Montreal-Protokoll](https://de.wikipedia.org/wiki/Montrealer_Protokoll), das die Produktion von FCKWs in allen 197 Ländern verbot und dazu führte, dass die globalen Emissionen von ozonabbauenden Substanzen seit 1986 um mehr als 99% zurückgegangen sind. Dank des Protokolls heilt die Ozonschicht jetzt, und das ist der Grund, warum wir nichts mehr darüber hören.
* Die [Biowaffenkonvention](https://de.wikipedia.org/wiki/Biowaffenkonvention), die biologische und Toxin-Waffen verbot und von 185 Staaten unterzeichnet wurde.
* Die [Chemiewaffenkonvention](https://de.wikipedia.org/wiki/Chemiewaffenkonvention), die chemische Waffen verbot und von 193 Staaten unterzeichnet wurde.
* Die [Umweltänderungskonvention](https://de.wikipedia.org/wiki/Umweltänderungskonvention), die Wetterkrieg verbot und von 78 Staaten unterzeichnet wurde.
* Der [Weltraumvertrag](https://de.wikipedia.org/wiki/Weltraumvertrag), der die Stationierung von Massenvernichtungswaffen im Weltraum verbot, militärische Aktivitäten auf Himmelskörpern verbot, die friedliche Erforschung und Nutzung des Weltraums rechtlich bindend machte und von 114 Ländern unterzeichnet wurde.
* Der [Nichtverbreitungsvertrag](https://de.wikipedia.org/wiki/Vertrag_über_die_Nichtverbreitung_von_Kernwaffen) und eine Reihe anderer internationaler Vereinbarungen, die Schlüsselrolle bei der Verhinderung der Verbreitung von Nuklearwaffen und der Förderung des Ziels der nuklearen Abrüstung gespielt haben. Dank ihnen haben wir viele Länder davon abgehalten, Nuklearwaffenprogramme zu verfolgen, die Menge an Nuklearwaffen seit den 90er Jahren reduziert und einen Nuklearkrieg für viele Jahrzehnte vermieden. Alle unglaublichen Errungenschaften.
* Die [Internationale Atomenergie-Organisation](https://de.wikipedia.org/wiki/Internationale_Atomenergie-Organisation), eine zwischenstaatliche Organisation, die aus 178 Mitgliedstaaten besteht und sich für die friedliche Nutzung von Kernenergie einsetzt und ihre Verwendung für militärische Zwecke verhindern will. Unabhängig davon, ob Sie denken, dass Kernenergie überreguliert ist oder nicht, gilt die IAEO als gutes Beispiel für ein internationales Instrument, das wir haben könnten, um die Sicherheit der größten KI-Modelle zu bewerten.
* Und die [Erklärung der Vereinten Nationen über das Klonen von Menschen](https://de.wikipedia.org/wiki/Erklärung_der_Vereinten_Nationen_über_das_Klonen_von_Menschen), die die Mitgliedstaaten aufforderte, das Klonen von Menschen im Jahr 2005 zu verbieten und viele von ihnen dazu brachte, es zu tun. Es ist ein interessanter Fall, weil jetzt, fast 20 Jahre später und ohne eine formelle Vereinbarung, 60 Länder es entweder vollständig oder teilweise verboten haben und es keinen einzigen (verifizierten) Fall eines geklonten Menschen gegeben hat. Also legt es nahe, dass die Möglichkeit besteht, dass viele einseitige Regulierungen ausreichen, um andere gefährliche Technologien zu verhindern.

Wenn Sie denken, dass KI tatsächlich ähnlich wie andere Fälle ist, in denen wir es nicht geschafft haben, gute Verträge international zu schließen: Alles, was jemals passiert ist, hatte ein erstes Mal. Es gab Besonderheiten, die sie zum ersten Mal machten, und das ist ein Grund, die [Besonderheiten von KI](#ki-besonderheiten) anzusprechen.

Auswirkungen von Protesten
-------------------------

Es ist ziemlich häufig, dass Menschen die Wirksamkeit von Protesten und sozialen Bewegungen im Allgemeinen in Frage stellen. Natürlich gibt es viele Fälle, in denen Demonstrationen keine Ergebnisse liefern, aber es gibt auch Situationen, in denen die Forderungen der Demonstranten erfüllt werden und es wahrscheinlich ist, dass diese Ergebnisse [durch die Proteste verursacht wurden](https://www.socialchangelab.org/_files/ugd/503ba4_052959e2ee8d4924934b7efe3916981e.pdf). Und [es gibt Gründe zu glauben, dass KI-Aktivismus ähnliche Ergebnisse erzielen könnte](https://forum.effectivealtruism.org/posts/WfodoyjePTTuaTjLe/efficacy-of-ai-activism-have-we-ever-said-no).

Wenn Sie die Idee des Protestierens nicht mögen, unternehmen wir auch [andere Aktionen](/action), wie den direkten Kontakt mit [Regierungen](/lobby-tips).

KI-Besonderheiten
-----------------

Wenn Sie denken, dass KI anders genug ist als diese Fälle (oder sogar wenn Sie es nicht tun), ist es nützlich, ihre besondere Situation zu analysieren. Die Dinge, die KI anders machen, müssen nicht unbedingt dazu führen, dass sie weniger regulierbar ist. Zum Beispiel versuchen wir nicht, bestehende Produkte und Dienstleistungen zu regulieren, die Menschen bereits nutzen und regelmäßig verwenden, und wir gehen nicht gegen viele Unternehmen vor, die Lobbyarbeit leisten oder Arbeitnehmer, die ihre Jobs verlieren würden, wenn wir erfolgreich sind. Ziemlich das Gegenteil.

Ein weiterer Punkt, der für uns spricht, ist, dass die Öffentlichkeit nicht parteiisch oder politisch gespalten ist, sondern [vereint in der Unterstützung von Regulierungen](https://drive.google.com/file/d/1n0pXDBuIcb01tW4TQdP1Mb5aAiFDvWk0/view). Trotzdem müssen wir vorsichtig sein, sie nicht zu verprellen, ihre Perspektiven zu hören und zu sehen, auf welche Weise sie durch eine Pause unterstützt werden können, basierend auf dem, was ihnen wichtig ist. Da viele Menschen noch nicht entschieden haben, welche Art von Regulierung sie unterstützen.

Wenn es um KI-Risiken geht, scheinen die Öffentlichkeit und die Experten [besorgt über die Risiken und interessiert an Regulierungen](/polls-and-surveys) zu sein. Die Politiker, basierend auf den [Richtlinien, die verabschiedet werden und in Arbeit sind](https://www.bloomberg.com/news/articles/2024-03-13/regulate-ai-how-us-eu-and-china-are-going-about-it), den [Gipfeln, die sie organisieren](/summit), und den [Erklärungen, die sie abgeben](/quotes), scheinen ziemlich besorgt zu sein. Sogar ein aktueller [Bericht der US-Regierung](https://time.com/6898967/ai-extinction-national-security-risks-report/) empfiehlt unter mehreren Vorschlägen verschiedene Arten von Pausen bei der KI-Entwicklung, um Risiken für die nationale Sicherheit und die Menschheit als Ganzes zu vermeiden.

All dies geschieht, während PauseAI noch ziemlich jung ist und die meisten Menschen noch nicht von den meisten Risiken gehört haben. Wenn wir das Bewusstsein und die Übereinstimmung über existenzielle Risiken erhöhen würden, hätten wir das Potenzial, mainstream zu werden, da praktisch niemand sterben oder die Welt untergehen lassen will. Das ist nicht einmal im besten Interesse der egoistischsten Unternehmen, Regierungen und Menschen.

Kollaterale Vorteile
-------------------

Für eine Pause einzutreten hat andere positive Auswirkungen außerhalb ihrer Erreichung. Die Information der Öffentlichkeit, der Technologie-Experten und der Politiker über die Risiken hilft anderen Interventionen, die darauf abzielen, sichere KI und KI-Sicherheit zu schaffen. Es veranlasst Menschen, der technischen, politischen und kommunikativen Arbeit, die in KI-Sicherheit und KI-Ethik investiert wird, mehr Bedeutung beizumessen, was letztendlich bedeutet, dass mehr Mittel und Arbeitsplätze in sie investiert werden, mit dem Ziel, bessere Ergebnisse zu erzielen.

Es würde nicht nur neue Menschen und Ressourcen für neue Interventionen bringen, sondern auch dazu beitragen, moderate technische und politische Initiativen als "vernünftiger" erscheinen zu lassen und ihre Chancen auf Unterstützung zu erhöhen.

Darüber hinaus könnte es die Menschen auf die Gefahren vorbereiten, sie lehren, wie man KI ethischer nutzt, und sie sogar davon überzeugen, nicht in Vorreiter- und unsichere Projekte zu investieren oder daran zu arbeiten.

Geben Sie nicht dem Pessimismus nach
--------------------------------

Wir verstehen, woher die pessimistischen Überzeugungen über starke Regulierungen kommen und dass es nicht einfach sein wird. Aber es ist auch nicht einfach, die Zukunft vorherzusagen, und dieser Artikel versucht, gegen die Überzeugung unserer Machtlosigkeit zu argumentieren, da dies nur als sich selbst erfüllende Prophezeiung dienen kann.

Das einzige, was einfach zu tun ist, ist aufzugeben, [es ist der einfache Ausweg](/psychology-of-x-risk#difficult-to-act-on). Denn wenn es nichts gibt, was wir tun können, gibt es nichts, was wir tun sollten. Aber wir sollten nicht aufgeben, ohne es zu versuchen. Dies ist tatsächlich unsere beste Chance, einen Einfluss auf die Welt und die Zukunft unserer Zivilisation zu haben.

Die Entscheidungstheorie sagt: Versuchen Sie es trotzdem
---------------------------------------------------

Selbst wenn Sie glauben, dass eine Pause ziemlich unwahrscheinlich ist und Sie sich nicht um die anderen Vorteile kümmern, empfehlen wir Ihnen, [sich anzuschließen](/join). Vergraben Sie Ihren Kopf nicht in den Sand und warten Sie auf den Tod oder die Rettung, Sie können uns helfen, dies zu erreichen!