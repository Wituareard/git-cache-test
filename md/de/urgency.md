---
title: Warum wir möglicherweise früher als die meisten denken eine Superintelligenz haben werden
description: Wir unterschätzen den Fortschritt der KI, und es besteht eine kleine, aber realistische Chance, dass wir sehr nahe an einer Superintelligenz sind.
date: '2023-05-04'

Aktuelle [State-of-the-Art](/sota)-KI-Modelle sind bereits in vielen Bereichen übermenschlich, aber glücklicherweise nicht in allen.
Wenn wir die Superintelligenz erreichen, bevor wir das Alignmentsproblem lösen, [droht uns ein Aussterberisiko](/xrisk).
Daher ist es wichtig, einen geschätzten Zeitraum zu haben, wann wir möglicherweise eine Superintelligenz haben werden, um sicherzustellen, dass wir nicht überrascht werden.
Wenn unsere Vorhersagen zu weit entfernt sind, können wir uns möglicherweise nicht rechtzeitig vorbereiten.

Aber wie weit entfernt sind wir?
Wann werden wir eine Superintelligenz haben?
Es könnte früher sein als die meisten denken.

## Exponentielles Wachstum durch Kombination von Faktoren

KI-Modelle benötigen Algorithmen, Daten und Chips.
Jeder dieser Komponenten verbessert sich rasant aufgrund enormer Investitionen in die KI.
Die Verbesserungen in jedem dieser Komponenten summieren sich auf und führen zu exponentiellem Wachstum in den Fähigkeiten der KI.

- **Mehr Chips**. ChatGPT wurde auf [10.000](https://www.fierceelectronics.com/sensors/chatgpt-runs-10k-nvidia-training-gpus-potential-thousands-more) spezialisierten Chips trainiert. Meta hat [angekündigt](https://www.datacenterdynamics.com/en/news/meta-to-operate-600000-gpus-by-year-end/), dass sie 600.000 Next-Gen-Chips haben werden, um ihre nächsten KI-Modelle dieses Jahr zu trainieren.
- **Schnellere Chips**. Jedes Jahr werden Chips aufgrund neuer Architekturen und Lithographie-Innovationen schneller. Die Chips, die Meta verwendet, sind 10-mal schneller als die Chips, die für ChatGPT verwendet wurden. Wir sehen auch hochspezialisierte Hardware wie die Groq-Chips, die [13-mal schneller](https://mezha.media/en/2024/02/22/groq-s-new-ai-chip-offers-to-increase-chatgpt-speed-by-13-times/) sind als die Konkurrenz. Auf einem längeren Zeitraum könnten [ternäre Architekturen](https://arxiv.org/pdf/2402.17764.pdf) oder [photonische Chips](https://www.nature.com/articles/s41566-024-01394-2) Chips noch schneller machen.
- **Mehr Daten**. GPT3 wurde auf [45 TB](https://community.openai.com/t/what-is-the-size-of-the-training-set-for-gpt-3/360896) Text trainiert, GPT4 verwendete etwa 20-mal so viel. KI-Unternehmen verwenden jetzt auch [riesige Mengen an Videodaten](https://www.404media.co/nvidia-ai-scraping-foundational-model-cosmos-project/), Audiodaten und generieren sogar [synthetische Daten, um diese Modelle zu trainieren](https://arxiv.org/pdf/2401.10020). Früher wurde die Idee, synthetische Daten für das Training zu verwenden, als unmöglich angesehen, da das Modell zusammenbricht, aber [neue Fortschritte](https://arxiv.org/abs/2406.07515) zeigen, dass es möglich ist, das Modellkollaps zu verhindern.
- **Bessere Daten**. Die "Textbooks are all you need"-Studie [zeigte](https://arxiv.org/abs/2306.11644), dass die Verwendung von hochwertigen synthetischen Daten die Modellleistung drastisch verbessern kann, selbst wenn weniger Daten und Rechenleistung verwendet werden.
- **Bessere Algorithmen**. Die Transformer-Architektur ermöglichte die aktuelle LLM-Revolution. Neue Architekturen können ähnliche Fähigkeitssprünge ermöglichen. Das Mamba-Modell zeigt beispielsweise [5-mal schnellere Durchsatzraten](https://arxiv.org/abs/2312.00752).
- **Bessere Laufzeiten**. Agentic-Laufzeiten, Retrieval-Augmented-Generation oder einfach cleveres Prompting (durch [Graph of Thought](https://arxiv.org/abs/2305.16582) zum Beispiel) können einen großen Einfluss auf die Fähigkeiten dieser Modelle haben.

Es ist durchaus möglich, dass das _einfache Skalieren_ uns in einem Jahr oder zwei zu [gefährlichen Fähigkeiten](/dangerous-capabilities) bringt, aber mit all diesen kombinierten Faktoren könnte es noch früher sein.

## Wir haben 2023 menschliches Leistungsniveau in vielen Bereichen erreicht

Im Jahr 2022 dachten KI-Forscher, dass es [17 Jahre](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dauern würde, bis KI in der Lage wäre, einen New-York-Times-Bestseller zu schreiben.
Ein Jahr später gewann ein chinesischer Professor einen Schreibwettbewerb mit einem von KI geschriebenen Buch.

Auf Metaculus war [die Gemeinschaftsvorhersage für (schwache) AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) vor drei Jahren 2057, und jetzt ist es ~~2027~~ 2026.

Lassen Sie uns nun auf die Definition von AGI eingehen