

---
title: Fähigkeiten moderner KI-Systeme im Vergleich zum Menschen
description: Wie intelligent sind die neuesten KI-Modelle im Vergleich zu Menschen?
---
Wie intelligent sind die neuesten KI-Modelle im Vergleich zu Menschen?
Lassen Sie uns einen Blick darauf werfen, wie die kompetentesten KI-Systeme in verschiedenen Bereichen im Vergleich zu Menschen abschneiden.
Die Liste unten wird regelmäßig aktualisiert, um die neuesten Entwicklungen widerzuspiegeln.

_Letztes Update: 2024-09-16_

## Übermenschlich (Besser als alle Menschen) {#superhuman-better-than-all-humans}

- **Spiele**: Bei vielen Spielen ([Schach, Go](https://en.wikipedia.org/wiki/AlphaGo_Zero), Starcraft, Dota, [Gran Turismo](https://www.technologyreview.com/2022/07/19/1056176/sonys-racing-ai-destroyed-its-human-competitors-by-being-nice-and-fast/) usw.) ist die beste KI besser als der beste Mensch.
- **Arbeitsgedächtnis**: Ein durchschnittlicher Mensch kann etwa 7 Elemente (wie Zahlen) gleichzeitig merken. Gemini 1.5 Pro [kann 99% von 7 Millionen Wörtern lesen und merken](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note).
- **Lesegeschwindigkeit**: Ein Modell wie Gemini 1.5 Pro kann ein ganzes Buch in 30 Sekunden lesen. Es kann eine völlig neue Sprache lernen und Texte in einer halben Minute übersetzen.
- **Denkgeschwindigkeit**: KI-Modelle können mit Geschwindigkeiten schreiben, die weit über denen von Menschen liegen, und ganze Computerprogramme in Sekunden schreiben.
- **Wissensumfang**: Moderne LLMs wissen weit mehr als jeder Mensch, ihr Wissen umfasst praktisch jeden Bereich. Es gibt keinen Menschen, dessen Wissensbreite auch nur annähernd kommt.
- **Speichereffizienz**: GPT-4 hat etwa [1,7 Billionen Parameter](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/) (Neuronenverbindungen), während Menschen [etwa 100 bis 1000 Mal so viele Synapsen](https://www.jax.org/news-and-insights/jax-blog/2018/December/600-trillion-synapses-and-alzheimers-disease) (Neuronenverbindungen) haben. GPT-4 weiß jedoch Tausende Male mehr und speichert mehr Informationen in einer kleineren Anzahl von Parametern.

## Besser als die meisten Menschen {#better-than-most-humans}

- **Sprache**: Die besten Sprachmodelle können praktisch alle Sprachen fließend übersetzen, haben übermenschliches Vokabular und können in vielen verschiedenen Stilen schreiben. Im Dezember 2023 gewann ein von einer KI geschriebener Roman einen Preis bei einem [nationalen Wettbewerb für Science-Fiction](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award?campaign=3245725&module=perpetual_scroll_0&pgtype=article). Der Professor, der die KI verwendete, erstellte die Erzählung aus einem Entwurf von 43.000 Zeichen, der in nur drei Stunden mit 66 Eingaben generiert wurde.
- **Argumentationsfähigkeit**: o1 [antwortet korrekt auf 78%](https://openai.com/index/learning-to-reason-with-llms/) der GPQA-Diamantenfragen und übertrifft damit menschliche Fachexperten (PhDs), die nur 69,7% erreichen.
- **Kreativität**: Besser als 99% der Menschen bei den [Torrance-Tests für kreatives Denken](https://neurosciencenews.com/ai-creativity-23585/), bei denen relevante und nützliche Ideen generiert werden müssen. Die Tests waren jedoch relativ klein, und für größere Projekte (z.B. die Gründung eines neuen Unternehmens) ist die KI noch nicht autonom genug.
- **Überzeugungskraft**: GPT-4 konnte mit Zugriff auf persönliche Informationen die Zustimmung der Teilnehmer zu den Argumenten ihrer Gegner um bemerkenswerte [81,7 Prozent](https://arxiv.org/abs/2403.14380) erhöhen, verglichen mit Debatten zwischen Menschen - fast doppelt so überzeugend wie die menschlichen Debattierer.
- **Intelligenzquotient**: Bei verbalen IQ-Tests übertrafen LLMs seit einiger Zeit 95 bis 99% der Menschen (Wert zwischen [125](https://medium.com/@soltrinox/the-i-q-of-gpt4-is-124-approx-2a29b7e5821e) und [155](https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/)). Bei non-verbalen (Mustererkennungs-) IQ-Tests erreichte das o1-Preview-Modell von 2024 [120 Punkte im Mensa-Test](https://www.maximumtruth.org/p/massive-breakthrough-in-ai-intelligence), womit es 91% der Menschen übertraf.
- **Spezialwissen**: GPT-4 erreicht 75% im [Medical Knowledge Self-Assessment Program](https://openai.com/research/gpt-4), Menschen im Durchschnitt zwischen [65 und 75%](https://pubmed.ncbi.nlm.nih.gov/420438/). Es schneidet besser ab als [68](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) bis [90%](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/) der Jurastudenten bei der Anwaltsprüfung.
- **Kunst**: Bildgenerierungsmodelle haben [Kunst-](https://dataconomy.com/2022/09/26/ai-artwork-wins-art-competition) und sogar [Fotowettbewerbe](https://www.artnews.com/art-news/news/ai-generated-image-world-photography-organization-contest-artist-declines-award-1234664549) gewonnen.
- **Forschung**: GPT-4 kann [autonome chemische Forschung](https://www.nature.com/articles/s41586-023-06792-0) betreiben, und DeepMind hat eine KI entwickelt, die [eine Lösung für ein offenes mathematisches Problem gefunden hat](https://www.nature.com/articles/s41586-023-06924-6). Diese Architekturen erfordern jedoch viel menschliches Engineering und sind nicht allgemein einsetzbar.
- **Programmierung**: o1 schlägt [93% der menschlichen Coder](https://medium.com/@marcelinohambali/tech-review-openai-o1-strawberry-a-new-phd-reasoning-model-783e88734d84) im Codeforces-Wettbewerb. KI-Modelle können Code in fast jeder Programmiersprache schreiben. Devin kann [13% der Codierprobleme lösen](https://twitter.com/cognition_labs/status/1767548763134964000) und kann [Geld auf Upwork verdienen](https://twitter.com/cognition_labs/status/1767548768734294113).
- **Hacking**: GPT-4 kann [autonom Websites hacken](https://arxiv.org/html/2402.06664v1) und [schlägt 89% der Hacker](https://arxiv.org/pdf/2402.11814.pdf) in einem Capture-the-Flag-Wettbewerb. Glücklicherweise scheitern SOTA-Modelle noch an wesentlichen Aufgaben, die für autonome Selbstreplikation erforderlich sind (siehe unten).
- **Mathematik**: o1 platziert sich unter den besten 500 Schülern in den USA in einem Qualifikationstest für die USA-Mathematik-Olympiade (AIME).

## Schlechter als die meisten Menschen {#worse-than-most-humans}

- **"Ich weiß nicht" sagen**. Praktisch alle großen Sprachmodelle haben dieses Problem der "Halluzination", also das Erfinden von Informationen, anstatt zu sagen, dass sie es nicht wissen. Dies mag wie ein relativ kleiner Mangel erscheinen, aber es ist ein sehr wichtiger. Es macht LLMs unzuverlässig und limitiert ihre Anwendbarkeit stark. Studien [zeigen](https://arxiv.org/html/2403.04307v1) jedoch, dass größere Modelle weit weniger halluzinieren als kleinere.
- **Ein überzeugender Mensch sein**. GPT-4 kann [54% der Menschen davon überzeugen](https://arxiv.org/abs/2405.08007), dass es ein Mensch ist, aber Menschen können dies 67% der Zeit. Mit anderen Worten, GPT-4 besteht den Turing-Test noch nicht konsequent.
- **Geschickte Bewegung**. Kein Roboter kann sich wie ein Mensch bewegen, aber wir kommen näher. Der [Atlas-Roboter kann gehen, Objekte werfen und Saltos machen](https://www.youtube.com/watch?v=-e1_QhJ1EhQ). Googles [RT-2](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) kann Ziele in der realen Welt in Aktionen umsetzen, wie "den Becher zum Weinflasche bewegen". Teslas Optimus-Roboter kann [Kleidung falten](https://electrek.co/2024/01/15/tesla-optimus-robot-cant-build-cars-folding-clothes/) und der bipede Roboter von Figure kann [Kaffee kochen](https://www.youtube.com/watch?v=Q5MKo7Idsok).
- **Selbstreplikation**. Alle Lebewesen auf der Erde können sich selbst replizieren. KI-Modelle könnten sich durch das Internet von Computer zu Computer verbreiten, aber dies erfordert eine Reihe von Fähigkeiten, die KI-Modelle noch nicht besitzen. Eine [Studie aus dem Jahr 2023](https://arxiv.org/abs/2312.11671) listet eine Reihe von 12 Aufgaben für die Selbstreplikation auf, von denen getestete Modelle 4 erfüllten. Wir möchten nicht herausfinden, [was passiert](/xrisk), wenn ein KI-Modell es schafft, sich selbst über das Internet zu verbreiten.
- **Kontinuierliches Lernen**. Aktuelle SOTA-LLMs trennen Lernen ("Training") von Tun ("Inferenz"). Obwohl LLMs mithilfe ihres Kontexts lernen können, können sie ihre Gewichte nicht aktualisieren, während sie verwendet werden. Menschen lernen und handeln gleichzeitig. Es gibt jedoch mehrere [mögliche Ansätze für kontinuierliches Lernen](https://arxiv.org/abs/2302.00487). Eine [Studie aus dem Jahr 2024](https://arxiv.org/html/2402.01364v2) beschrieb einige aktuelle Ansätze für kontinuierliches Lernen in LLMs.
- **Planung**. LLMs sind [noch nicht sehr gut bei der Planung (z.B. beim Nachdenken darüber, wie man Blöcke auf einem Tisch stapelt)](https://openreview.net/pdf?id=YXogl4uQUO). Größere Modelle performen jedoch wesentlich besser als kleinere.

## Der Endpunkt {#the-endpoint}

Mit fortschreitender Zeit und verbesserten Fähigkeiten verschieben wir Elemente von den unteren Abschnitten in den oberen Abschnitt.
Wenn bestimmte [gefährliche Fähigkeiten](/dangerous-capabilities) erreicht werden, wird die KI neue Risiken darstellen.
Irgendwann wird die KI jeden Menschen in jeder vorstellbaren Metrik überbieten.
Wenn wir diese Superintelligenz geschaffen haben, [werden wir wahrscheinlich bald tot sein](/ai-takeover).
Lasst uns eine [Pause implementieren](/proposal), um sicherzustellen, dass wir nicht so weit kommen.