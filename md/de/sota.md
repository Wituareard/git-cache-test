

---
title: Fähigkeiten moderner KI-Systeme im Vergleich zum Menschen
description: Wie intelligent sind die neuesten KI-Modelle im Vergleich zu Menschen?
---

Wie intelligent sind die neuesten KI-Modelle im Vergleich zu Menschen?
Lassen Sie uns einen Blick darauf werfen, wie die kompetentesten KI-Systeme in verschiedenen Bereichen im Vergleich zu Menschen abschneiden.
Die Liste unten wird regelmäßig aktualisiert, um die neuesten Entwicklungen widerzuspiegeln.

_Letzte Aktualisierung: 2024-09-16_

## Übermenschlich (Besser als alle Menschen)

- **Spiele**: Bei vielen Spielen (Schach, Go, Starcraft, Dota, Gran Turismo usw.) ist die beste KI besser als der beste Mensch.
- **Arbeitsgedächtnis**: Ein durchschnittlicher Mensch kann etwa 7 Elemente (wie Zahlen) gleichzeitig merken. Gemini 1.5 Pro kann 99% von 7 Millionen Wörtern lesen und merken.
- **Lesegeschwindigkeit**: Ein Modell wie Gemini 1.5 Pro kann ein ganzes Buch in 30 Sekunden lesen. Es kann eine völlig neue Sprache lernen und Texte in einer halben Minute übersetzen.
- **Denkgeschwindigkeit**: KI-Modelle können mit Geschwindigkeiten schreiben, die weit über denen von Menschen liegen, und ganze Computerprogramme in Sekunden schreiben.
- **Wissensumfang**: Moderne LLMs wissen weit mehr als jeder Mensch, ihr Wissen erstreckt sich auf nahezu jeden Bereich. Es gibt keinen Menschen, dessen Wissensbreite auch nur annähernd kommt.
- **Speichereffizienz**: GPT-4 hat etwa 1,7 Billionen Parameter (Neuronenverbindungen), während Menschen etwa 100 bis 1000 Mal so viele Synapsen (Neuronenverbindungen) haben. Allerdings weiß GPT-4 Tausende Male mehr und speichert mehr Informationen in einer kleineren Anzahl von Parametern.

## Besser als die meisten Menschen

- **Sprache**: Die besten Sprachmodelle können nahezu alle Sprachen fließend übersetzen, haben übermenschliches Vokabular und können in vielen verschiedenen Stilen schreiben. Im Dezember 2023 gewann ein von einer KI geschriebener Roman einen Preis bei einem nationalen Wissenschafts-Fiction-Wettbewerb. Der Professor, der die KI verwendete, erstellte die Erzählung aus einem Entwurf von 43.000 Zeichen, der in nur drei Stunden mit 66 Eingaben generiert wurde.
- **Argumentationsfähigkeit**: o1 beantwortet 78% der GPQA-Diamantenfragen korrekt, wodurch es menschliche Fachexperten (PhDs) übertrifft, die nur 69,7% erreichen.
- **Kreativität**: Besser als 99% der Menschen bei den Torrance-Tests für kreatives Denken, bei denen relevante und nützliche Ideen generiert werden müssen. Allerdings waren die Tests relativ klein und für größere Projekte (z.B. die Gründung eines neuen Unternehmens) ist die KI noch nicht autonom genug.
- **Überzeugungskraft**: GPT-4 konnte mit Zugriff auf persönliche Informationen die Zustimmung der Teilnehmer zu den Argumenten ihrer Gegner um 81,7% erhöhen, verglichen mit Debatten zwischen Menschen - fast doppelt so überzeugend wie die menschlichen Debattierer.
- **Intelligenzquotient**: Bei verbalen IQ-Tests haben LLMs seit einiger Zeit 95 bis 99% der Menschen übertroffen (Punktzahl zwischen 125 und 155). Bei nonverbalen (Mustererkennungs-) IQ-Tests erreichte das o1-Preview-Modell 2024 120 Punkte im Mensa-Test, wodurch es 91% der Menschen übertraf.
- **Spezialwissen**: GPT-4 erreicht 75% im Medical Knowledge Self-Assessment Program, Menschen im Durchschnitt zwischen 65 und 75%. Es schneidet besser ab als 68 bis 90% der Jurastudenten bei der Anwaltsprüfung.
- **Kunst**: Bildgenerierungsmodelle haben Kunst- und sogar Fotowettbewerbe gewonnen.
- **Forschung**: GPT-4 kann autonome chemische Forschung betreiben und DeepMind hat eine KI entwickelt, die eine Lösung für ein offenes mathematisches Problem gefunden hat. Allerdings erfordern diese Architekturen viel menschliches Engineering und sind nicht allgemein einsetzbar.
- **Programmierung**: o1 schlägt 93% der menschlichen Programmierer im Codeforces-Wettbewerb. KI-Modelle können Code in fast jeder Programmiersprache schreiben. Devin kann 13% der Codierprobleme lösen und kann Geld auf Upwork verdienen.
- **Hacking**: GPT-4 kann autonom Websites hacken und schlägt 89% der Hacker in einem Capture-the-Flag-Wettbewerb. Glücklicherweise scheitern SOTA-Modelle noch an wesentlichen Aufgaben, die für autonome Selbstreplikation erforderlich sind (siehe unten).
- **Mathematik**: o1 platziert sich unter den besten 500 Schülern in den USA in einem Qualifikationstest für die USA-Mathematik-Olympiade (AIME).

## Schlechter als die meisten Menschen

- **"Ich weiß nicht" sagen**: Virtuell alle großen Sprachmodelle haben dieses Problem der "Halluzination", also Informationen zu erfinden, anstatt zu sagen, dass sie es nicht wissen. Dies mag wie ein relativ kleiner Mangel erscheinen, aber es ist ein sehr wichtiger. Es macht LLMs unzuverlässig und schränkt ihre Anwendbarkeit stark ein. Allerdings zeigen Studien, dass größere Modelle weit weniger halluzinieren als kleinere.
- **Ein überzeugender Mensch sein**: GPT-4 kann 54% der Menschen davon überzeugen, dass es ein Mensch ist, aber Menschen können dies 67% der Zeit tun. Mit anderen Worten, GPT-4 besteht den Turing-Test noch nicht konsequent.
- **Geschickte Bewegung**: Kein Roboter kann sich wie ein Mensch bewegen, aber wir kommen näher. Der Atlas-Roboter kann gehen, Objekte werfen und Saltos machen. Googles RT-2 kann Ziele in die Tat umsetzen, wie "den Becher zum Weinflasche bewegen". Teslas Optimus-Roboter kann Kleidung falten und die bipede Figur kann Kaffee machen.
- **Selbstreplikation**: Alle Lebewesen auf der Erde können sich selbst replizieren. KI-Modelle könnten sich durch das Internet von Computer zu Computer verbreiten, aber dies erfordert eine Reihe von Fähigkeiten, die KI-Modelle noch nicht besitzen. Eine Studie aus dem Jahr 2023 listet eine Reihe von 12 Aufgaben für die Selbstreplikation auf, von denen getestete Modelle 4 erfüllten. Wir wollen nicht herausfinden, was passiert, wenn ein KI-Modell es schafft, sich selbst über das Internet zu verbreiten.
- **Kontinuierliches Lernen**: Aktuelle SOTA-LLMs trennen Lernen ("Training") von Tun ("Inferenz"). Obwohl LLMs mithilfe ihres Kontexts lernen können, können sie ihre Gewichte nicht aktualisieren, während sie verwendet werden. Menschen lernen und handeln gleichzeitig. Es gibt jedoch mehrere potenzielle Ansätze für kontinuierliches Lernen in LLMs. Eine Studie aus dem Jahr 2024 beschrieb einige aktuelle Ansätze für kontinuierliches Lernen in LLMs.
- **Planung**: LLMs sind noch nicht sehr gut bei der Planung (z.B. beim Nachdenken darüber, wie man Blöcke auf einem Tisch stapelt). Allerdings performen größere Modelle wesentlich besser als kleinere.

## Der Endpunkt

Mit fortschreitender Zeit und verbesserten Fähigkeiten verschieben wir Elemente von den unteren Abschnitten in den oberen Abschnitt.
Wenn bestimmte gefährliche Fähigkeiten erreicht werden, wird die KI neue Risiken darstellen.
Irgendwann wird die KI jeden Menschen in jeder vorstellbaren Metrik überbieten.
Wenn wir diese Superintelligenz gebaut haben, werden wir wahrscheinlich bald tot sein.
Lasst uns eine Pause einlegen, um sicherzustellen, dass wir nicht dorthin kommen.