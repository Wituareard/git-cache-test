

---
title: PauseAI-Protest @ FCDO, London, 13. Juli
---

- PauseAI-Protest, um den Sicherheitsrat der Vereinten Nationen dazu aufzufordern, eine globale Pause bei den größten KI-Trainingsläufen einzulegen.
- Wo: vor dem Foreign, Commonwealth and Development Office (FCDO), King Charles Street, Westminster, London, SW1A 2AH
- Wann: 13. Juli, 16:30 - 17:30 Uhr
- [Anmelden](https://docs.google.com/forms/d/e/1FAIpQLSfW_E_Q92EEdv6AwHdsEbyR66tOUByo-wFrc3SU4zIL6HTjxw/viewform?usp%253Dsf_link)

## Kontakt {#contact}

- Alistair Steward ([Twitter](https://twitter.com/alistair___s))

## Pressemitteilung: PauseAI protestiert vor dem Foreign Office vor dem UN-Sicherheitsratstreffen zu KI-Risiken {#press-release-pauseai-protests-foreign-office-ahead-of-un-security-council-meeting-on-ai-risk}

Am Donnerstag, dem 13. Juli, werden Freiwillige der neuen [PauseAI](http://pauseai.info/)-Bewegung vor dem Foreign Office in London zusammenkommen, um den UN-Sicherheitsrat dazu aufzufordern, eine Pause bei den Trainingsläufen der leistungsfähigsten KI-Systeme einzulegen. In einer [Pressekonferenz](https://youtu.be/USap-tFrTDc?t=3235) letzte Woche erklärte die britische Botschafterin und Präsidentin des Sicherheitsrates, Barbara Woodward: "Künstliche Intelligenz ist nicht selbst ein Akteur", was ein Mangel an technischer Expertise zeigt, der typisch für Regierungsbeamte ist und dazu führt, dass Risiken durch zukünftige KI-Systeme stark unterschätzt werden. Viele KI-Experten glauben, dass übermenschliche KI der menschlichen Kontrolle entkommen könnte, mit katastrophalen Folgen, einschließlich des Aussterbens der Menschheit. Der UN-Generalsekretär António Guterres [hat diese Bedrohung kürzlich anerkannt](https://press.un.org/en/2023/sgsm21832.doc.htm):

> "Die Alarmglocken über die neueste Form der künstlichen Intelligenz - generative KI - sind ohrenbetäubend, und sie sind am lautesten von den Entwicklern, die sie entworfen haben. Diese Wissenschaftler und Experten haben die Welt dazu aufgerufen, zu handeln, und KI als existenzielle Bedrohung für die Menschheit auf einer Ebene mit dem Risiko eines Atomkriegs erklärt."

Der Sicherheitsrat der Vereinten Nationen wird am 18. Juli ein beispielloses Treffen abhalten, um über diese KI-Risiken zu diskutieren. Unter dem Vorsitz des britischen Außenministers James Cleverly wird das Treffen des Sicherheitsrates eine Gelegenheit bieten, Expertenmeinungen zu KI zu hören und eine Diskussion unter den 15 Ratsmitgliedern über ihre Auswirkungen zu beginnen. Ein [offener Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) (veröffentlicht im April), der KI-Unternehmen dazu aufruft, ihre Trainingsläufe zu pausieren, wurde von über 33.000 Menschen unterzeichnet, darunter viele KI-Forscher und Tech-Führer. Kein einziges KI-Unternehmen hat bisher nachgegeben.

> "Wir können nicht erwarten, dass KI-Unternehmen freiwillig aufhören, neue KI-Modelle zu trainieren - der Wettbewerbsdruck ist zu groß. Nationale Regierungen haben ein ähnliches Problem, da Nationen auch im Wettbewerb stehen. Wir brauchen globale Maßnahmen. Der UN-Sicherheitsrat ist eines der wenigen Gremien, in denen ein solcher internationaler Vertrag gebildet werden könnte. Wir fordern unsere Führer auf, diese einzigartige Gelegenheit zu nutzen und die KI-Trainingsläufe zu pausieren." - PauseAI-Mitglieder

Das Vereinigte Königreich übernimmt derzeit die internationale Führung bei KI-Sicherheitsvorschriften, da die Regierung [am 7. Juni bekannt gab](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence), dass es den ersten KI-Sicherheitsgipfel in diesem Herbst ausrichten wird. Die Demonstranten befürchten jedoch, dass es zu wenig Aktionen geben wird, zu spät:

> "Es ist unglaublich schwierig, vorherzusagen, wie schnell KI fortschreiten wird. Wir müssen auf der Seite der Vorsicht erraten und uns auf ein Szenario vorbereiten, in dem wir gefährliche Intelligenzniveaus in Monaten - nicht Jahren - erreichen. Das Treffen des UN-Sicherheitsrates ist der erste Moment, in dem eine globale Pause beschlossen werden könnte." - PauseAI-Mitglieder