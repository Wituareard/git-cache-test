

Titel: Ein internationaler Stopp - Antworten auf die schwierigen Fragen
Beschreibung: Wie würde ein Stopp der künstlichen Intelligenz aussehen? Wie kann man tatsächlich verhindern, dass eine Superintelligenz geschaffen wird?

Wenn wir die Schaffung einer superintelligenten künstlichen Intelligenz zulassen, riskieren wir jedes einzelne Leben auf der Erde. Wenn wir über einen Stopp sprechen, sprechen wir über die Umsetzung eines internationalen Verbots der Schaffung einer superintelligenten künstlichen Intelligenz. Allerdings benötigen wir mehr als nur ein Verbot, wir müssen tatsächlich verhindern, dass es passiert. Um uns sicher zu halten, müssen wir den Bau einer Superintelligenz noch schwieriger machen, als er bereits ist. Und das bedeutet, dass wir einige schwierige Fragen beantworten müssen.

## Wie regulieren wir Hardware für künstliche Intelligenz?

<!-- Die größten künstlichen Intelligenz-Modelle, die trainiert wurden, haben ungefähr 100 Milliarden bis 1 Billion Parameter. -->
<!-- Zum Vergleich: Das menschliche Gehirn hat etwa 100 Billionen Synapsen. -->

Um ein Modell wie GPT-4 zu trainieren, benötigt man eine Vielzahl von hochspezialisierten und teuren Hardware (25.000 Nvidia A100-GPUs, Kosten von 10.000 $ pro Stück). Derzeit kann nur ein Unternehmen diese Grafikkarten herstellen: Nvidia. Nur ein Unternehmen kann die Chips herstellen: TSMC. Nur ein Unternehmen stellt die Lithographiemaschinen her: ASML.

Das bedeutet, dass die Lieferkette für die Schaffung dieser künstlichen Intelligenz-Modelle sehr zentralisiert ist, was bedeutet, dass sie relativ leicht zu kontrollieren ist. Die Umsetzung von Exportkontrollen für Grafikkarten und die Überwachung von Verkäufen wäre ein guter erster Schritt.

Aber da das Mooresche Gesetz weiterhin gilt, wird die Hürde für die Schaffung dieser Modelle immer niedriger. Wenn es sich als schwierig herausstellt, künstliche Intelligenz nachweislich sicher zu machen, könnte der Stopp viele Jahre dauern. Nicht nur wird die Hardware billiger und leistungsfähiger, wir können auch erwarten, dass effizientere Algorithmen entwickelt werden (wir werden später darüber sprechen). Das bedeutet, dass wir die Regulierung im Laufe der Zeit verschärfen müssen.

Irgendwann sollten wir es nicht mehr zulassen, dass Hardware leistungsfähiger wird. Das Risiko, eine superintelligente künstliche Intelligenz zu schaffen, könnte zu hoch sein.

## Wie regulieren wir Software für das Training von künstlicher Intelligenz?

Die Transformer-Architektur revolutionierte das Feld der künstlichen Intelligenz. Dieses neue parallele Design ermöglichte es, künstliche Intelligenz-Modelle auf viel höherem Niveau zu skalieren, bei viel niedrigeren Kosten und mit besseren Ergebnissen. Die Software-Seite ist jedoch viel schwieriger zu kontrollieren. Software ist nur Information - sie kann sehr leicht kopiert und verteilt werden.