---
title: Cybersicherheitsrisiken durch fortschrittliche KI-Modelle
description: Wie KI zum Hacken aller Geräte eingesetzt werden könnte.
---

Virtuell alles, was wir heutzutage tun, hängt auf irgendeine Weise von Computern ab.
Wir bezahlen unsere Einkäufe, planen unsere Tage, kontaktieren unsere Liebsten und sogar fahren unsere Autos mit Computern.
Und praktisch alle diese Computer sind miteinander verbunden.
Dies macht uns alle anfällig für Cyberangriffe.

Hochpotente Cyberwaffen, Malware und Botnetze (wie [Stuxnet](https://www.youtube.com/watch?v=nd1x0csO3hU), [Mirai](<https://en.wikipedia.org/wiki/Mirai_(malware)>) und [EMOTET](https://en.wikipedia.org/wiki/Emotet)) waren immer schwierig zu erstellen.
Die [Cyberwaffe Pegasus](<https://en.wikipedia.org/wiki/Pegasus_(spyware)>), zum Beispiel, kostete Hunderte Millionen Dollar zu entwickeln.
Das Auffinden sogenannter Zero-Day-Exploits (Sicherheitslücken, die noch nicht entdeckt wurden) erfordert viel Geschick und viel Zeit - nur hochspezialisierte Hacker können dies tun.
Wenn jedoch KI ausreichend fortgeschritten ist, wird dies nicht mehr der Fall sein.
Anstatt ein Team von hochqualifizierten Sicherheitsexperten/Hackern anzuheuern, um Zero-Day-Exploits zu finden, könnte jeder einfach eine viel billigere KI verwenden.

## KI-Modelle können autonom Sicherheitslücken finden und ausnutzen

Die neuesten KI-Systeme können bereits Software analysieren und schreiben.
Sie [können Sicherheitslücken finden](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411) in Software und [sie könnten verwendet werden, um sie auszunutzen](https://blog.checkpoint.com/2023/03/15/check-point-research-conducts-initial-security-analysis-of-chatgpt4-highlighting-potential-scenarios-for-accelerated-cybercrime/).
GPT-4 kann bereits [autonom Websites hacken](https://arxiv.org/html/2402.06664v1), indem es Aufgaben wie die Extraktion von Datenbank-Schemas und SQL-Injektionen ohne menschliches Feedback durchführt, was 18 Monate nach Abschluss der GPT-4-Trainingsphase entdeckt wurde.
GPT-4 übertrifft bereits [88%](https://arxiv.org/pdf/2402.11814.pdf) der menschlichen Hacker in einem CTF-Wettbewerb.
Es kann auch [autonom 87% der getesteten Sicherheitslücken ausnutzen](https://arxiv.org/abs/2404.08144), was einen enormen Fortschritt gegenüber GPT-3.5 oder Open-Source-Modellen darstellt, die alle 0% erreichten.
Teams aus mehreren LLMs [funktionieren noch besser](https://arxiv.org/abs/2406.01637) - sie können reale Zero-Day-Sicherheitslücken ausnutzen.
Wenn die KI-Fähigkeiten wachsen, werden auch die Sicherheitslücken, die sie erkennen können, und die Exploits, die sie erstellen können, zunehmen.
Sie sind noch nicht so gut darin wie die besten Menschen, also ist die Gefahr im Moment begrenzt.
Die Fähigkeiten nehmen jedoch rapide zu und können plötzlich stark ansteigen.

Es ist zu beachten, dass KI auch völlig neue Arten von Angriffen ermöglicht.
Zum Beispiel kann KI verwendet werden, um [das Passwort, das Sie in einem Online-Anruf eingegeben haben, zu hören](https://beebom.com/ai-crack-password-listening-keyboard-sounds/)
oder [Wi-Fi verwenden, um Menschen durch Wände zu sehen](https://www.marktechpost.com/2023/02/15/cmu-researchers-create-an-ai-model-that-can-detect-the-pose-of-multiple-humans-in-a-room-using-only-the-signals-from-wifi/).
KI kann auch verwendet werden, um [selbstmodifizierende Malware](https://www.hyas.com/blog/blackmamba-using-ai-to-generate-polymorphic-malware) zu erstellen, was es viel schwieriger macht, sie zu erkennen.

Es wird wahrscheinlich ein Punkt kommen, an dem eine KI besser im Hacken ist als die besten menschlichen Hacker.
Dies kann auf viele Arten schiefgehen.

- **Infrastruktur**: Cyberwaffen können verwendet werden, um Zugang zu oder die Kontrolle über kritische Infrastrukturen wie [Ölpipelines](https://en.wikipedia.org/wiki/Colonial_Pipeline_ransomware_attack) oder [Stromnetze](https://obr.uk/box/cyber-attacks-during-the-russian-invasion-of-ukraine/) zu erlangen.
- **Finanzen**: Cyberwaffen können verwendet werden, um [Geld von Banken zu stehlen](https://en.wikipedia.org/wiki/2015%E2%80%932016_SWIFT_banking_hack) oder um [den Aktienmarkt zu manipulieren](https://en.wikipedia.org/wiki/2010_flash_crash).
- **Militär**: Geräte wie Waffen und Sensoren sind zunehmend von drahtloser Konnektivität und komplexer Software abhängig.

## Groß angelegte Cyberangriffe

Es ist möglich, dass eine solche leistungsfähige KI verwendet wird, um einen Virus zu erstellen, der eine große Anzahl von Zero-Day-Exploits verwendet.
Die meisten Cyberwaffen verwenden
Eine ausreichend leistungsfähige KI könnte den Quellcode aller Betriebssysteme und anderer Software analysieren und Sicherheitslücken finden.
Ein solcher Virus könnte jeden Computer infizieren, unabhängig vom Betriebssystem, über mehrere Kanäle wie Wi-Fi, Bluetooth, UTP usw.
Dies könnte die volle Kontrolle über diese Maschinen ermöglichen und dem Angreifer ermöglichen, Daten zu stehlen, die Hardware für eigene Berechnungen zu verwenden, den Inhalt zu verschlüsseln, um Lösegeld zu erpressen, oder [die Maschine vollständig zu deaktivieren](https://en.wikipedia.org/wiki/Hardware_Trojan).

Ein Virus wie dieser könnte von Kriminellen als Werkzeug zum Stehlen von Geld erstellt werden oder als sehr zerstörerische Cyberwaffe von einer Nation oder einer terroristischen Organisation.
Wenn jedoch die KI immer agenter wird, könnte sie auch autonom erstellt und eingesetzt werden von [fehlgeleiteter KI](/xrisk).

Wenn das Ziel eines Cyberangriffs darin besteht, Geräte und Infrastrukturen zu deaktivieren, könnte der Schaden enorm sein.
Unsere Gesellschaft ist zunehmend von Computern und dem Internet abhängig.
Zahlungen, Verkehr, Kommunikation, Planung, Lieferketten, Stromnetze...
Wenn unsere Geräte nicht mehr ordnungsgemäß funktionieren, funktionieren auch viele Teile unserer Gesellschaft nicht mehr.

Über [93% der Cybersicherheitsexperten](https://www.weforum.org/publications/global-cybersecurity-outlook-2023/) glauben, dass "ein weitreichendes, katastrophales Cyberereignis in den nächsten zwei Jahren wahrscheinlich ist".

## Minderung von KI-Cybersicherheitsrisiken

Die oben beschriebene Geschichte kann nur passieren, wenn:

1. Die **Fähigkeit, Zero-Day-Exploits zu finden**, entsteht. Aktuelle Modelle können bereits einige Sicherheitslücken entdecken, aber dies wird wahrscheinlich mit neueren Modellen verbessert.
2. Das **Modell in die Hände von böswilligen Akteuren gerät**. Dies kann passieren, wenn die Modellgewichte geleakt werden, wenn das Modell Open-Source ist oder wenn es von einem böswilligen Akteur entwickelt wird.
3. Die **Sicherheitslücken nicht gepatcht werden**, bevor ein solches Cyberwaffen eingesetzt wird. Leider sind die Verteidiger im Nachteil, wenn das Modell weit verbreitet ist, aus zwei Gründen:
   1. Patchen + Veröffentlichen + Bereitstellen dauert viel länger als angreifen. Das Fenster der Verwundbarkeit ist größer als die Zeit, die benötigt wird, um den Angriff zu starten.
   2. Die Angreifer müssen nur eine Sicherheitslücke finden, während die Verteidiger alle finden müssen.

Es gibt verschiedene Maßnahmen, die wir ergreifen können, um diese Risiken zu mindern:

- **Erlauben Sie nicht die Schulung von Modellen, die Zero-Day-Exploits finden können**. Dies ist der effektivste Weg, um dies zu verhindern. Es ist der sicherste Weg, und es ist das, was wir [vorschlagen](/proposal).
- **Erlauben Sie nur die Bereitstellung oder Open-Sourcing von Modellen nach umfassenden Tests**. Wenn sie gefährliche Fähigkeiten haben, veröffentlichen Sie sie nicht.
- **Erlassen Sie strenge Cybersicherheitsvorschriften, um zu verhindern, dass Modellgewichte geleakt werden**. Wenn Sie gefährliche Modelle zulassen, stellen Sie sicher, dass sie nicht in die falschen Hände geraten geraten geraten geraten geraten geraten geraten geraten geraten geraten ger